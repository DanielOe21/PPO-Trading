{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvQeBc6SyedA"
      },
      "source": [
        "#INSTALA LIBRERIAS\n",
        "\n",
        "Se descargan librerias de GitHub necesarias para ejecutar el algoritmo, se puede comentariar si se ejecutan varios experimentos, solo correr 1 vez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5oNllgBLECXa"
      },
      "outputs": [],
      "source": [
        "# DESCARGA DE LIBRERIAS\n",
        "#!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git@2070f85cdd4d2cde4c00da98ff01ff448b1e593b --use-deprecated=legacy-resolver\n",
        "#!pip install git+https://github.com/quantopian/pyfolio.git --use-deprecated=legacy-resolver\n",
        "#!pip install yfinance --use-deprecated=legacy-resolver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxqB2TSe-rZd"
      },
      "source": [
        "#Descarga de librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9xZAmbuDXSZ",
        "outputId": "59158cb8-9829-45e6-d5b3-330d813b1875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La creación del directorio ./data falló\n"
          ]
        }
      ],
      "source": [
        "# DESCARGA DE LIBRERIAS 2\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import datetime\n",
        "import os\n",
        "import math\n",
        "\n",
        "from finrl.config import config\n",
        "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
        "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
        "from finrl.preprocessing.data import data_split\n",
        "from finrl.env.env_portfolio import StockPortfolioEnv\n",
        "\n",
        "from finrl.model.models import DRLAgent\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "import yfinance as yf\n",
        "from pandas_datareader import data as pdr\n",
        "\n",
        "import pyfolio\n",
        "from copy import deepcopy\n",
        "\n",
        "  # para usar el sr como reward funct\n",
        "  # Se define el nombre de la carpeta o directorio a crear\n",
        "directorio = \"./data\"\n",
        "try:\n",
        "  os.mkdir(directorio)\n",
        "except OSError:\n",
        "  print(\"La creación del directorio %s falló\" % directorio)\n",
        "else:\n",
        "  print(\"Se ha creado el directorio: %s \" % directorio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9WZVB3eyjXN"
      },
      "source": [
        "# AGENTE\n",
        "\n",
        "En esta sección se configuran los ajustes del agente:\n",
        " - PPO Policy\n",
        " - actor, es la red neuronal (Figura de actor, hasta Miu), es a partir del ELSE\n",
        "        1. cambiar funcion de activación con el mismo numero de capas\n",
        "        2. cambiar optimizador\n",
        "        3. cambiar número de capas (no tienen q ser 64)\n",
        " - critic: Tiene 1 neurona de salida, puede agregarse otra capa de salida\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA6FmNNCoj27",
        "outputId": "0d8b9174-b798-4417-ea5b-cb6119c37e2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "Device set to : cpu\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "# AGENT DE APRENDIZAJE POR REFUERZO\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.distributions import Categorical\n",
        "import time\n",
        "\n",
        "################################## set device ##################################\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "# set device to cpu or cuda\n",
        "device = torch.device('cpu')\n",
        "\n",
        "if(torch.cuda.is_available()): \n",
        "    device = torch.device('cuda:0') \n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
        "else:\n",
        "    print(\"Device set to : cpu\")\n",
        "    \n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "################################## PPO Policy ##################################\n",
        "\n",
        "\n",
        "class RolloutBuffer:\n",
        "    def __init__(self):\n",
        "        self.actions = []\n",
        "        self.states = []\n",
        "        self.logprobs = []\n",
        "        self.rewards = []\n",
        "        self.is_terminals = []\n",
        "    \n",
        "\n",
        "    def clear(self):\n",
        "        del self.actions[:]\n",
        "        del self.states[:]\n",
        "        del self.logprobs[:]\n",
        "        del self.rewards[:]\n",
        "        del self.is_terminals[:]\n",
        "\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self,\n",
        "                 state_dim,\n",
        "                 action_dim,\n",
        "                 has_continuous_action_space,\n",
        "                 action_std_init,\n",
        "                 nn_arch,\n",
        "                 kernel_size):\n",
        "        super(ActorCritic, self).__init__()\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_dim = action_dim\n",
        "            #[0.6, 0.6, 0.6]\n",
        "            # Calcular la varianza los precios de cierre historicos de cada activo\n",
        "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
        "\n",
        "        self.nn_arch = nn_arch\n",
        "\n",
        "        # actor\n",
        "        # 1. cambiar funcion de activación con el mismo nuomero de capas\n",
        "        # 2. cambiar optimizador\n",
        "        # 3. cambiar número de capas\n",
        "        if has_continuous_action_space:\n",
        "            if self.nn_arch == 'CNN-MLP':\n",
        "              self.actor = nn.Sequential(\n",
        "                              nn.Linear(state_dim, state_dim),\n",
        "                              nn.AvgPool1d(kernel_size, stride=kernel_size),\n",
        "                              #nn.Conv1d(1, 1, kernel_size, stride=kernel_size),\n",
        "                              #2d, #imprimir diagrama, #downsampling, upsampling\n",
        "                              nn.Linear(int(state_dim / kernel_size), 64),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(64, 64),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(64, action_dim),\n",
        "                              nn.Tanh())\n",
        "    ######################### AQUI SE MODIFICA #############################\n",
        "            else:\n",
        "              self.actor = nn.Sequential(\n",
        "                              nn.Linear(state_dim, 128),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(128, 128),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(128, action_dim),\n",
        "                              nn.Tanh())\n",
        "                              \n",
        "        # critic\n",
        "        if self.nn_arch == 'CNN-MLP':\n",
        "            self.critic = nn.Sequential(\n",
        "                            nn.Linear(state_dim, state_dim),\n",
        "                            nn.AvgPool1d(kernel_size, stride=kernel_size),\n",
        "                            #nn.Conv1d(1, 1, kernel_size, stride=kernel_size),\n",
        "                            nn.Linear(int(state_dim / kernel_size), 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 1))\n",
        "    ######################### AQUI SE MODIFICA #############################\n",
        "        else:\n",
        "          self.critic = nn.Sequential(\n",
        "                          nn.Linear(state_dim, 128),\n",
        "                          nn.Tanh(),\n",
        "                          nn.Linear(128, 128),\n",
        "                          nn.Tanh(),\n",
        "                          nn.Linear(128, 1))\n",
        "                          #nn.Tanh())\n",
        "                \n",
        "        \n",
        "    def set_action_std(self, new_action_std):\n",
        "        #return\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "    \n",
        "\n",
        "    def act(self, state):\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state) #LA SALIDA ES MIU\n",
        "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0) #Calcula la matriz de covarianzas\n",
        "            dist = MultivariateNormal(action_mean, cov_mat) #Genera la matriz de distribución normal con (M,N) o sea la funcion\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "\n",
        "        action = dist.sample() # Genera numeros aleatorios y se los pasa a la funcion de distribucion que se deriva de las medias de las acciones y la matriz de covarianza (dist)\n",
        "        action_logprob = dist.log_prob(action) #La accion es la flechita que sale de N en el diagrama\n",
        "        \n",
        "        return action.detach(), action_logprob.detach()\n",
        "    \n",
        "\n",
        "    def evaluate(self, state, action): #Es similar a actuar, pero evalua que tan buenos son los valores de los estados que se han pronosticado\n",
        "        if self.nn_arch == 'CNN-MLP':\n",
        "          state = state.unsqueeze(0)\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state)\n",
        "            \n",
        "            action_var = self.action_var.expand_as(action_mean)\n",
        "            cov_mat = torch.diag_embed(action_var).to(device)\n",
        "            dist = MultivariateNormal(action_mean, cov_mat)\n",
        "            \n",
        "            # For Single Action Environments.\n",
        "            if self.action_dim == 1:\n",
        "                action = action.reshape(-1, self.action_dim)\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "        state_values = self.critic(state)\n",
        "        \n",
        "        return action_logprobs, state_values, dist_entropy\n",
        "\n",
        "\n",
        "class PPO:\n",
        "    def __init__(self,\n",
        "                 state_dim,\n",
        "                 action_dim,\n",
        "                 lr_actor,\n",
        "                 lr_critic,\n",
        "                 gamma,\n",
        "                 K_epochs,\n",
        "                 eps_clip,\n",
        "                 has_continuous_action_space,\n",
        "                 action_std_init=0.6,\n",
        "                 nn_arch='MLP',\n",
        "                 kernel_size=1):\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_std = action_std_init\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.eps_clip = eps_clip\n",
        "        self.K_epochs = K_epochs\n",
        "        \n",
        "        self.buffer = RolloutBuffer()\n",
        "\n",
        "        self.policy = ActorCritic(state_dim,\n",
        "                                  action_dim,\n",
        "                                  has_continuous_action_space,\n",
        "                                  action_std_init,\n",
        "                                  nn_arch,\n",
        "                                  kernel_size).to(device)\n",
        "        print(self.policy)\n",
        "        self.optimizer = torch.optim.RMSprop([\n",
        "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
        "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
        "                    ])\n",
        "\n",
        "        self.policy_old = ActorCritic(state_dim,\n",
        "                                      action_dim,\n",
        "                                      has_continuous_action_space,\n",
        "                                      action_std_init,\n",
        "                                      nn_arch,\n",
        "                                      kernel_size).to(device)\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "        \n",
        "        self.MseLoss = nn.MSELoss()\n",
        "\n",
        "\n",
        "    def set_action_std(self, new_action_std):\n",
        "        \n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = new_action_std\n",
        "            self.policy.set_action_std(new_action_std)\n",
        "            self.policy_old.set_action_std(new_action_std)\n",
        "        \n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = self.action_std - action_std_decay_rate\n",
        "            self.action_std = round(self.action_std, 4)\n",
        "            if (self.action_std <= min_action_std):\n",
        "                self.action_std = min_action_std\n",
        "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
        "            else:\n",
        "                print(\"setting actor output action_std to : \", self.action_std)\n",
        "            self.set_action_std(self.action_std)\n",
        "\n",
        "        else:\n",
        "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
        "\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def select_action(self, state):\n",
        "        with torch.no_grad():\n",
        "            state = torch.FloatTensor(state).to(device)\n",
        "            state_unsqueeze = state.unsqueeze(0)\n",
        "            action, action_logprob = self.policy_old.act(state_unsqueeze)\n",
        "  \n",
        "        if self.has_continuous_action_space:\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "\n",
        "            return action.detach().cpu().numpy().flatten()\n",
        "        else:\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "\n",
        "            return action.item()\n",
        "\n",
        "\n",
        "    def update(self):\n",
        "      # Monte Carlo estimate of returns\n",
        "      rewards = []\n",
        "      discounted_reward = 0\n",
        "      for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
        "          if is_terminal:\n",
        "              discounted_reward = 0\n",
        "          discounted_reward = reward + (self.gamma * discounted_reward)\n",
        "          rewards.insert(0, discounted_reward)\n",
        "          \n",
        "      # Normalizing the rewards\n",
        "      rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "      rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
        "\n",
        "      # convert list to tensor\n",
        "      old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
        "      old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
        "      old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
        "\n",
        "      \n",
        "      # Optimize policy for K epochs\n",
        "      for _ in range(self.K_epochs):\n",
        "\n",
        "        # Evaluating old actions and values\n",
        "        logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
        "\n",
        "        # match state_values tensor dimensions with rewards tensor\n",
        "        state_values = torch.squeeze(state_values)\n",
        "        \n",
        "        # Finding the ratio (pi_theta / pi_theta__old)\n",
        "        ratios = torch.exp(logprobs - old_logprobs.detach())\n",
        "\n",
        "        # Finding Surrogate Loss\n",
        "        advantages = rewards - state_values.detach()   \n",
        "        surr1 = ratios * advantages\n",
        "        surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
        "\n",
        "        # final loss of clipped objective PPO\n",
        "        loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
        "        \n",
        "        # take gradient step\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.mean().backward()\n",
        "        self.optimizer.step()\n",
        "      # Copy new weights into old policy\n",
        "      self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "      # clear buffer\n",
        "      self.buffer.clear()\n",
        "            \n",
        "    def save(self, checkpoint_path):\n",
        "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
        "   \n",
        "\n",
        "    def load(self, checkpoint_path):\n",
        "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
        "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDfuXELB-0Ob"
      },
      "source": [
        "#PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Td0JBxOpEMtE"
      },
      "outputs": [],
      "source": [
        "class PortfolioAllocation(gym.Env):\n",
        "  passmetadata = {'render.modes': ['human']}\n",
        "\n",
        "  def __init__(self,\n",
        "               df,\n",
        "               stock_dim,\n",
        "               initial_amount,\n",
        "               tech_indicator_list,\n",
        "               market_variables,\n",
        "               reward_function,\n",
        "               day=0,\n",
        "               data_stddev=None,\n",
        "               free_risk_return=None,\n",
        "               data_corr=None,\n",
        "               expected_values=None,\n",
        "               trading_fee=0,\n",
        "               nn_arch='MLP',\n",
        "               window_width=1):\n",
        "    self.df = df\n",
        "    self.stock_dim = stock_dim\n",
        "    self.initial_amount = initial_amount\n",
        "    self.tech_indicator_list = tech_indicator_list\n",
        "    self.day_start = day\n",
        "    self.day = self.day_start\n",
        "    self.market_variables = market_variables\n",
        "    self.reward_function = reward_function\n",
        "    self.window_width = window_width\n",
        "    self.nn_arch = nn_arch\n",
        "\n",
        "    self.setup()\n",
        "\n",
        "    # Reward based on Sharpe Ratio (correlation)\n",
        "    self.expected_values = expected_values\n",
        "    self.data_stddev = data_stddev\n",
        "    self.data_corr = data_corr\n",
        "    self.free_risk_return = free_risk_return\n",
        "\n",
        "    self.trading_fee = trading_fee\n",
        "\n",
        "  def setup(self):\n",
        "    # action_space normalization and shape is self.stock_dim\n",
        "    self.action_space = spaces.Box(low=0, high=1,\n",
        "                                   shape=(self.stock_dim,))\n",
        "    # observation space\n",
        "    shape = (self.stock_dim * (len(self.market_variables) + len(self.tech_indicator_list)) * self.window_width,)\n",
        "\n",
        "    self.observation_space = spaces.Box(low=-0, high=np.inf,\n",
        "                                        shape=shape)\n",
        "\n",
        "    self.reset()\n",
        "\n",
        "  def step(self, actions):\n",
        "    self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
        "\n",
        "    if self.terminal:\n",
        "      #df = pd.DataFrame(self.portfolio_return_memory)\n",
        "      #df.columns = ['daily_return']\n",
        "      return self.state, self.reward, self.terminal, {}\n",
        "    else:\n",
        "      # actions are the portfolio weight\n",
        "      # normalize to sum of 1\n",
        "      weights = self.softmax_normalization(actions) #-> [0.2, 0.7, 0.1] #Los pesos son el capital a destinar de cada uno de los activos, se calculan a paritr de aplicar una normalizacion de tipo softmax a lo que se considera actions\n",
        "      # Acciones son la salida de la N\n",
        "\n",
        "      last_day_memory = self.data\n",
        "\n",
        "      # load next state\n",
        "      self.day += 1\n",
        "      self.state = self._get_state()\n",
        "  \n",
        "      prev_portfolio_value = self.portfolio_value\n",
        "      # [0.2, 0.7, 0.1] * [80, 120] -> [0.2, 0.7, 0.1] * [80, 120, 1] \n",
        "      # 1 am = [1] / [120] = 0.0083 (1dll)\n",
        "      # 2 [0.0083]* [150] = 1.25  (+ 0.25dll)\n",
        "      # 3 am += ([1] * [1.25]) / [150] = \n",
        "      # A [0.5, 0.5] / [120, 80] = 0.0041, 0.0062\n",
        "      # B [0.0041, 0.0062] * [130, 100] = [ 0.54 , 0.62] = 1.16\n",
        "      # C [0.3, 0.7] * [1.16] = [0.384, 0.82] / [130, 100] = [0.00276259, 0.0082] = \n",
        "      self.portfolio_value = sum(self.actions_memory[-1] * self.data.close.values)\n",
        "      self.actions_memory.append(weights*self.portfolio_value / self.data.close.values)\n",
        "      portfolio_return = ((self.portfolio_value / prev_portfolio_value) - 1)\n",
        "\n",
        "      # save into memory\n",
        "      self.portfolio_return_memory.append(portfolio_return)\n",
        "      self.date_memory.append(self.data.date.unique()[0])           \n",
        "      self.asset_memory.append(self.portfolio_value)\n",
        "\n",
        "      # reward\n",
        "\n",
        "      if self.reward_function == 'pv':\n",
        "        self.reward = portfolio_return\n",
        "        #self.reward = portfolio_return\n",
        "      elif self.reward_function == 'sr':\n",
        "        portfolio_risk = self.portfolio_risk(weights, self.data_stddev, self.data_corr)\n",
        "        self.reward = self.sharpeVE_ratio(weights, self.expected_values, portfolio_risk, self.free_risk_return)\n",
        "\n",
        "      return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "  def _get_state(self):\n",
        "    self.data = self.df.loc[self.day,:].sort_values(by=['tic'])\n",
        "\n",
        "    tmp_data = [np.array(self.data[prop])\n",
        "                for prop in self.market_variables + self.tech_indicator_list]\n",
        "\n",
        "    for i in range(1, self.window_width):\n",
        "      data = self.df.loc[self.day - i,:].sort_values(by=['tic'])\n",
        "      tmp_data = tmp_data + [np.array(data[prop])\n",
        "                             for prop in self.market_variables + self.tech_indicator_list]\n",
        "    \n",
        "    state = np.concatenate(tmp_data, axis=0)\n",
        "    return state\n",
        "\n",
        "  def _reset(self):\n",
        "    self.state = self._get_state()\n",
        "    self.terminal = False\n",
        "    # Agregar + 1 en stock_dim 1/(self.stock_dim + 1)\n",
        "    initial_weights = np.array([1/self.stock_dim] * self.stock_dim)\n",
        "    # [.5, .5] * [120, 80] = [0.004, 0.006]* [120, 80] = [0.5, 0.5]\n",
        "    self.portfolio_value = sum((initial_weights / self.data.close.values) * self.data.close.values)\n",
        "\n",
        "    self.portfolio_return_memory = [0]\n",
        "    self.asset_memory = [self.initial_amount]\n",
        "    # agregar + 1\n",
        "    self.actions_memory = [initial_weights / self.data.close.values]\n",
        "    self.date_memory = [self.data.date.unique()[0]] \n",
        "\n",
        "  def reset(self):\n",
        "    self.day = self.day_start\n",
        "    self._reset()\n",
        "    return self.state\n",
        "\n",
        "  def save_asset_memory(self):\n",
        "    date_list = self.date_memory\n",
        "    portfolio_return = self.portfolio_return_memory\n",
        "    df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "    return df_account_value\n",
        "\n",
        "  def save_action_memory(self):\n",
        "    # date and close price length must match actions length\n",
        "    date_list = self.date_memory\n",
        "    df_date = pd.DataFrame(date_list)\n",
        "    df_date.columns = ['date']\n",
        "    \n",
        "    action_list = self.actions_memory\n",
        "    df_actions = pd.DataFrame(action_list)\n",
        "    df_actions.columns = self.data.tic.values\n",
        "    df_actions.index = df_date.date\n",
        "    return df_actions\n",
        "\n",
        "  def render(self, mode='human'):\n",
        "    return self.state\n",
        "\n",
        "  def softmax_normalization(self, actions):\n",
        "    numerator = np.exp(actions)\n",
        "    denominator = np.sum(np.exp(actions))\n",
        "    softmax_output = numerator/denominator\n",
        "    return softmax_output\n",
        "\n",
        "  def _seed(self, seed=None):\n",
        "    self.np_random, seed = seeding.np_random(seed)\n",
        "    return [seed]\n",
        "\n",
        "  def get_sb_env(self):\n",
        "    e = DummyVecEnv([lambda: self])\n",
        "    obs = e.reset()\n",
        "    return e, obs\n",
        "\n",
        "  def portfolio_risk(self, weights, data_stddev, data_corr):\n",
        "    aux_1 = 0\n",
        "    aux_2 = 0\n",
        "    for i in range(len(weights)):\n",
        "        aux_1 += math.pow(weights[i], 2) * math.pow(data_stddev[i], 2)\n",
        "\n",
        "    for i in range(len(weights)):\n",
        "        for j in range(len(weights)):\n",
        "            if i == j:\n",
        "                continue\n",
        "            aux_2 += weights[i] * weights[j] * data_stddev[i] * data_stddev[j] * data_corr.values[i][j]\n",
        "\n",
        "    return np.sqrt(aux_1 + (2 * aux_2))\n",
        "\n",
        "  def sharpeVE_ratio(self, weights, expected_values,\n",
        "                     risk, free_risk_return):\n",
        "    sr = (sum(weights * expected_values * 252) - free_risk_return) / risk\n",
        "    return sr\n",
        "\n",
        "def get_dataframe(tickers, start_date, end_date):\n",
        "    df = YahooDownloader(start_date=start_date,\n",
        "                         end_date=end_date,\n",
        "                         ticker_list=tickers).fetch_data()\n",
        "    return df\n",
        "\n",
        "def retrieve_data_from_yahoo(assets, start_date, end_date, attribute):\n",
        "  '''\n",
        "  -> Example output\n",
        "                  GFNORTEO.MX     BSMXB.MX    ....\n",
        "  Date                              \n",
        "  2019-01-02      93.142639       24.001934\n",
        "  ...\n",
        "  ...\n",
        "  2019-12-31      93.142639       24.001934\n",
        "  '''\n",
        "  df = pd.DataFrame()\n",
        "  for asset in assets:\n",
        "    try:\n",
        "      df_asset = pd.read_csv('./data/{}+[{}]_[{}].csv'.format(asset, start_date, end_date))\n",
        "      df_asset.set_index('Date', inplace=True)\n",
        "    except FileNotFoundError as e:\n",
        "      df_asset = pdr.get_data_yahoo(asset, start=start_date, end=end_date)[attribute]\n",
        "      df_asset = df_asset.to_frame(name=asset)\n",
        "      df_asset.to_csv('./data/{}+[{}]_[{}].csv'.format(asset, start_date, end_date))\n",
        "\n",
        "    df = pd.concat([df, df_asset], axis=1, sort=False)\n",
        "  return df\n",
        "\n",
        "def data_cleaning(dataframe):\n",
        "    df = dataframe.dropna(axis=1, how='all') \n",
        "    df = df.interpolate(limit_direction='both') \n",
        "    return df.sort_index(axis=1), sorted(df.columns)\n",
        "\n",
        "def data_preparation(dataframe, assets):\n",
        "  data_pct_changes = dataframe.pct_change().dropna()\n",
        "  data_covariances = np.cov(data_pct_changes.transpose())\n",
        "  data_stddev = np.array(np.std(data_pct_changes))\n",
        "  data_corr = data_pct_changes.corr()\n",
        "  expected_values = get_expected_values(dataframe, data_pct_changes, assets)\n",
        "\n",
        "  return data_stddev, data_corr, expected_values\n",
        "  #return data_pct_changes, data_covariances, data_stddev, data_corr, expected_values\n",
        "\n",
        "def get_expected_values(data, data_pct_changes, assets):\n",
        "  expected_values = []\n",
        "\n",
        "  for serie in assets:\n",
        "      x, rangos = np.histogram(data_pct_changes[serie], bins=10)\n",
        "      y=[]\n",
        "      for i in range(len(rangos) - 1):\n",
        "          y.append((rangos[i] + rangos[i + 1]) / 2)\n",
        "      p = x / len(data)\n",
        "      expected_value = sum(p * y) \n",
        "      expected_values.append(expected_value)\n",
        "\n",
        "  return np.array(expected_values)\n",
        "\n",
        "def feature_engineering(df, indicators):\n",
        "    fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                        tech_indicator_list=indicators,\n",
        "                        use_turbulence=False,\n",
        "                        user_defined_feature=False)\n",
        "\n",
        "    return fe.preprocess_data(df)\n",
        "\n",
        "def zscore(df, tickers, properties):\n",
        "  df = df.copy()\n",
        "  df = df.sort_values(by=['tic','date'])\n",
        "\n",
        "  for var in properties:\n",
        "      var_df = pd.DataFrame()\n",
        "      for ticker in tickers:\n",
        "          temp_normalized = stats.zscore(df[df.tic == ticker][var])\n",
        "          temp_normalized = pd.DataFrame(temp_normalized, columns=[var+'_zscore'])\n",
        "          temp_normalized['tic'] = ticker\n",
        "          temp_normalized['date'] = df[df.tic == ticker]['date'].to_list()\n",
        "          var_df = var_df.append(\n",
        "              temp_normalized, ignore_index=True\n",
        "          )\n",
        "      df = df.merge(var_df[['tic','date',var+'_zscore']],on=['tic','date'],how='left')\n",
        "  df = df.sort_values(by=['date','tic'])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKENnzGyiGJ3"
      },
      "source": [
        "# Hiperparametros del PPO\n",
        "\n",
        "se crea el agente y el entorno. \n",
        "\n",
        "Se pueden modificar las epocas del PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tv6P9YbTE8Hw"
      },
      "outputs": [],
      "source": [
        "def train_and_perform(index,\n",
        "                      policy,\n",
        "                      episodes,\n",
        "                      n_steps,\n",
        "                      market_variables,\n",
        "                      indicators,\n",
        "                      reward_function,\n",
        "                      normalization_function,\n",
        "                      tickers,\n",
        "                      training_start_date,\n",
        "                      training_end_date,\n",
        "                      trading_start_date,\n",
        "                      trading_end_date,\n",
        "                      trading_fee,\n",
        "                      file_,\n",
        "                      nn_arch='MLP',\n",
        "                      window_width=1):\n",
        "  df = get_dataframe(tickers, training_start_date, trading_end_date)\n",
        "  df['rate open/close'] = df['open']/df['close']\n",
        "  df = feature_engineering(df, indicators)\n",
        "\n",
        "  if not (normalization_function is None):\n",
        "    df = normalization_function(df, tickers, market_variables + indicators)\n",
        "\n",
        "  train_df = data_split(df, training_start_date, training_end_date)\n",
        "  print(train_df)\n",
        "  # calcular vector varianzas de train_df en base a los precios de cierre\n",
        "  trading_df = data_split(df, trading_start_date, trading_end_date)\n",
        "\n",
        "  if reward_function == 'pv':\n",
        "    env_kwargs = {\n",
        "    'initial_amount': 1, \n",
        "    'stock_dim': len(tickers),\n",
        "    'tech_indicator_list': indicators,\n",
        "    'market_variables': market_variables,\n",
        "    'reward_function': reward_function,\n",
        "    'trading_fee': trading_fee,\n",
        "    'nn_arch': nn_arch,\n",
        "    'window_width': window_width,\n",
        "    'day': window_width - 1\n",
        "    }\n",
        "  elif reward_function == 'sr':\n",
        "    yf.pdr_override()\n",
        "\n",
        "    df_adj_close = retrieve_data_from_yahoo(tickers,\n",
        "                                            training_start_date,\n",
        "                                            training_end_date,\n",
        "                                            'Adj Close')\n",
        "    df_adj_close, tickers_adj_close = data_cleaning(df_adj_close)\n",
        "\n",
        "    data_stddev, data_corr, expected_values = data_preparation(df_adj_close, tickers_adj_close)\n",
        "\n",
        "    free_risk_return = 0.015\n",
        "\n",
        "    env_kwargs = {\n",
        "      'initial_amount': 1, \n",
        "      'stock_dim': len(tickers), \n",
        "      'tech_indicator_list': indicators, \n",
        "      'market_variables': market_variables,\n",
        "      'expected_values': expected_values,\n",
        "      'reward_function': reward_function,\n",
        "      'free_risk_return': free_risk_return,\n",
        "      'data_stddev': data_stddev,\n",
        "      'data_corr': data_corr,\n",
        "      'trading_fee': trading_fee,\n",
        "      'nn_arch': nn_arch,\n",
        "      'window_width': window_width,\n",
        "      'day': window_width - 1\n",
        "    }\n",
        "\n",
        "  training_env_gym = PortfolioAllocation(df=train_df, **env_kwargs)\n",
        "  training_env, _ = training_env_gym.get_sb_env()\n",
        "\n",
        "  trading_env_gym = PortfolioAllocation(df=trading_df, **env_kwargs)\n",
        "  trading_env, _ = trading_env_gym.get_sb_env()\n",
        "\n",
        "  ####### initialize environment hyperparameters ######\n",
        "\n",
        "  has_continuous_action_space = True\n",
        "  max_ep_len = len(train_df.date.unique())\n",
        "  max_ep_trading_len = len(trading_df.date.unique())                   \n",
        "  max_training_timesteps = len(train_df.date.unique()) * episodes \n",
        "\n",
        "  print_freq = max_ep_len * 10        # print avg reward in the interval (in num timesteps)\n",
        "  log_freq = max_ep_len * 2           # log avg reward in the interval (in num timesteps)\n",
        "  save_model_freq = int(1e5)          # save model frequency (in num timesteps)\n",
        "\n",
        "  action_std = 0.6                    # starting std for action distribution (Multivariate Normal)\n",
        "  action_std_decay_rate = 0.01        # linearly decay action_std (action_std = action_std - action_std_decay_rate)\n",
        "  min_action_std = 0.1                # minimum action_std (stop decay after action_std <= min_action_std)\n",
        "  action_std_decay_freq = int(5.5e3)  # action_std decay frequency (in num timesteps)\n",
        "  \n",
        "  #####################################################\n",
        "\n",
        "  ################ PPO hyperparameters ################\n",
        "\n",
        "  update_timestep = max_ep_len * 4      # update policy every n timesteps\n",
        "  #update_timestep = int(max_ep_len / 4)\n",
        "  K_epochs = 80               # update policy for K epochs in one PPO update\n",
        "\n",
        "  eps_clip = 0.2          # clip parameter for PPO\n",
        "  gamma = 0.99           # discount factor\n",
        "\n",
        "  lr_actor = 0.0003       # learning rate for actor network\n",
        "  lr_critic = 0.001       # learning rate for critic network\n",
        "\n",
        "  random_seed = 0         # set random seed if required (0 = no random seed)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  # state space dimension\n",
        "  state_dim = training_env.observation_space.shape[0]\n",
        "\n",
        "  # action space dimension\n",
        "  action_dim = training_env.action_space.shape[0]\n",
        "\n",
        "  ppo_agent = PPO(state_dim,\n",
        "                  action_dim, #[0.2, 0.3, 0.5] aunque solamente tengas 2 activos\n",
        "                  lr_actor,\n",
        "                  lr_critic,\n",
        "                  gamma,\n",
        "                  K_epochs,\n",
        "                  eps_clip,\n",
        "                  has_continuous_action_space,\n",
        "                  action_std,\n",
        "                  nn_arch=nn_arch,\n",
        "                  kernel_size=(len(market_variables) + len(indicators)) * window_width)\n",
        "  \n",
        "  # printing and logging variables\n",
        "  print_running_reward = 0\n",
        "  print_running_episodes = 0\n",
        "\n",
        "  time_step = 0\n",
        "  i_episode = 0\n",
        "\n",
        "  ################ Training ################\n",
        "  training_time = time.time()\n",
        "  while time_step <= max_training_timesteps:\n",
        "    state = training_env.reset()\n",
        "    current_ep_reward = 0\n",
        "\n",
        "    for t in range(1, max_ep_len+1):\n",
        "      # select action with policy\n",
        "      action = ppo_agent.select_action(state)\n",
        "      state, reward, done, _ = training_env.step([action])\n",
        "\n",
        "      reward = reward[0]\n",
        "\n",
        "      # saving reward and is_terminals\n",
        "      ppo_agent.buffer.rewards.append(reward)\n",
        "      ppo_agent.buffer.is_terminals.append(done)\n",
        "\n",
        "      time_step +=1\n",
        "      current_ep_reward += reward\n",
        "\n",
        "      # update PPO agent\n",
        "      if time_step % update_timestep == 0:\n",
        "        ppo_agent.update()\n",
        "\n",
        "      # if continuous action space; then decay action std of ouput action distribution\n",
        "      if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
        "        ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
        "\n",
        "      # break; if the episode is over\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    print_running_reward += current_ep_reward\n",
        "    print_running_episodes += 1\n",
        "\n",
        "    i_episode += 1\n",
        "  training_time = time.time() - training_time\n",
        "  print('Training')\n",
        "  \n",
        "  #####################################################\n",
        "\n",
        "  ################ Testing ################\n",
        "\n",
        "  testing_time = 0\n",
        "  df_daily_return = None\n",
        "  total_test_episodes = 15\n",
        "  for ep in range(total_test_episodes):\n",
        "    testing_time_  = time.time()\n",
        "    ep_reward = 0\n",
        "    state = trading_env.reset()\n",
        "\n",
        "    for t in range(max_ep_trading_len):\n",
        "      action = ppo_agent.select_action(state)\n",
        "      state, reward, done, _ = trading_env.step([action])\n",
        "  \n",
        "      reward = reward[0]\n",
        "      ep_reward += reward\n",
        "\n",
        "      if t == max_ep_trading_len - (window_width + 2):\n",
        "        tmp_dr = trading_env.env_method(method_name=\"save_asset_memory\")[0]\n",
        "        actions_memory = trading_env.env_method(method_name=\"save_action_memory\")[0]\n",
        "        if df_daily_return is None:\n",
        "          df_daily_return = tmp_dr\n",
        "        else:\n",
        "          df_daily_return['daily_return'] = df_daily_return['daily_return'] + tmp_dr['daily_return']\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    # clear buffer\n",
        "    ppo_agent.buffer.clear()\n",
        "    testing_time += (time.time() - testing_time_)\n",
        "\n",
        "  print('Testing')\n",
        "  print(actions_memory)\n",
        "  #####################################################\n",
        "\n",
        "  df_daily_return.loc[:,'daily_return'] /= total_test_episodes\n",
        "  df_plot = deepcopy(df_daily_return)\n",
        "  df_plot['date'] = pd.to_datetime(df_plot['date'])\n",
        "  df_plot.set_index(\"date\", inplace=True, drop=True)\n",
        "  df_plot.index = df_plot.index.tz_localize(\"UTC\")\n",
        "\n",
        "  serie = pd.Series(df_plot[\"daily_return\"], index=df_plot.index)\n",
        "  print(serie)\n",
        "  file_.write('training_time {}\\n'.format(training_time))\n",
        "  file_.write('testing_time {}\\n'.format(testing_time))\n",
        "  file_.write(str(pyfolio.timeseries.perf_stats(returns=serie)))\n",
        "  serie.to_csv('2019-drl{}-{}-{}-{}.csv'.format(window_width, index, reward_function, normalization_function))\n",
        "  #print(pyfolio.timeseries.perf_stats(returns=serie))\n",
        "  pyfolio.create_full_tear_sheet(returns=serie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6ZTJ1HnlEvr"
      },
      "source": [
        "# Ejecución del algoritmo\n",
        "\n",
        "Episodios se pueden modificar\n",
        "\n",
        "Market variables también, pero hay que revisar el DF\n",
        "\n",
        "Indicadores tambien asi se queda\n",
        "\n",
        "Las variables y los indicadores dan como resultado todas las combinaciones\n",
        "\n",
        "Funcion de recompensa puede ser SR y PV\n",
        "\n",
        "Activos\n",
        "\n",
        "Lag\n",
        "\n",
        "A la salida el setting actor output action_std es que hace mas chica la campana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q8BDFx-zCCfI",
        "outputId": "5df2f72e-70b3-4f61-ef69-833c0065f767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33660, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...       atr    boll_ub    boll_lb\n",
            "0    2017-01-02  16.340000  16.660000  ...  2.691708  14.509286  13.709918\n",
            "0    2017-01-02  27.900000  27.959999  ...  2.696893  14.509286  13.709918\n",
            "0    2017-01-02  16.403706  16.665527  ...  2.593767  14.404326  13.834863\n",
            "0    2017-01-02  18.012772  18.031555  ...  2.598404  14.395791  13.891929\n",
            "0    2017-01-02  27.850000  28.610001  ...  2.558020  14.356648  13.912230\n",
            "..          ...        ...        ...  ...       ...        ...        ...\n",
            "499  2018-12-28  31.170000  31.540001  ...  1.898186  20.701950  19.320025\n",
            "499  2018-12-28  26.035000  26.740000  ...  1.936032  20.806097  19.268335\n",
            "499  2018-12-28   9.170000   9.300000  ...  1.909810  20.839428  19.260774\n",
            "499  2018-12-28  50.310001  51.200001  ...  1.929930  20.926680  19.315670\n",
            "499  2018-12-28   8.590000   8.930000  ...  1.944705  21.132474  19.249850\n",
            "\n",
            "[22500 rows x 19 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=585, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=128, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=585, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2019-01-02  0.001513  0.000546  0.001030  ...  0.002531  0.000547  0.002560\n",
            "2019-01-03  0.003034  0.000276  0.000782  ...  0.001766  0.001026  0.002018\n",
            "2019-01-04  0.002581  0.000262  0.000417  ...  0.002398  0.000272  0.001404\n",
            "2019-01-07  0.003874  0.000302  0.000233  ...  0.002519  0.000543  0.006502\n",
            "2019-01-08  0.002131  0.000531  0.000979  ...  0.002083  0.000201  0.004121\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2019-12-19  0.005523  0.000445  0.000495  ...  0.003778  0.000299  0.002904\n",
            "2019-12-20  0.000719  0.000496  0.000885  ...  0.005908  0.000617  0.001777\n",
            "2019-12-23  0.002490  0.000779  0.001282  ...  0.005787  0.000317  0.004720\n",
            "2019-12-26  0.001533  0.000506  0.000891  ...  0.006386  0.000326  0.003708\n",
            "2019-12-27  0.001952  0.001264  0.001232  ...  0.004429  0.000620  0.001142\n",
            "\n",
            "[247 rows x 45 columns]\n",
            "date\n",
            "2019-01-02 00:00:00+00:00    0.000000\n",
            "2019-01-03 00:00:00+00:00    0.013373\n",
            "2019-01-04 00:00:00+00:00    0.006413\n",
            "2019-01-07 00:00:00+00:00   -0.007260\n",
            "2019-01-08 00:00:00+00:00    0.003493\n",
            "                               ...   \n",
            "2019-12-19 00:00:00+00:00    0.007064\n",
            "2019-12-20 00:00:00+00:00    0.002738\n",
            "2019-12-23 00:00:00+00:00    0.011401\n",
            "2019-12-26 00:00:00+00:00    0.016325\n",
            "2019-12-27 00:00:00+00:00   -0.003803\n",
            "Name: daily_return, Length: 247, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2019-01-02</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2019-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>45.074%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>44.007%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>17.308%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>2.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>5.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-8.237%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>3.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>-0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>1.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.027%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.24</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>2019-03-27</td>\n",
              "      <td>2019-06-07</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.46</td>\n",
              "      <td>2019-08-09</td>\n",
              "      <td>2019-08-26</td>\n",
              "      <td>2019-09-12</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.01</td>\n",
              "      <td>2019-02-04</td>\n",
              "      <td>2019-03-07</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.39</td>\n",
              "      <td>2019-09-20</td>\n",
              "      <td>2019-10-08</td>\n",
              "      <td>2019-10-16</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.35</td>\n",
              "      <td>2019-07-10</td>\n",
              "      <td>2019-07-25</td>\n",
              "      <td>2019-08-08</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.15%</td>\n",
              "      <td>-3.67%</td>\n",
              "      <td>3.02%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33660, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...    boll_ub    boll_lb      rsi_14\n",
            "0    2017-01-02  16.340000  16.660000  ...  14.509288  13.709917  100.000000\n",
            "0    2017-01-02  27.900000  27.959999  ...  14.509288  13.709917  100.000000\n",
            "0    2017-01-02  16.403706  16.665527  ...  14.404327  13.834862   70.213043\n",
            "0    2017-01-02  18.012772  18.031555  ...  14.395791  13.891929   75.626056\n",
            "0    2017-01-02  27.850000  28.610001  ...  14.356649  13.912230   57.976254\n",
            "..          ...        ...        ...  ...        ...        ...         ...\n",
            "499  2018-12-28  31.170000  31.540001  ...  20.701955  19.320024   52.664379\n",
            "499  2018-12-28  26.035000  26.740000  ...  20.806102  19.268334   61.377954\n",
            "499  2018-12-28   9.170000   9.300000  ...  20.839434  19.260774   56.868502\n",
            "499  2018-12-28  50.310001  51.200001  ...  20.926684  19.315670   60.361154\n",
            "499  2018-12-28   8.590000   8.930000  ...  21.132478  19.249851   63.895282\n",
            "\n",
            "[22500 rows x 13 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=315, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=128, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=315, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2019-01-02  0.001513  0.000546  0.001030  ...  0.002531  0.000547  0.002560\n",
            "2019-01-03  0.000728  0.000376  0.000227  ...  0.003942  0.001553  0.002978\n",
            "2019-01-04  0.002107  0.000290  0.000388  ...  0.004123  0.000938  0.003129\n",
            "2019-01-07  0.001286  0.000606  0.003137  ...  0.003834  0.000618  0.001912\n",
            "2019-01-08  0.000643  0.000149  0.000322  ...  0.003317  0.000702  0.003350\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2019-12-19  0.000643  0.000390  0.000656  ...  0.003423  0.002491  0.000806\n",
            "2019-12-20  0.001481  0.000603  0.001022  ...  0.006985  0.000728  0.000927\n",
            "2019-12-23  0.001072  0.000889  0.003474  ...  0.003549  0.000586  0.002310\n",
            "2019-12-26  0.001219  0.000903  0.001510  ...  0.007469  0.001257  0.002284\n",
            "2019-12-27  0.001810  0.001673  0.000824  ...  0.010440  0.000914  0.001435\n",
            "\n",
            "[247 rows x 45 columns]\n",
            "date\n",
            "2019-01-02 00:00:00+00:00    0.000000\n",
            "2019-01-03 00:00:00+00:00    0.013373\n",
            "2019-01-04 00:00:00+00:00    0.005675\n",
            "2019-01-07 00:00:00+00:00   -0.006496\n",
            "2019-01-08 00:00:00+00:00    0.004863\n",
            "                               ...   \n",
            "2019-12-19 00:00:00+00:00    0.006464\n",
            "2019-12-20 00:00:00+00:00    0.001633\n",
            "2019-12-23 00:00:00+00:00    0.010826\n",
            "2019-12-26 00:00:00+00:00    0.014565\n",
            "2019-12-27 00:00:00+00:00   -0.002648\n",
            "Name: daily_return, Length: 247, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2019-01-02</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2019-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>45.937%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>44.846%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>17.056%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>2.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>5.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-8.262%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>3.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>-0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-1.993%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.26</td>\n",
              "      <td>2019-07-10</td>\n",
              "      <td>2019-08-26</td>\n",
              "      <td>2019-09-20</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.07</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>2019-03-27</td>\n",
              "      <td>2019-05-31</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.79</td>\n",
              "      <td>2019-02-05</td>\n",
              "      <td>2019-03-07</td>\n",
              "      <td>2019-03-15</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.47</td>\n",
              "      <td>2019-09-20</td>\n",
              "      <td>2019-10-08</td>\n",
              "      <td>2019-10-16</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.09</td>\n",
              "      <td>2019-11-07</td>\n",
              "      <td>2019-11-13</td>\n",
              "      <td>2019-11-22</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.16%</td>\n",
              "      <td>-3.68%</td>\n",
              "      <td>2.86%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33660, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...       atr    boll_ub    boll_lb\n",
            "0    2017-01-02  16.340000  16.660000  ...  2.691708  14.509286  13.709918\n",
            "0    2017-01-02  27.900000  27.959999  ...  2.696893  14.509286  13.709918\n",
            "0    2017-01-02  16.403706  16.665527  ...  2.593767  14.404325  13.834863\n",
            "0    2017-01-02  18.012772  18.031555  ...  2.598405  14.395789  13.891929\n",
            "0    2017-01-02  27.850000  28.610001  ...  2.558021  14.356647  13.912230\n",
            "..          ...        ...        ...  ...       ...        ...        ...\n",
            "499  2018-12-28  31.170000  31.540001  ...  1.898186  20.701952  19.320023\n",
            "499  2018-12-28  26.035000  26.740000  ...  1.936032  20.806097  19.268334\n",
            "499  2018-12-28   9.170000   9.300000  ...  1.909810  20.839429  19.260773\n",
            "499  2018-12-28  50.310001  51.200001  ...  1.929930  20.926679  19.315669\n",
            "499  2018-12-28   8.590000   8.930000  ...  1.944706  21.132473  19.249850\n",
            "\n",
            "[22500 rows x 19 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=495, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=128, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=495, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2019-01-02  0.001513  0.000546  0.001030  ...  0.002531  0.000547  0.002560\n",
            "2019-01-03  0.001444  0.000941  0.000429  ...  0.002582  0.000193  0.003536\n",
            "2019-01-04  0.000943  0.000421  0.001354  ...  0.001168  0.000768  0.002861\n",
            "2019-01-07  0.001389  0.000466  0.000488  ...  0.001467  0.001022  0.002698\n",
            "2019-01-08  0.001820  0.000895  0.000751  ...  0.000872  0.000134  0.004180\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2019-12-19  0.000663  0.000399  0.000607  ...  0.001172  0.000491  0.003702\n",
            "2019-12-20  0.001853  0.000428  0.001489  ...  0.003688  0.000815  0.001644\n",
            "2019-12-23  0.000775  0.001008  0.000771  ...  0.001786  0.001003  0.006690\n",
            "2019-12-26  0.001768  0.000877  0.000955  ...  0.001465  0.001130  0.004082\n",
            "2019-12-27  0.001177  0.000562  0.000728  ...  0.001818  0.001007  0.003264\n",
            "\n",
            "[247 rows x 45 columns]\n",
            "date\n",
            "2019-01-02 00:00:00+00:00    0.000000\n",
            "2019-01-03 00:00:00+00:00    0.013373\n",
            "2019-01-04 00:00:00+00:00    0.004925\n",
            "2019-01-07 00:00:00+00:00   -0.007344\n",
            "2019-01-08 00:00:00+00:00    0.004955\n",
            "                               ...   \n",
            "2019-12-19 00:00:00+00:00    0.006285\n",
            "2019-12-20 00:00:00+00:00    0.000375\n",
            "2019-12-23 00:00:00+00:00    0.009286\n",
            "2019-12-26 00:00:00+00:00    0.015190\n",
            "2019-12-27 00:00:00+00:00   -0.002864\n",
            "Name: daily_return, Length: 247, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2019-01-02</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2019-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>46.477%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>45.372%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>16.964%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>2.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>5.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-8.006%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>3.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>-0.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>1.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-1.98%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.01</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>2019-03-27</td>\n",
              "      <td>2019-05-29</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.95</td>\n",
              "      <td>2019-08-09</td>\n",
              "      <td>2019-08-26</td>\n",
              "      <td>2019-09-18</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.43</td>\n",
              "      <td>2019-02-04</td>\n",
              "      <td>2019-03-07</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.25</td>\n",
              "      <td>2019-09-20</td>\n",
              "      <td>2019-10-08</td>\n",
              "      <td>2019-10-16</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.11</td>\n",
              "      <td>2019-07-10</td>\n",
              "      <td>2019-08-05</td>\n",
              "      <td>2019-08-09</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.16%</td>\n",
              "      <td>-3.67%</td>\n",
              "      <td>3.03%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33660, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...    boll_ub    boll_lb      rsi_14\n",
            "0    2017-01-02  16.340000  16.660000  ...  14.509289  13.709915  100.000000\n",
            "0    2017-01-02  27.900000  27.959999  ...  14.509289  13.709915  100.000000\n",
            "0    2017-01-02  16.403706  16.665527  ...  14.404327  13.834861   70.212934\n",
            "0    2017-01-02  18.012772  18.031555  ...  14.395791  13.891928   75.625891\n",
            "0    2017-01-02  27.850000  28.610001  ...  14.356648  13.912229   57.976474\n",
            "..          ...        ...        ...  ...        ...        ...         ...\n",
            "499  2018-12-28  31.170000  31.540001  ...  20.701953  19.320025   52.664405\n",
            "499  2018-12-28  26.035000  26.740000  ...  20.806099  19.268336   61.377895\n",
            "499  2018-12-28   9.170000   9.300000  ...  20.839430  19.260776   56.868410\n",
            "499  2018-12-28  50.310001  51.200001  ...  20.926682  19.315671   60.361158\n",
            "499  2018-12-28   8.590000   8.930000  ...  21.132475  19.249852   63.895194\n",
            "\n",
            "[22500 rows x 13 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=225, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=128, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=225, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2019-01-02  0.001513  0.000546  0.001030  ...  0.002531  0.000547  0.002560\n",
            "2019-01-03  0.000498  0.000515  0.000480  ...  0.001812  0.000502  0.002319\n",
            "2019-01-04  0.001673  0.000817  0.001428  ...  0.001684  0.000661  0.000983\n",
            "2019-01-07  0.001946  0.001037  0.000639  ...  0.002201  0.000641  0.001807\n",
            "2019-01-08  0.000873  0.000820  0.000482  ...  0.001611  0.000736  0.001276\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2019-12-19  0.000825  0.000569  0.001360  ...  0.002214  0.000355  0.001447\n",
            "2019-12-20  0.002459  0.000640  0.000652  ...  0.002355  0.000627  0.002140\n",
            "2019-12-23  0.001090  0.001658  0.001164  ...  0.003242  0.001409  0.002287\n",
            "2019-12-26  0.000892  0.001210  0.000614  ...  0.005070  0.000959  0.000575\n",
            "2019-12-27  0.001515  0.001145  0.001330  ...  0.003670  0.000700  0.000519\n",
            "\n",
            "[247 rows x 45 columns]\n",
            "date\n",
            "2019-01-02 00:00:00+00:00    0.000000\n",
            "2019-01-03 00:00:00+00:00    0.013373\n",
            "2019-01-04 00:00:00+00:00    0.005081\n",
            "2019-01-07 00:00:00+00:00   -0.007779\n",
            "2019-01-08 00:00:00+00:00    0.004169\n",
            "                               ...   \n",
            "2019-12-19 00:00:00+00:00    0.006164\n",
            "2019-12-20 00:00:00+00:00    0.001614\n",
            "2019-12-23 00:00:00+00:00    0.012777\n",
            "2019-12-26 00:00:00+00:00    0.015675\n",
            "2019-12-27 00:00:00+00:00   -0.003876\n",
            "Name: daily_return, Length: 247, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2019-01-02</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2019-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>49.081%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>47.905%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>17.226%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>2.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>6.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-7.886%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>3.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>-0.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>1.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.006%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.89</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>2019-03-27</td>\n",
              "      <td>2019-05-30</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.02</td>\n",
              "      <td>2019-08-09</td>\n",
              "      <td>2019-08-26</td>\n",
              "      <td>2019-09-12</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.87</td>\n",
              "      <td>2019-02-04</td>\n",
              "      <td>2019-03-07</td>\n",
              "      <td>2019-03-18</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.42</td>\n",
              "      <td>2019-09-20</td>\n",
              "      <td>2019-10-08</td>\n",
              "      <td>2019-10-16</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.57</td>\n",
              "      <td>2019-07-10</td>\n",
              "      <td>2019-08-05</td>\n",
              "      <td>2019-08-09</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.16%</td>\n",
              "      <td>-3.68%</td>\n",
              "      <td>2.79%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "policies = ['MlpPolicy'] #SE QUEDA ASI\n",
        "episodes = [100] #MODIFICABLE, SE QUEDA ASI POR CONEGUNDES\n",
        "\n",
        "market_variables = [['open', 'close', 'volume'], ['volume']] #SE PUEDE PONER EL CIERRE AJUSTADO\n",
        "indicators = [['close_5_sma', 'close_10_sma', 'close_5_ema', 'close_10_ema', 'macd', 'rsi_14', 'cci', 'atr', 'boll_ub', 'boll_lb'],\n",
        "              ['close_20_sma', 'boll_ub', 'boll_lb', 'rsi_14']]\n",
        "\n",
        "\n",
        "reward_function = ['sr'] #SE MODIFICA DE ACUERDO A LA CORRIDA, SE PUEDE CORRER CON ['pv', 'sr']\n",
        "n_steps = [None]\n",
        "normalization_function = [None]\n",
        "\n",
        "#tickers=['PLTR', 'DELL', 'GLW', 'LSPD', 'ST', 'VNT', 'SAIC', 'YALA']\n",
        "#tickers=['ELAT', 'OSH', 'AMWL', 'INSP', 'CTLT', 'BIO', 'TARO', 'BSX', 'AMN', 'TEVA']\n",
        "#tickers=['PDS', 'WLL', 'PBA', 'ALIN-PE', 'EURN', 'XOM', 'TPL', 'DLNG-PA', 'OVV', 'EPD']\n",
        "# 2017\n",
        "#tickers=['ITUB4.SA', 'BBDC4.SA', 'ABEV3.SA', 'PETR4.SA', 'VALE3.SA', 'BRFS3.SA', 'BBAS3.SA', 'ITSA4.SA', 'B3SA3.SA', 'UGPA3.SA']\n",
        "# 2018\n",
        "#tickers=['ITUB4.SA', 'VALE3.SA', 'BBDC4.SA', 'ABEV3.SA', 'PETR4.SA', 'B3SA3.SA', 'ITSA4.SA', 'BBAS3.SA', 'UGPA3.SA', 'BRFS3.SA']\n",
        "# 2019\n",
        "#tickers=['ITUB4.SA', 'VALE3.SA', 'BBDC4.SA', 'PETR4.SA', 'ABEV3.SA', 'BBAS3.SA', 'B3SA3.SA', 'ITSA4.SA', 'LREN3.SA', 'UGPA3.SA']\n",
        "# SP500 - 2020\n",
        "#tickers=['MSFT', 'AAPL']\n",
        "# BOVESPA ETF\n",
        "tickers=['ITUB4.SA','BBDC4.SA','ABEV3.SA', 'PETR4.SA', 'VALE3.SA','PETR3.SA', 'BBAS3.SA', 'ITSA4.SA', 'BRFS3.SA','UGPA3.SA','CIEL3.SA', 'JBSS3.SA','BBSE3.SA','BBDC3.SA','LREN3.SA','CCRO3.SA','RADL3.SA','EMBR3.SA','SANB11.SA','EQTL3.SA','HYPE3.SA','SBSP3.SA','GGBR4.SA','WEGE3.SA','BRKM5.SA','BRML3.SA','CPFE3.SA','CMIG4.SA','EGIE3.SA','KLBN11.SA','CSNA3.SA','CSAN3.SA','RENT3.SA','ELET3.SA','MULT3.SA','BRAP4.SA','QUAL3.SA','MRVE3.SA','ENBR3.SA','CPLE6.SA','GOAU4.SA','CYRE3.SA','USIM5.SA','MRFG3.SA','ECOR3.SA']\n",
        "\n",
        "training_start_date='2017-01-01'\n",
        "training_end_date='2018-12-31'\n",
        "trading_start_date='2019-01-01'\n",
        "trading_end_date='2019-12-31'\n",
        "\n",
        "f= open(\"./out.txt\",\"w+\")\n",
        "f.write(str(tickers) + '\\n')\n",
        "f.write(training_start_date+ '\\n')\n",
        "f.write(training_end_date+ '\\n')\n",
        "f.write(trading_start_date+ '\\n')\n",
        "f.write(trading_end_date+ '\\n\\n')\n",
        "\n",
        "for i, cb in enumerate(itertools.product(policies,\n",
        "                                episodes,\n",
        "                                n_steps,\n",
        "                                market_variables,\n",
        "                                indicators,\n",
        "                                reward_function,\n",
        "                                normalization_function)):\n",
        "  \n",
        "  f.write('CB' + str(i) + '\\n')\n",
        "  f.write('{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n'.format(cb[0],cb[1], cb[2], cb[3], cb[4], cb[5], cb[6]))\n",
        "  train_and_perform(index='CB' + str(i),\n",
        "                    policy=cb[0],\n",
        "                    episodes=cb[1],\n",
        "                    n_steps=None,\n",
        "                    market_variables=cb[3],\n",
        "                    indicators=cb[4],\n",
        "                    reward_function=cb[5],\n",
        "                    normalization_function=cb[6],\n",
        "                    tickers=tickers,\n",
        "                    training_start_date=training_start_date,\n",
        "                    training_end_date=training_end_date,\n",
        "                    trading_start_date=trading_start_date,\n",
        "                    trading_end_date=trading_end_date,\n",
        "                    trading_fee=0,\n",
        "                    file_=f,\n",
        "                    nn_arch='MLP',\n",
        "                    window_width=1) #LAG\n",
        "  f.write('\\n\\n\\n')\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KNP526zy69NK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jvQeBc6SyedA",
        "IxqB2TSe-rZd",
        "J9WZVB3eyjXN",
        "JDfuXELB-0Ob",
        "hKENnzGyiGJ3"
      ],
      "name": "V4_ppo_trading_2_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}