{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvQeBc6SyedA"
      },
      "source": [
        "#INSTALA LIBRERIAS\n",
        "\n",
        "Se descargan librerias de GitHub necesarias para ejecutar el algoritmo, se puede comentariar si se ejecutan varios experimentos, solo correr 1 vez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5oNllgBLECXa"
      },
      "outputs": [],
      "source": [
        "# DESCARGA DE LIBRERIAS\n",
        "#!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git@2070f85cdd4d2cde4c00da98ff01ff448b1e593b --use-deprecated=legacy-resolver\n",
        "#!pip install git+https://github.com/quantopian/pyfolio.git --use-deprecated=legacy-resolver\n",
        "#!pip install yfinance --use-deprecated=legacy-resolver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxqB2TSe-rZd"
      },
      "source": [
        "#Descarga de librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9xZAmbuDXSZ",
        "outputId": "873888b0-7c5e-438d-8c9c-1172f9819b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La creación del directorio ./data falló\n"
          ]
        }
      ],
      "source": [
        "# DESCARGA DE LIBRERIAS 2\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import datetime\n",
        "import os\n",
        "import math\n",
        "\n",
        "from finrl.config import config\n",
        "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
        "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
        "from finrl.preprocessing.data import data_split\n",
        "from finrl.env.env_portfolio import StockPortfolioEnv\n",
        "\n",
        "from finrl.model.models import DRLAgent\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "import yfinance as yf\n",
        "from pandas_datareader import data as pdr\n",
        "\n",
        "import pyfolio\n",
        "from copy import deepcopy\n",
        "\n",
        "  # para usar el sr como reward funct\n",
        "  # Se define el nombre de la carpeta o directorio a crear\n",
        "directorio = \"./data\"\n",
        "try:\n",
        "  os.mkdir(directorio)\n",
        "except OSError:\n",
        "  print(\"La creación del directorio %s falló\" % directorio)\n",
        "else:\n",
        "  print(\"Se ha creado el directorio: %s \" % directorio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9WZVB3eyjXN"
      },
      "source": [
        "# AGENTE\n",
        "\n",
        "En esta sección se configuran los ajustes del agente:\n",
        " - PPO Policy\n",
        " - actor, es la red neuronal (Figura de actor, hasta Miu), es a partir del ELSE\n",
        "        1. cambiar funcion de activación con el mismo numero de capas\n",
        "        2. cambiar optimizador\n",
        "        3. cambiar número de capas (no tienen q ser 64)\n",
        " - critic: Tiene 1 neurona de salida, puede agregarse otra capa de salida\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA6FmNNCoj27",
        "outputId": "da98416e-cde0-4df1-def3-5d632934714e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "Device set to : cpu\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "# AGENT DE APRENDIZAJE POR REFUERZO\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.distributions import Categorical\n",
        "import time\n",
        "\n",
        "################################## set device ##################################\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "# set device to cpu or cuda\n",
        "device = torch.device('cpu')\n",
        "\n",
        "if(torch.cuda.is_available()): \n",
        "    device = torch.device('cuda:0') \n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
        "else:\n",
        "    print(\"Device set to : cpu\")\n",
        "    \n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "################################## PPO Policy ##################################\n",
        "\n",
        "\n",
        "class RolloutBuffer:\n",
        "    def __init__(self):\n",
        "        self.actions = []\n",
        "        self.states = []\n",
        "        self.logprobs = []\n",
        "        self.rewards = []\n",
        "        self.is_terminals = []\n",
        "    \n",
        "\n",
        "    def clear(self):\n",
        "        del self.actions[:]\n",
        "        del self.states[:]\n",
        "        del self.logprobs[:]\n",
        "        del self.rewards[:]\n",
        "        del self.is_terminals[:]\n",
        "\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self,\n",
        "                 state_dim,\n",
        "                 action_dim,\n",
        "                 has_continuous_action_space,\n",
        "                 action_std_init,\n",
        "                 nn_arch,\n",
        "                 kernel_size):\n",
        "        super(ActorCritic, self).__init__()\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_dim = action_dim\n",
        "            #[0.6, 0.6, 0.6]\n",
        "            # Calcular la varianza los precios de cierre historicos de cada activo\n",
        "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
        "\n",
        "        self.nn_arch = nn_arch\n",
        "\n",
        "        # actor\n",
        "        # 1. cambiar funcion de activación con el mismo nuomero de capas\n",
        "        # 2. cambiar optimizador\n",
        "        # 3. cambiar número de capas\n",
        "        if has_continuous_action_space:\n",
        "            if self.nn_arch == 'CNN-MLP':\n",
        "              self.actor = nn.Sequential(\n",
        "                              nn.Linear(state_dim, state_dim),\n",
        "                              nn.AvgPool1d(kernel_size, stride=kernel_size),\n",
        "                              #nn.Conv1d(1, 1, kernel_size, stride=kernel_size),\n",
        "                              #2d, #imprimir diagrama, #downsampling, upsampling\n",
        "                              nn.Linear(int(state_dim / kernel_size), 64),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(64, 64),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(64, action_dim),\n",
        "                              nn.Tanh())\n",
        "    ######################### AQUI SE MODIFICA #############################\n",
        "            else:\n",
        "              self.actor = nn.Sequential(\n",
        "                              nn.Linear(state_dim, 100),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(100, 100),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(100, action_dim),\n",
        "                              nn.Tanh())\n",
        "                              \n",
        "        # critic\n",
        "        if self.nn_arch == 'CNN-MLP':\n",
        "            self.critic = nn.Sequential(\n",
        "                            nn.Linear(state_dim, state_dim),\n",
        "                            nn.AvgPool1d(kernel_size, stride=kernel_size),\n",
        "                            #nn.Conv1d(1, 1, kernel_size, stride=kernel_size),\n",
        "                            nn.Linear(int(state_dim / kernel_size), 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 1))\n",
        "    ######################### AQUI SE MODIFICA #############################\n",
        "        else:\n",
        "          self.critic = nn.Sequential(\n",
        "                          nn.Linear(state_dim, 100),\n",
        "                          nn.Tanh(),\n",
        "                          nn.Linear(100, 100),\n",
        "                          nn.Tanh(),\n",
        "                          nn.Linear(100, 1))\n",
        "                          #nn.Tanh())\n",
        "                \n",
        "        \n",
        "    def set_action_std(self, new_action_std):\n",
        "        #return\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "    \n",
        "\n",
        "    def act(self, state):\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state) #LA SALIDA ES MIU\n",
        "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0) #Calcula la matriz de covarianzas\n",
        "            dist = MultivariateNormal(action_mean, cov_mat) #Genera la matriz de distribución normal con (M,N) o sea la funcion\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "\n",
        "        action = dist.sample() # Genera numeros aleatorios y se los pasa a la funcion de distribucion que se deriva de las medias de las acciones y la matriz de covarianza (dist)\n",
        "        action_logprob = dist.log_prob(action) #La accion es la flechita que sale de N en el diagrama\n",
        "        \n",
        "        return action.detach(), action_logprob.detach()\n",
        "    \n",
        "\n",
        "    def evaluate(self, state, action): #Es similar a actuar, pero evalua que tan buenos son los valores de los estados que se han pronosticado\n",
        "        if self.nn_arch == 'CNN-MLP':\n",
        "          state = state.unsqueeze(0)\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state)\n",
        "            \n",
        "            action_var = self.action_var.expand_as(action_mean)\n",
        "            cov_mat = torch.diag_embed(action_var).to(device)\n",
        "            dist = MultivariateNormal(action_mean, cov_mat)\n",
        "            \n",
        "            # For Single Action Environments.\n",
        "            if self.action_dim == 1:\n",
        "                action = action.reshape(-1, self.action_dim)\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "        state_values = self.critic(state)\n",
        "        \n",
        "        return action_logprobs, state_values, dist_entropy\n",
        "\n",
        "\n",
        "class PPO:\n",
        "    def __init__(self,\n",
        "                 state_dim,\n",
        "                 action_dim,\n",
        "                 lr_actor,\n",
        "                 lr_critic,\n",
        "                 gamma,\n",
        "                 K_epochs,\n",
        "                 eps_clip,\n",
        "                 has_continuous_action_space,\n",
        "                 action_std_init=0.6,\n",
        "                 nn_arch='MLP',\n",
        "                 kernel_size=1):\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_std = action_std_init\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.eps_clip = eps_clip\n",
        "        self.K_epochs = K_epochs\n",
        "        \n",
        "        self.buffer = RolloutBuffer()\n",
        "\n",
        "        self.policy = ActorCritic(state_dim,\n",
        "                                  action_dim,\n",
        "                                  has_continuous_action_space,\n",
        "                                  action_std_init,\n",
        "                                  nn_arch,\n",
        "                                  kernel_size).to(device)\n",
        "        print(self.policy)\n",
        "        self.optimizer = torch.optim.RMSprop([\n",
        "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
        "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
        "                    ])\n",
        "\n",
        "        self.policy_old = ActorCritic(state_dim,\n",
        "                                      action_dim,\n",
        "                                      has_continuous_action_space,\n",
        "                                      action_std_init,\n",
        "                                      nn_arch,\n",
        "                                      kernel_size).to(device)\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "        \n",
        "        self.MseLoss = nn.MSELoss()\n",
        "\n",
        "\n",
        "    def set_action_std(self, new_action_std):\n",
        "        \n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = new_action_std\n",
        "            self.policy.set_action_std(new_action_std)\n",
        "            self.policy_old.set_action_std(new_action_std)\n",
        "        \n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = self.action_std - action_std_decay_rate\n",
        "            self.action_std = round(self.action_std, 4)\n",
        "            if (self.action_std <= min_action_std):\n",
        "                self.action_std = min_action_std\n",
        "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
        "            else:\n",
        "                print(\"setting actor output action_std to : \", self.action_std)\n",
        "            self.set_action_std(self.action_std)\n",
        "\n",
        "        else:\n",
        "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
        "\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def select_action(self, state):\n",
        "        with torch.no_grad():\n",
        "            state = torch.FloatTensor(state).to(device)\n",
        "            state_unsqueeze = state.unsqueeze(0)\n",
        "            action, action_logprob = self.policy_old.act(state_unsqueeze)\n",
        "  \n",
        "        if self.has_continuous_action_space:\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "\n",
        "            return action.detach().cpu().numpy().flatten()\n",
        "        else:\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "\n",
        "            return action.item()\n",
        "\n",
        "\n",
        "    def update(self):\n",
        "      # Monte Carlo estimate of returns\n",
        "      rewards = []\n",
        "      discounted_reward = 0\n",
        "      for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
        "          if is_terminal:\n",
        "              discounted_reward = 0\n",
        "          discounted_reward = reward + (self.gamma * discounted_reward)\n",
        "          rewards.insert(0, discounted_reward)\n",
        "          \n",
        "      # Normalizing the rewards\n",
        "      rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "      rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
        "\n",
        "      # convert list to tensor\n",
        "      old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
        "      old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
        "      old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
        "\n",
        "      \n",
        "      # Optimize policy for K epochs\n",
        "      for _ in range(self.K_epochs):\n",
        "\n",
        "        # Evaluating old actions and values\n",
        "        logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
        "\n",
        "        # match state_values tensor dimensions with rewards tensor\n",
        "        state_values = torch.squeeze(state_values)\n",
        "        \n",
        "        # Finding the ratio (pi_theta / pi_theta__old)\n",
        "        ratios = torch.exp(logprobs - old_logprobs.detach())\n",
        "\n",
        "        # Finding Surrogate Loss\n",
        "        advantages = rewards - state_values.detach()   \n",
        "        surr1 = ratios * advantages\n",
        "        surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
        "\n",
        "        # final loss of clipped objective PPO\n",
        "        loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
        "        \n",
        "        # take gradient step\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.mean().backward()\n",
        "        self.optimizer.step()\n",
        "      # Copy new weights into old policy\n",
        "      self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "      # clear buffer\n",
        "      self.buffer.clear()\n",
        "            \n",
        "    def save(self, checkpoint_path):\n",
        "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
        "   \n",
        "\n",
        "    def load(self, checkpoint_path):\n",
        "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
        "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDfuXELB-0Ob"
      },
      "source": [
        "#PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Td0JBxOpEMtE"
      },
      "outputs": [],
      "source": [
        "class PortfolioAllocation(gym.Env):\n",
        "  passmetadata = {'render.modes': ['human']}\n",
        "\n",
        "  def __init__(self,\n",
        "               df,\n",
        "               stock_dim,\n",
        "               initial_amount,\n",
        "               tech_indicator_list,\n",
        "               market_variables,\n",
        "               reward_function,\n",
        "               day=0,\n",
        "               data_stddev=None,\n",
        "               free_risk_return=None,\n",
        "               data_corr=None,\n",
        "               expected_values=None,\n",
        "               trading_fee=0,\n",
        "               nn_arch='MLP',\n",
        "               window_width=1):\n",
        "    self.df = df\n",
        "    self.stock_dim = stock_dim\n",
        "    self.initial_amount = initial_amount\n",
        "    self.tech_indicator_list = tech_indicator_list\n",
        "    self.day_start = day\n",
        "    self.day = self.day_start\n",
        "    self.market_variables = market_variables\n",
        "    self.reward_function = reward_function\n",
        "    self.window_width = window_width\n",
        "    self.nn_arch = nn_arch\n",
        "\n",
        "    self.setup()\n",
        "\n",
        "    # Reward based on Sharpe Ratio (correlation)\n",
        "    self.expected_values = expected_values\n",
        "    self.data_stddev = data_stddev\n",
        "    self.data_corr = data_corr\n",
        "    self.free_risk_return = free_risk_return\n",
        "\n",
        "    self.trading_fee = trading_fee\n",
        "\n",
        "  def setup(self):\n",
        "    # action_space normalization and shape is self.stock_dim\n",
        "    self.action_space = spaces.Box(low=0, high=1,\n",
        "                                   shape=(self.stock_dim,))\n",
        "    # observation space\n",
        "    shape = (self.stock_dim * (len(self.market_variables) + len(self.tech_indicator_list)) * self.window_width,)\n",
        "\n",
        "    self.observation_space = spaces.Box(low=-0, high=np.inf,\n",
        "                                        shape=shape)\n",
        "\n",
        "    self.reset()\n",
        "\n",
        "  def step(self, actions):\n",
        "    self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
        "\n",
        "    if self.terminal:\n",
        "      #df = pd.DataFrame(self.portfolio_return_memory)\n",
        "      #df.columns = ['daily_return']\n",
        "      return self.state, self.reward, self.terminal, {}\n",
        "    else:\n",
        "      # actions are the portfolio weight\n",
        "      # normalize to sum of 1\n",
        "      weights = self.softmax_normalization(actions) #-> [0.2, 0.7, 0.1] #Los pesos son el capital a destinar de cada uno de los activos, se calculan a paritr de aplicar una normalizacion de tipo softmax a lo que se considera actions\n",
        "      # Acciones son la salida de la N\n",
        "\n",
        "      last_day_memory = self.data\n",
        "\n",
        "      # load next state\n",
        "      self.day += 1\n",
        "      self.state = self._get_state()\n",
        "  \n",
        "      prev_portfolio_value = self.portfolio_value\n",
        "      # [0.2, 0.7, 0.1] * [80, 120] -> [0.2, 0.7, 0.1] * [80, 120, 1] \n",
        "      # 1 am = [1] / [120] = 0.0083 (1dll)\n",
        "      # 2 [0.0083]* [150] = 1.25  (+ 0.25dll)\n",
        "      # 3 am += ([1] * [1.25]) / [150] = \n",
        "      # A [0.5, 0.5] / [120, 80] = 0.0041, 0.0062\n",
        "      # B [0.0041, 0.0062] * [130, 100] = [ 0.54 , 0.62] = 1.16\n",
        "      # C [0.3, 0.7] * [1.16] = [0.384, 0.82] / [130, 100] = [0.00276259, 0.0082] = \n",
        "      self.portfolio_value = sum(self.actions_memory[-1] * self.data.close.values)\n",
        "      self.actions_memory.append(weights*self.portfolio_value / self.data.close.values)\n",
        "      portfolio_return = ((self.portfolio_value / prev_portfolio_value) - 1)\n",
        "\n",
        "      # save into memory\n",
        "      self.portfolio_return_memory.append(portfolio_return)\n",
        "      self.date_memory.append(self.data.date.unique()[0])           \n",
        "      self.asset_memory.append(self.portfolio_value)\n",
        "\n",
        "      # reward\n",
        "\n",
        "      if self.reward_function == 'pv':\n",
        "        self.reward = portfolio_return\n",
        "        #self.reward = portfolio_return\n",
        "      elif self.reward_function == 'sr':\n",
        "        portfolio_risk = self.portfolio_risk(weights, self.data_stddev, self.data_corr)\n",
        "        self.reward = self.sharpeVE_ratio(weights, self.expected_values, portfolio_risk, self.free_risk_return)\n",
        "\n",
        "      return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "  def _get_state(self):\n",
        "    self.data = self.df.loc[self.day,:].sort_values(by=['tic'])\n",
        "\n",
        "    tmp_data = [np.array(self.data[prop])\n",
        "                for prop in self.market_variables + self.tech_indicator_list]\n",
        "\n",
        "    for i in range(1, self.window_width):\n",
        "      data = self.df.loc[self.day - i,:].sort_values(by=['tic'])\n",
        "      tmp_data = tmp_data + [np.array(data[prop])\n",
        "                             for prop in self.market_variables + self.tech_indicator_list]\n",
        "    \n",
        "    state = np.concatenate(tmp_data, axis=0)\n",
        "    return state\n",
        "\n",
        "  def _reset(self):\n",
        "    self.state = self._get_state()\n",
        "    self.terminal = False\n",
        "    # Agregar + 1 en stock_dim 1/(self.stock_dim + 1)\n",
        "    initial_weights = np.array([1/self.stock_dim] * self.stock_dim)\n",
        "    # [.5, .5] * [120, 80] = [0.004, 0.006]* [120, 80] = [0.5, 0.5]\n",
        "    self.portfolio_value = sum((initial_weights / self.data.close.values) * self.data.close.values)\n",
        "\n",
        "    self.portfolio_return_memory = [0]\n",
        "    self.asset_memory = [self.initial_amount]\n",
        "    # agregar + 1\n",
        "    self.actions_memory = [initial_weights / self.data.close.values]\n",
        "    self.date_memory = [self.data.date.unique()[0]] \n",
        "\n",
        "  def reset(self):\n",
        "    self.day = self.day_start\n",
        "    self._reset()\n",
        "    return self.state\n",
        "\n",
        "  def save_asset_memory(self):\n",
        "    date_list = self.date_memory\n",
        "    portfolio_return = self.portfolio_return_memory\n",
        "    df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "    return df_account_value\n",
        "\n",
        "  def save_action_memory(self):\n",
        "    # date and close price length must match actions length\n",
        "    date_list = self.date_memory\n",
        "    df_date = pd.DataFrame(date_list)\n",
        "    df_date.columns = ['date']\n",
        "    \n",
        "    action_list = self.actions_memory\n",
        "    df_actions = pd.DataFrame(action_list)\n",
        "    df_actions.columns = self.data.tic.values\n",
        "    df_actions.index = df_date.date\n",
        "    return df_actions\n",
        "\n",
        "  def render(self, mode='human'):\n",
        "    return self.state\n",
        "\n",
        "  def softmax_normalization(self, actions):\n",
        "    numerator = np.exp(actions)\n",
        "    denominator = np.sum(np.exp(actions))\n",
        "    softmax_output = numerator/denominator\n",
        "    return softmax_output\n",
        "\n",
        "  def _seed(self, seed=None):\n",
        "    self.np_random, seed = seeding.np_random(seed)\n",
        "    return [seed]\n",
        "\n",
        "  def get_sb_env(self):\n",
        "    e = DummyVecEnv([lambda: self])\n",
        "    obs = e.reset()\n",
        "    return e, obs\n",
        "\n",
        "  def portfolio_risk(self, weights, data_stddev, data_corr):\n",
        "    aux_1 = 0\n",
        "    aux_2 = 0\n",
        "    for i in range(len(weights)):\n",
        "        aux_1 += math.pow(weights[i], 2) * math.pow(data_stddev[i], 2)\n",
        "\n",
        "    for i in range(len(weights)):\n",
        "        for j in range(len(weights)):\n",
        "            if i == j:\n",
        "                continue\n",
        "            aux_2 += weights[i] * weights[j] * data_stddev[i] * data_stddev[j] * data_corr.values[i][j]\n",
        "\n",
        "    return np.sqrt(aux_1 + (2 * aux_2))\n",
        "\n",
        "  def sharpeVE_ratio(self, weights, expected_values,\n",
        "                     risk, free_risk_return):\n",
        "    sr = (sum(weights * expected_values * 252) - free_risk_return) / risk\n",
        "    return sr\n",
        "\n",
        "def get_dataframe(tickers, start_date, end_date):\n",
        "    df = YahooDownloader(start_date=start_date,\n",
        "                         end_date=end_date,\n",
        "                         ticker_list=tickers).fetch_data()\n",
        "    return df\n",
        "\n",
        "def retrieve_data_from_yahoo(assets, start_date, end_date, attribute):\n",
        "  '''\n",
        "  -> Example output\n",
        "                  GFNORTEO.MX     BSMXB.MX    ....\n",
        "  Date                              \n",
        "  2019-01-02      93.142639       24.001934\n",
        "  ...\n",
        "  ...\n",
        "  2019-12-31      93.142639       24.001934\n",
        "  '''\n",
        "  df = pd.DataFrame()\n",
        "  for asset in assets:\n",
        "    try:\n",
        "      df_asset = pd.read_csv('./data/{}+[{}]_[{}].csv'.format(asset, start_date, end_date))\n",
        "      df_asset.set_index('Date', inplace=True)\n",
        "    except FileNotFoundError as e:\n",
        "      df_asset = pdr.get_data_yahoo(asset, start=start_date, end=end_date)[attribute]\n",
        "      df_asset = df_asset.to_frame(name=asset)\n",
        "      df_asset.to_csv('./data/{}+[{}]_[{}].csv'.format(asset, start_date, end_date))\n",
        "\n",
        "    df = pd.concat([df, df_asset], axis=1, sort=False)\n",
        "  return df\n",
        "\n",
        "def data_cleaning(dataframe):\n",
        "    df = dataframe.dropna(axis=1, how='all') \n",
        "    df = df.interpolate(limit_direction='both') \n",
        "    return df.sort_index(axis=1), sorted(df.columns)\n",
        "\n",
        "def data_preparation(dataframe, assets):\n",
        "  data_pct_changes = dataframe.pct_change().dropna()\n",
        "  data_covariances = np.cov(data_pct_changes.transpose())\n",
        "  data_stddev = np.array(np.std(data_pct_changes))\n",
        "  data_corr = data_pct_changes.corr()\n",
        "  expected_values = get_expected_values(dataframe, data_pct_changes, assets)\n",
        "\n",
        "  return data_stddev, data_corr, expected_values\n",
        "  #return data_pct_changes, data_covariances, data_stddev, data_corr, expected_values\n",
        "\n",
        "def get_expected_values(data, data_pct_changes, assets):\n",
        "  expected_values = []\n",
        "\n",
        "  for serie in assets:\n",
        "      x, rangos = np.histogram(data_pct_changes[serie], bins=10)\n",
        "      y=[]\n",
        "      for i in range(len(rangos) - 1):\n",
        "          y.append((rangos[i] + rangos[i + 1]) / 2)\n",
        "      p = x / len(data)\n",
        "      expected_value = sum(p * y) \n",
        "      expected_values.append(expected_value)\n",
        "\n",
        "  return np.array(expected_values)\n",
        "\n",
        "def feature_engineering(df, indicators):\n",
        "    fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                        tech_indicator_list=indicators,\n",
        "                        use_turbulence=False,\n",
        "                        user_defined_feature=False)\n",
        "\n",
        "    return fe.preprocess_data(df)\n",
        "\n",
        "def zscore(df, tickers, properties):\n",
        "  df = df.copy()\n",
        "  df = df.sort_values(by=['tic','date'])\n",
        "\n",
        "  for var in properties:\n",
        "      var_df = pd.DataFrame()\n",
        "      for ticker in tickers:\n",
        "          temp_normalized = stats.zscore(df[df.tic == ticker][var])\n",
        "          temp_normalized = pd.DataFrame(temp_normalized, columns=[var+'_zscore'])\n",
        "          temp_normalized['tic'] = ticker\n",
        "          temp_normalized['date'] = df[df.tic == ticker]['date'].to_list()\n",
        "          var_df = var_df.append(\n",
        "              temp_normalized, ignore_index=True\n",
        "          )\n",
        "      df = df.merge(var_df[['tic','date',var+'_zscore']],on=['tic','date'],how='left')\n",
        "  df = df.sort_values(by=['date','tic'])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKENnzGyiGJ3"
      },
      "source": [
        "# Hiperparametros del PPO\n",
        "\n",
        "se crea el agente y el entorno. \n",
        "\n",
        "Se pueden modificar las epocas del PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tv6P9YbTE8Hw"
      },
      "outputs": [],
      "source": [
        "def train_and_perform(index,\n",
        "                      policy,\n",
        "                      episodes,\n",
        "                      n_steps,\n",
        "                      market_variables,\n",
        "                      indicators,\n",
        "                      reward_function,\n",
        "                      normalization_function,\n",
        "                      tickers,\n",
        "                      training_start_date,\n",
        "                      training_end_date,\n",
        "                      trading_start_date,\n",
        "                      trading_end_date,\n",
        "                      trading_fee,\n",
        "                      file_,\n",
        "                      nn_arch='MLP',\n",
        "                      window_width=1):\n",
        "  df = get_dataframe(tickers, training_start_date, trading_end_date)\n",
        "  df['rate open/close'] = df['open']/df['close']\n",
        "  df = feature_engineering(df, indicators)\n",
        "\n",
        "  if not (normalization_function is None):\n",
        "    df = normalization_function(df, tickers, market_variables + indicators)\n",
        "\n",
        "  train_df = data_split(df, training_start_date, training_end_date)\n",
        "  print(train_df)\n",
        "  # calcular vector varianzas de train_df en base a los precios de cierre\n",
        "  trading_df = data_split(df, trading_start_date, trading_end_date)\n",
        "\n",
        "  if reward_function == 'pv':\n",
        "    env_kwargs = {\n",
        "    'initial_amount': 1, \n",
        "    'stock_dim': len(tickers),\n",
        "    'tech_indicator_list': indicators,\n",
        "    'market_variables': market_variables,\n",
        "    'reward_function': reward_function,\n",
        "    'trading_fee': trading_fee,\n",
        "    'nn_arch': nn_arch,\n",
        "    'window_width': window_width,\n",
        "    'day': window_width - 1\n",
        "    }\n",
        "  elif reward_function == 'sr':\n",
        "    yf.pdr_override()\n",
        "\n",
        "    df_adj_close = retrieve_data_from_yahoo(tickers,\n",
        "                                            training_start_date,\n",
        "                                            training_end_date,\n",
        "                                            'Adj Close')\n",
        "    df_adj_close, tickers_adj_close = data_cleaning(df_adj_close)\n",
        "\n",
        "    data_stddev, data_corr, expected_values = data_preparation(df_adj_close, tickers_adj_close)\n",
        "\n",
        "    free_risk_return = 0.015\n",
        "\n",
        "    env_kwargs = {\n",
        "      'initial_amount': 1, \n",
        "      'stock_dim': len(tickers), \n",
        "      'tech_indicator_list': indicators, \n",
        "      'market_variables': market_variables,\n",
        "      'expected_values': expected_values,\n",
        "      'reward_function': reward_function,\n",
        "      'free_risk_return': free_risk_return,\n",
        "      'data_stddev': data_stddev,\n",
        "      'data_corr': data_corr,\n",
        "      'trading_fee': trading_fee,\n",
        "      'nn_arch': nn_arch,\n",
        "      'window_width': window_width,\n",
        "      'day': window_width - 1\n",
        "    }\n",
        "\n",
        "  training_env_gym = PortfolioAllocation(df=train_df, **env_kwargs)\n",
        "  training_env, _ = training_env_gym.get_sb_env()\n",
        "\n",
        "  trading_env_gym = PortfolioAllocation(df=trading_df, **env_kwargs)\n",
        "  trading_env, _ = trading_env_gym.get_sb_env()\n",
        "\n",
        "  ####### initialize environment hyperparameters ######\n",
        "\n",
        "  has_continuous_action_space = True\n",
        "  max_ep_len = len(train_df.date.unique())\n",
        "  max_ep_trading_len = len(trading_df.date.unique())                   \n",
        "  max_training_timesteps = len(train_df.date.unique()) * episodes \n",
        "\n",
        "  print_freq = max_ep_len * 10        # print avg reward in the interval (in num timesteps)\n",
        "  log_freq = max_ep_len * 2           # log avg reward in the interval (in num timesteps)\n",
        "  save_model_freq = int(1e5)          # save model frequency (in num timesteps)\n",
        "\n",
        "  action_std = 0.6                    # starting std for action distribution (Multivariate Normal)\n",
        "  action_std_decay_rate = 0.01        # linearly decay action_std (action_std = action_std - action_std_decay_rate)\n",
        "  min_action_std = 0.1                # minimum action_std (stop decay after action_std <= min_action_std)\n",
        "  action_std_decay_freq = int(5.5e3)  # action_std decay frequency (in num timesteps)\n",
        "  \n",
        "  #####################################################\n",
        "\n",
        "  ################ PPO hyperparameters ################\n",
        "\n",
        "  update_timestep = max_ep_len * 4      # update policy every n timesteps\n",
        "  #update_timestep = int(max_ep_len / 4)\n",
        "  K_epochs = 80               # update policy for K epochs in one PPO update\n",
        "\n",
        "  eps_clip = 0.2          # clip parameter for PPO\n",
        "  gamma = 0.99           # discount factor\n",
        "\n",
        "  lr_actor = 0.0003       # learning rate for actor network\n",
        "  lr_critic = 0.001       # learning rate for critic network\n",
        "\n",
        "  random_seed = 0         # set random seed if required (0 = no random seed)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  # state space dimension\n",
        "  state_dim = training_env.observation_space.shape[0]\n",
        "\n",
        "  # action space dimension\n",
        "  action_dim = training_env.action_space.shape[0]\n",
        "\n",
        "  ppo_agent = PPO(state_dim,\n",
        "                  action_dim, #[0.2, 0.3, 0.5] aunque solamente tengas 2 activos\n",
        "                  lr_actor,\n",
        "                  lr_critic,\n",
        "                  gamma,\n",
        "                  K_epochs,\n",
        "                  eps_clip,\n",
        "                  has_continuous_action_space,\n",
        "                  action_std,\n",
        "                  nn_arch=nn_arch,\n",
        "                  kernel_size=(len(market_variables) + len(indicators)) * window_width)\n",
        "  \n",
        "  # printing and logging variables\n",
        "  print_running_reward = 0\n",
        "  print_running_episodes = 0\n",
        "\n",
        "  time_step = 0\n",
        "  i_episode = 0\n",
        "\n",
        "  ################ Training ################\n",
        "  training_time = time.time()\n",
        "  while time_step <= max_training_timesteps:\n",
        "    state = training_env.reset()\n",
        "    current_ep_reward = 0\n",
        "\n",
        "    for t in range(1, max_ep_len+1):\n",
        "      # select action with policy\n",
        "      action = ppo_agent.select_action(state)\n",
        "      state, reward, done, _ = training_env.step([action])\n",
        "\n",
        "      reward = reward[0]\n",
        "\n",
        "      # saving reward and is_terminals\n",
        "      ppo_agent.buffer.rewards.append(reward)\n",
        "      ppo_agent.buffer.is_terminals.append(done)\n",
        "\n",
        "      time_step +=1\n",
        "      current_ep_reward += reward\n",
        "\n",
        "      # update PPO agent\n",
        "      if time_step % update_timestep == 0:\n",
        "        ppo_agent.update()\n",
        "\n",
        "      # if continuous action space; then decay action std of ouput action distribution\n",
        "      if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
        "        ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
        "\n",
        "      # break; if the episode is over\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    print_running_reward += current_ep_reward\n",
        "    print_running_episodes += 1\n",
        "\n",
        "    i_episode += 1\n",
        "  training_time = time.time() - training_time\n",
        "  print('Training')\n",
        "  \n",
        "  #####################################################\n",
        "\n",
        "  ################ Testing ################\n",
        "\n",
        "  testing_time = 0\n",
        "  df_daily_return = None\n",
        "  total_test_episodes = 15\n",
        "  for ep in range(total_test_episodes):\n",
        "    testing_time_  = time.time()\n",
        "    ep_reward = 0\n",
        "    state = trading_env.reset()\n",
        "\n",
        "    for t in range(max_ep_trading_len):\n",
        "      action = ppo_agent.select_action(state)\n",
        "      state, reward, done, _ = trading_env.step([action])\n",
        "  \n",
        "      reward = reward[0]\n",
        "      ep_reward += reward\n",
        "\n",
        "      if t == max_ep_trading_len - (window_width + 2):\n",
        "        tmp_dr = trading_env.env_method(method_name=\"save_asset_memory\")[0]\n",
        "        actions_memory = trading_env.env_method(method_name=\"save_action_memory\")[0]\n",
        "        if df_daily_return is None:\n",
        "          df_daily_return = tmp_dr\n",
        "        else:\n",
        "          df_daily_return['daily_return'] = df_daily_return['daily_return'] + tmp_dr['daily_return']\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    # clear buffer\n",
        "    ppo_agent.buffer.clear()\n",
        "    testing_time += (time.time() - testing_time_)\n",
        "\n",
        "  print('Testing')\n",
        "  print(actions_memory)\n",
        "  #####################################################\n",
        "\n",
        "  df_daily_return.loc[:,'daily_return'] /= total_test_episodes\n",
        "  df_plot = deepcopy(df_daily_return)\n",
        "  df_plot['date'] = pd.to_datetime(df_plot['date'])\n",
        "  df_plot.set_index(\"date\", inplace=True, drop=True)\n",
        "  df_plot.index = df_plot.index.tz_localize(\"UTC\")\n",
        "\n",
        "  serie = pd.Series(df_plot[\"daily_return\"], index=df_plot.index)\n",
        "  print(serie)\n",
        "  file_.write('training_time {}\\n'.format(training_time))\n",
        "  file_.write('testing_time {}\\n'.format(testing_time))\n",
        "  file_.write(str(pyfolio.timeseries.perf_stats(returns=serie)))\n",
        "  serie.to_csv('2019-drl{}-{}-{}-{}.csv'.format(window_width, index, reward_function, normalization_function))\n",
        "  #print(pyfolio.timeseries.perf_stats(returns=serie))\n",
        "  pyfolio.create_full_tear_sheet(returns=serie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6ZTJ1HnlEvr"
      },
      "source": [
        "# Ejecución del algoritmo\n",
        "\n",
        "Episodios se pueden modificar\n",
        "\n",
        "Market variables también, pero hay que revisar el DF\n",
        "\n",
        "Indicadores tambien asi se queda\n",
        "\n",
        "Las variables y los indicadores dan como resultado todas las combinaciones\n",
        "\n",
        "Funcion de recompensa puede ser SR y PV\n",
        "\n",
        "Activos\n",
        "\n",
        "Lag\n",
        "\n",
        "A la salida el setting actor output action_std es que hace mas chica la campana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q8BDFx-zCCfI",
        "outputId": "534d4208-25a0-47dd-966d-02e92ed3a2ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...       atr    boll_ub    boll_lb\n",
            "0    2016-01-04  17.730000  17.730000  ...  3.509301  14.647764  14.016735\n",
            "0    2016-01-04  14.440000  14.570000  ...  3.400413  14.647764  14.016735\n",
            "0    2016-01-04  10.452175  10.597057  ...  3.269908  14.548198  14.097023\n",
            "0    2016-01-04  10.825763  10.973749  ...  3.199397  14.662571  13.782962\n",
            "0    2016-01-04  23.850000  24.150000  ...  3.217245  14.594391  13.804042\n",
            "..          ...        ...        ...  ...       ...        ...        ...\n",
            "502  2017-12-29  34.330002  34.330002  ...  1.934575  21.228146  19.053770\n",
            "502  2017-12-29  37.500000  37.500000  ...  1.943873  21.318276  18.827588\n",
            "502  2017-12-29   9.100000   9.100000  ...  1.981405  21.291975  18.751094\n",
            "502  2017-12-29  40.259998  40.259998  ...  1.963694  21.247253  18.647671\n",
            "502  2017-12-29   9.273076   9.273076  ...  1.974344  21.140937  18.619446\n",
            "\n",
            "[22635 rows x 19 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=2925, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=2925, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2018-01-08  0.001165  0.000820  0.001269  ...  0.002447  0.000673  0.002483\n",
            "2018-01-09  0.000267  0.000755  0.001587  ...  0.001104  0.000306  0.002681\n",
            "2018-01-10  0.000385  0.001168  0.001075  ...  0.002237  0.000871  0.002665\n",
            "2018-01-11  0.000339  0.000508  0.000875  ...  0.002206  0.000152  0.001880\n",
            "2018-01-12  0.000475  0.000170  0.000931  ...  0.000300  0.000562  0.001512\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2018-12-19  0.000452  0.000441  0.001675  ...  0.001234  0.001077  0.001845\n",
            "2018-12-20  0.001059  0.000818  0.000808  ...  0.001494  0.000827  0.001771\n",
            "2018-12-21  0.001232  0.000829  0.000969  ...  0.001682  0.000369  0.002349\n",
            "2018-12-26  0.001400  0.000612  0.000838  ...  0.002344  0.000419  0.001375\n",
            "2018-12-27  0.000434  0.000200  0.001189  ...  0.003349  0.000506  0.001168\n",
            "\n",
            "[241 rows x 45 columns]\n",
            "date\n",
            "2018-01-08 00:00:00+00:00    0.000000\n",
            "2018-01-09 00:00:00+00:00   -0.006211\n",
            "2018-01-10 00:00:00+00:00   -0.007809\n",
            "2018-01-11 00:00:00+00:00    0.015947\n",
            "2018-01-12 00:00:00+00:00   -0.001243\n",
            "                               ...   \n",
            "2018-12-19 00:00:00+00:00   -0.006153\n",
            "2018-12-20 00:00:00+00:00   -0.005004\n",
            "2018-12-21 00:00:00+00:00    0.002053\n",
            "2018-12-26 00:00:00+00:00   -0.003399\n",
            "2018-12-27 00:00:00+00:00    0.005730\n",
            "Name: daily_return, Length: 241, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2018-01-08</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2018-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>6.284%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>6.001%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>21.888%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>0.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-20.859%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>0.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.724%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.86</td>\n",
              "      <td>2018-02-23</td>\n",
              "      <td>2018-06-18</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.59</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>2018-11-13</td>\n",
              "      <td>2018-12-03</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.35</td>\n",
              "      <td>2018-01-26</td>\n",
              "      <td>2018-02-09</td>\n",
              "      <td>2018-02-21</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.34</td>\n",
              "      <td>2018-12-03</td>\n",
              "      <td>2018-12-26</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.42</td>\n",
              "      <td>2018-01-22</td>\n",
              "      <td>2018-01-23</td>\n",
              "      <td>2018-01-24</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.03%</td>\n",
              "      <td>-4.50%</td>\n",
              "      <td>5.12%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...    boll_ub    boll_lb      rsi_14\n",
            "0    2016-01-04  17.730000  17.730000  ...  14.647763  14.016737  100.000000\n",
            "0    2016-01-04  14.440000  14.570000  ...  14.647763  14.016737  100.000000\n",
            "0    2016-01-04  10.452175  10.597057  ...  14.548197  14.097023   59.592518\n",
            "0    2016-01-04  10.825763  10.973749  ...  14.662572  13.782959   27.367625\n",
            "0    2016-01-04  23.850000  24.150000  ...  14.594392  13.804039   43.189964\n",
            "..          ...        ...        ...  ...        ...        ...         ...\n",
            "502  2017-12-29  34.330002  34.330002  ...  21.228144  19.053773   32.104796\n",
            "502  2017-12-29  37.500000  37.500000  ...  21.318274  18.827592   36.519869\n",
            "502  2017-12-29   9.100000   9.100000  ...  21.291973  18.751098   46.509119\n",
            "502  2017-12-29  40.259998  40.259998  ...  21.247251  18.647675   43.298881\n",
            "502  2017-12-29   9.273076   9.273076  ...  21.140935  18.619450   47.636078\n",
            "\n",
            "[22635 rows x 13 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=1575, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=1575, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2018-01-08  0.001165  0.000820  0.001269  ...  0.002447  0.000673  0.002483\n",
            "2018-01-09  0.001507  0.000605  0.001190  ...  0.002664  0.000671  0.001092\n",
            "2018-01-10  0.000382  0.000217  0.001688  ...  0.002485  0.000354  0.002595\n",
            "2018-01-11  0.002064  0.000633  0.001921  ...  0.001697  0.000205  0.002072\n",
            "2018-01-12  0.000750  0.000297  0.001038  ...  0.001839  0.000826  0.002253\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2018-12-19  0.000833  0.000616  0.001759  ...  0.003716  0.000421  0.002212\n",
            "2018-12-20  0.001694  0.000176  0.001814  ...  0.004517  0.000193  0.002950\n",
            "2018-12-21  0.001381  0.000523  0.001066  ...  0.002229  0.000443  0.005236\n",
            "2018-12-26  0.000282  0.000305  0.000426  ...  0.001902  0.000251  0.002336\n",
            "2018-12-27  0.000596  0.000774  0.001991  ...  0.003404  0.000313  0.002044\n",
            "\n",
            "[241 rows x 45 columns]\n",
            "date\n",
            "2018-01-08 00:00:00+00:00    0.000000\n",
            "2018-01-09 00:00:00+00:00   -0.006211\n",
            "2018-01-10 00:00:00+00:00   -0.008303\n",
            "2018-01-11 00:00:00+00:00    0.016331\n",
            "2018-01-12 00:00:00+00:00   -0.000554\n",
            "                               ...   \n",
            "2018-12-19 00:00:00+00:00   -0.006720\n",
            "2018-12-20 00:00:00+00:00   -0.005668\n",
            "2018-12-21 00:00:00+00:00    0.001443\n",
            "2018-12-26 00:00:00+00:00   -0.004523\n",
            "2018-12-27 00:00:00+00:00    0.004162\n",
            "Name: daily_return, Length: 241, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2018-01-08</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2018-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>4.483%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>4.284%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>21.178%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-20.349%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>0.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.642%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.35</td>\n",
              "      <td>2018-02-23</td>\n",
              "      <td>2018-06-18</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.47</td>\n",
              "      <td>2018-01-26</td>\n",
              "      <td>2018-02-09</td>\n",
              "      <td>2018-02-22</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.21</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>2018-11-13</td>\n",
              "      <td>2018-11-29</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.71</td>\n",
              "      <td>2018-12-03</td>\n",
              "      <td>2018-12-26</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.55</td>\n",
              "      <td>2018-01-22</td>\n",
              "      <td>2018-01-23</td>\n",
              "      <td>2018-01-24</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.03%</td>\n",
              "      <td>-4.25%</td>\n",
              "      <td>4.74%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...       atr    boll_ub    boll_lb\n",
            "0    2016-01-04  17.730000  17.730000  ...  3.509301  14.647766  14.016734\n",
            "0    2016-01-04  14.440000  14.570000  ...  3.400413  14.647766  14.016734\n",
            "0    2016-01-04  10.452175  10.597057  ...  3.269908  14.548199  14.097022\n",
            "0    2016-01-04  10.825763  10.973749  ...  3.199397  14.662573  13.782959\n",
            "0    2016-01-04  23.850000  24.150000  ...  3.217245  14.594393  13.804039\n",
            "..          ...        ...        ...  ...       ...        ...        ...\n",
            "502  2017-12-29  34.330002  34.330002  ...  1.934576  21.228146  19.053769\n",
            "502  2017-12-29  37.500000  37.500000  ...  1.943873  21.318276  18.827588\n",
            "502  2017-12-29   9.100000   9.100000  ...  1.981405  21.291975  18.751093\n",
            "502  2017-12-29  40.259998  40.259998  ...  1.963694  21.247252  18.647671\n",
            "502  2017-12-29   9.273076   9.273076  ...  1.974344  21.140936  18.619448\n",
            "\n",
            "[22635 rows x 19 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=2475, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=2475, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2018-01-08  0.001165  0.000820  0.001269  ...  0.002447  0.000673  0.002483\n",
            "2018-01-09  0.000983  0.001034  0.000947  ...  0.001556  0.000333  0.001972\n",
            "2018-01-10  0.001127  0.001072  0.000793  ...  0.001271  0.000804  0.004115\n",
            "2018-01-11  0.000721  0.000612  0.001861  ...  0.000742  0.000675  0.003323\n",
            "2018-01-12  0.000757  0.001313  0.002625  ...  0.000854  0.000571  0.001460\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2018-12-19  0.003040  0.000174  0.000562  ...  0.001985  0.000466  0.000528\n",
            "2018-12-20  0.002517  0.000552  0.001325  ...  0.001164  0.001838  0.002704\n",
            "2018-12-21  0.003338  0.000765  0.000935  ...  0.002312  0.001090  0.004232\n",
            "2018-12-26  0.002750  0.000289  0.001560  ...  0.001918  0.000585  0.002036\n",
            "2018-12-27  0.001369  0.000599  0.001006  ...  0.002479  0.000304  0.003453\n",
            "\n",
            "[241 rows x 45 columns]\n",
            "date\n",
            "2018-01-08 00:00:00+00:00    0.000000\n",
            "2018-01-09 00:00:00+00:00   -0.006211\n",
            "2018-01-10 00:00:00+00:00   -0.008858\n",
            "2018-01-11 00:00:00+00:00    0.016912\n",
            "2018-01-12 00:00:00+00:00    0.000120\n",
            "                               ...   \n",
            "2018-12-19 00:00:00+00:00   -0.007646\n",
            "2018-12-20 00:00:00+00:00   -0.004746\n",
            "2018-12-21 00:00:00+00:00    0.002307\n",
            "2018-12-26 00:00:00+00:00   -0.004335\n",
            "2018-12-27 00:00:00+00:00    0.003320\n",
            "Name: daily_return, Length: 241, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2018-01-08</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2018-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>6.466%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>6.175%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>21.978%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-20.273%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.735%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.27</td>\n",
              "      <td>2018-02-23</td>\n",
              "      <td>2018-06-18</td>\n",
              "      <td>2018-11-01</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.65</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>2018-11-13</td>\n",
              "      <td>2018-12-03</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.32</td>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>2018-02-09</td>\n",
              "      <td>2018-02-21</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.62</td>\n",
              "      <td>2018-12-03</td>\n",
              "      <td>2018-12-26</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.60</td>\n",
              "      <td>2018-01-22</td>\n",
              "      <td>2018-01-23</td>\n",
              "      <td>2018-01-24</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.03%</td>\n",
              "      <td>-4.43%</td>\n",
              "      <td>5.36%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...    boll_ub    boll_lb      rsi_14\n",
            "0    2016-01-04  17.730000  17.730000  ...  14.647764  14.016735  100.000000\n",
            "0    2016-01-04  14.440000  14.570000  ...  14.647764  14.016735  100.000000\n",
            "0    2016-01-04  10.452175  10.597057  ...  14.548198  14.097023   59.592947\n",
            "0    2016-01-04  10.825763  10.973749  ...  14.662572  13.782958   27.367705\n",
            "0    2016-01-04  23.850000  24.150000  ...  14.594392  13.804040   43.190139\n",
            "..          ...        ...        ...  ...        ...        ...         ...\n",
            "502  2017-12-29  34.330002  34.330002  ...  21.228146  19.053770   32.104686\n",
            "502  2017-12-29  37.500000  37.500000  ...  21.318276  18.827587   36.519713\n",
            "502  2017-12-29   9.100000   9.100000  ...  21.291976  18.751092   46.509081\n",
            "502  2017-12-29  40.259998  40.259998  ...  21.247252  18.647670   43.298836\n",
            "502  2017-12-29   9.273076   9.273076  ...  21.140936  18.619446   47.636152\n",
            "\n",
            "[22635 rows x 13 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=1125, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=1125, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2018-01-08  0.001165  0.000820  0.001269  ...  0.002447  0.000673  0.002483\n",
            "2018-01-09  0.001394  0.001026  0.000367  ...  0.004203  0.001001  0.001350\n",
            "2018-01-10  0.001987  0.000312  0.001450  ...  0.001624  0.001002  0.004008\n",
            "2018-01-11  0.000749  0.001181  0.000608  ...  0.001119  0.001062  0.001093\n",
            "2018-01-12  0.001317  0.000602  0.000754  ...  0.003622  0.001284  0.000707\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2018-12-19  0.000932  0.000216  0.000643  ...  0.002139  0.000944  0.003223\n",
            "2018-12-20  0.002720  0.000412  0.000812  ...  0.005553  0.000395  0.002224\n",
            "2018-12-21  0.001161  0.000148  0.000718  ...  0.005154  0.000478  0.003358\n",
            "2018-12-26  0.001919  0.000527  0.000606  ...  0.003428  0.000452  0.002574\n",
            "2018-12-27  0.002041  0.000526  0.000341  ...  0.003012  0.000715  0.003416\n",
            "\n",
            "[241 rows x 45 columns]\n",
            "date\n",
            "2018-01-08 00:00:00+00:00    0.000000\n",
            "2018-01-09 00:00:00+00:00   -0.006211\n",
            "2018-01-10 00:00:00+00:00   -0.008093\n",
            "2018-01-11 00:00:00+00:00    0.018542\n",
            "2018-01-12 00:00:00+00:00    0.001542\n",
            "                               ...   \n",
            "2018-12-19 00:00:00+00:00   -0.005982\n",
            "2018-12-20 00:00:00+00:00   -0.006432\n",
            "2018-12-21 00:00:00+00:00    0.000978\n",
            "2018-12-26 00:00:00+00:00   -0.004293\n",
            "2018-12-27 00:00:00+00:00    0.002486\n",
            "Name: daily_return, Length: 241, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2018-01-08</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2018-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>5.541%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>5.293%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>22.026%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-19.539%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.744%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.54</td>\n",
              "      <td>2018-02-26</td>\n",
              "      <td>2018-06-18</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.68</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>2018-11-13</td>\n",
              "      <td>2018-12-03</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.19</td>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>2018-02-09</td>\n",
              "      <td>2018-02-21</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.65</td>\n",
              "      <td>2018-12-03</td>\n",
              "      <td>2018-12-26</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.83</td>\n",
              "      <td>2018-01-17</td>\n",
              "      <td>2018-01-23</td>\n",
              "      <td>2018-01-24</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.03%</td>\n",
              "      <td>-4.56%</td>\n",
              "      <td>4.96%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "policies = ['MlpPolicy'] #SE QUEDA ASI\n",
        "episodes = [100] #MODIFICABLE, SE QUEDA ASI POR CONEGUNDES\n",
        "\n",
        "market_variables = [['open', 'close', 'volume'], ['volume']] #SE PUEDE PONER EL CIERRE AJUSTADO\n",
        "indicators = [['close_5_sma', 'close_10_sma', 'close_5_ema', 'close_10_ema', 'macd', 'rsi_14', 'cci', 'atr', 'boll_ub', 'boll_lb'],\n",
        "              ['close_20_sma', 'boll_ub', 'boll_lb', 'rsi_14']]\n",
        "\n",
        "\n",
        "reward_function = ['pv'] #SE MODIFICA DE ACUERDO A LA CORRIDA, SE PUEDE CORRER CON ['pv', 'sr']\n",
        "n_steps = [None]\n",
        "normalization_function = [None]\n",
        "\n",
        "#tickers=['PLTR', 'DELL', 'GLW', 'LSPD', 'ST', 'VNT', 'SAIC', 'YALA']\n",
        "#tickers=['ELAT', 'OSH', 'AMWL', 'INSP', 'CTLT', 'BIO', 'TARO', 'BSX', 'AMN', 'TEVA']\n",
        "#tickers=['PDS', 'WLL', 'PBA', 'ALIN-PE', 'EURN', 'XOM', 'TPL', 'DLNG-PA', 'OVV', 'EPD']\n",
        "# 2017\n",
        "#tickers=['ITUB4.SA', 'BBDC4.SA', 'ABEV3.SA', 'PETR4.SA', 'VALE3.SA', 'BRFS3.SA', 'BBAS3.SA', 'ITSA4.SA', 'B3SA3.SA', 'UGPA3.SA']\n",
        "# 2018\n",
        "#tickers=['ITUB4.SA', 'VALE3.SA', 'BBDC4.SA', 'ABEV3.SA', 'PETR4.SA', 'B3SA3.SA', 'ITSA4.SA', 'BBAS3.SA', 'UGPA3.SA', 'BRFS3.SA']\n",
        "# 2019\n",
        "#tickers=['ITUB4.SA', 'VALE3.SA', 'BBDC4.SA', 'PETR4.SA', 'ABEV3.SA', 'BBAS3.SA', 'B3SA3.SA', 'ITSA4.SA', 'LREN3.SA', 'UGPA3.SA']\n",
        "# SP500 - 2020\n",
        "#tickers=['MSFT', 'AAPL']\n",
        "# BOVESPA ETF\n",
        "tickers=['ITUB4.SA','BBDC4.SA','ABEV3.SA', 'PETR4.SA', 'VALE3.SA','PETR3.SA', 'BBAS3.SA', 'ITSA4.SA', 'BRFS3.SA','UGPA3.SA','CIEL3.SA', 'JBSS3.SA','BBSE3.SA','BBDC3.SA','LREN3.SA','CCRO3.SA','RADL3.SA','EMBR3.SA','SANB11.SA','EQTL3.SA','HYPE3.SA','SBSP3.SA','GGBR4.SA','WEGE3.SA','BRKM5.SA','BRML3.SA','CPFE3.SA','CMIG4.SA','EGIE3.SA','KLBN11.SA','CSNA3.SA','CSAN3.SA','RENT3.SA','ELET3.SA','MULT3.SA','BRAP4.SA','QUAL3.SA','MRVE3.SA','ENBR3.SA','CPLE6.SA','GOAU4.SA','CYRE3.SA','USIM5.SA','MRFG3.SA','ECOR3.SA']\n",
        "\n",
        "training_start_date='2016-01-01'\n",
        "training_end_date='2017-12-31'\n",
        "trading_start_date='2018-01-01'\n",
        "trading_end_date='2018-12-31'\n",
        "\n",
        "f= open(\"./out.txt\",\"w+\")\n",
        "f.write(str(tickers) + '\\n')\n",
        "f.write(training_start_date+ '\\n')\n",
        "f.write(training_end_date+ '\\n')\n",
        "f.write(trading_start_date+ '\\n')\n",
        "f.write(trading_end_date+ '\\n\\n')\n",
        "\n",
        "for i, cb in enumerate(itertools.product(policies,\n",
        "                                episodes,\n",
        "                                n_steps,\n",
        "                                market_variables,\n",
        "                                indicators,\n",
        "                                reward_function,\n",
        "                                normalization_function)):\n",
        "  \n",
        "  f.write('CB' + str(i) + '\\n')\n",
        "  f.write('{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n'.format(cb[0],cb[1], cb[2], cb[3], cb[4], cb[5], cb[6]))\n",
        "  train_and_perform(index='CB' + str(i),\n",
        "                    policy=cb[0],\n",
        "                    episodes=cb[1],\n",
        "                    n_steps=None,\n",
        "                    market_variables=cb[3],\n",
        "                    indicators=cb[4],\n",
        "                    reward_function=cb[5],\n",
        "                    normalization_function=cb[6],\n",
        "                    tickers=tickers,\n",
        "                    training_start_date=training_start_date,\n",
        "                    training_end_date=training_end_date,\n",
        "                    trading_start_date=trading_start_date,\n",
        "                    trading_end_date=trading_end_date,\n",
        "                    trading_fee=0,\n",
        "                    file_=f,\n",
        "                    nn_arch='MLP',\n",
        "                    window_width=5) #LAG\n",
        "  f.write('\\n\\n\\n')\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KNP526zy69NK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jvQeBc6SyedA",
        "IxqB2TSe-rZd",
        "J9WZVB3eyjXN",
        "JDfuXELB-0Ob",
        "hKENnzGyiGJ3"
      ],
      "name": "V4_ppo_trading_2_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}