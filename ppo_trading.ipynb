{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvQeBc6SyedA"
      },
      "source": [
        "#INSTALA LIBRERIAS\n",
        "\n",
        "Se descargan librerias de GitHub necesarias para ejecutar el algoritmo, se puede comentariar si se ejecutan varios experimentos, solo correr 1 vez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5oNllgBLECXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5871da03-db5a-42f7-a2e0-54ce32744e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git@2070f85cdd4d2cde4c00da98ff01ff448b1e593b\n",
            "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git (to revision 2070f85cdd4d2cde4c00da98ff01ff448b1e593b) to /tmp/pip-req-build-9mvlzi55\n",
            "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-9mvlzi55\n",
            "  Running command git rev-parse -q --verify 'sha^2070f85cdd4d2cde4c00da98ff01ff448b1e593b'\n",
            "  Running command git fetch -q https://github.com/AI4Finance-LLC/FinRL-Library.git 2070f85cdd4d2cde4c00da98ff01ff448b1e593b\n",
            "  Running command git checkout -q 2070f85cdd4d2cde4c00da98ff01ff448b1e593b\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (1.21.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (1.3.5)\n",
            "Collecting stockstats\n",
            "  Downloading stockstats-0.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Collecting pyfolio\n",
            "  Downloading pyfolio-0.9.2.tar.gz (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (1.0.2)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (0.17.3)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-1.4.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 38.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (3.6.4)\n",
            "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (0.37.1)\n",
            "Collecting arrow\n",
            "  Downloading arrow-1.2.2-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting python-rapidjson\n",
            "  Downloading python_rapidjson-1.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 42.2 MB/s \n",
            "\u001b[?25hCollecting questionary\n",
            "  Downloading questionary-1.10.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (1.4.31)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (0.8.9)\n",
            "Collecting ccxt\n",
            "  Downloading ccxt-1.74.17-py2.py3-none-any.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 41.6 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (2.8.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (1.5.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->finrl==0.0.3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->finrl==0.0.3) (2.8.2)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 35.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.0.3) (0.0.10)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio->finrl==0.0.3) (5.5.0)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio->finrl==0.0.3) (1.4.1)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio->finrl==0.0.3) (0.11.2)\n",
            "Collecting empyrical>=0.5.0\n",
            "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.0.3) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.0.3) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.0.3) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.0.3) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.0.3) (1.1.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.0.3) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.0.3) (1.5.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (1.10.0+cu111)\n",
            "Requirement already satisfied: opencv-python; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (4.1.2.30)\n",
            "Requirement already satisfied: tensorboard>=2.2.0; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (2.8.0)\n",
            "Requirement already satisfied: pillow; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (7.1.2)\n",
            "Requirement already satisfied: psutil; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (5.4.8)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'atari-py' candidate (version 0.2.6 at https://files.pythonhosted.org/packages/8f/ba/1d22e9d2f332f07aaa57041f5dd569c2cb40a92bd6374a0b743ec3dfae97/atari_py-0.2.6-cp37-cp37m-manylinux1_x86_64.whl#sha256=d9e2c25d39783867c2f29d1dd9d3a659fc56036456d07dc9efe8bd7bb31a07d7 (from https://pypi.org/simple/atari-py/))\n",
            "Reason for being yanked: re-release with new wheels\u001b[0m\n",
            "Collecting atari-py==0.2.6; extra == \"extra\"\n",
            "  Downloading atari_py-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 41.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (21.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (1.11.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (8.12.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from arrow->finrl==0.0.3) (3.10.0.2)\n",
            "Collecting prompt_toolkit<4.0,>=2.0\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[K     |████████████████████████████████| 380 kB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->finrl==0.0.3) (4.11.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->finrl==0.0.3) (1.1.2)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.7/dist-packages (from ccxt->finrl==0.0.3) (2021.10.8)\n",
            "Collecting aiodns>=1.1.1; python_version >= \"3.5.2\"\n",
            "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
            "Collecting yarl==1.7.2; python_version >= \"3.5.2\"\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 63.4 MB/s \n",
            "\u001b[?25hCollecting aiohttp>=3.8; python_version >= \"3.5.2\"\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 49.9 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.6.1\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 36.6 MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 40.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (0.24.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.0.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (13.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (3.3.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.43.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.13.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance->finrl==0.0.3) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance->finrl==0.0.3) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance->finrl==0.0.3) (1.24.3)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (4.8.0)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio->finrl==0.0.3) (0.9.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.0.3) (0.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->finrl==0.0.3) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy->finrl==0.0.3) (3.7.0)\n",
            "Collecting pycares>=4.0.0\n",
            "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
            "\u001b[K     |████████████████████████████████| 291 kB 59.7 MB/s \n",
            "\u001b[?25hCollecting multidict>=4.0\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting asynctest==0.13.0; python_version < \"3.8\"\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 61.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.0.3) (1.15.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->finrl==0.0.3) (1.5.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=3.2.3->pyfolio->finrl==0.0.3) (0.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (4.2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.0.3) (2.21)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.4.8)\n",
            "Building wheels for collected packages: finrl, pyfolio, empyrical\n",
            "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.0.3-py3-none-any.whl size=117219 sha256=2f31df4c0d742dc754cd0b024db2905f8fb7057a9cb08b7e6f9c8ddce215fd38\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b3/33/ac4f66c4d2bf78bb4e478f9ed5e647b08f249b35ee59243a74\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2-py3-none-any.whl size=88682 sha256=564ae85123f31b491c8bc4d555515bcc957a235b74c0a0c7dbdb9125f70ab0f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/96/9b/0dfff5453e702fd780a099b7c850521099c5ec0dfafae189f9\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39780 sha256=e0684eb6c966eced1a47f5004570fbed9519cd4d23d76ce7264c24bff709362f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
            "Successfully built finrl pyfolio empyrical\n",
            "Installing collected packages: stockstats, requests, lxml, yfinance, empyrical, pyfolio, atari-py, stable-baselines3, arrow, python-rapidjson, prompt-toolkit, questionary, pycares, aiodns, multidict, yarl, async-timeout, asynctest, frozenlist, aiosignal, aiohttp, cryptography, ccxt, colorama, finrl, tf-estimator-nightly\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Attempting uninstall: atari-py\n",
            "    Found existing installation: atari-py 0.2.9\n",
            "    Uninstalling atari-py-0.2.9:\n",
            "      Successfully uninstalled atari-py-0.2.9\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.28 which is incompatible.\n",
            "ipython 5.5.0 requires prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 3.0.28 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you'll have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\n",
            "ccxt 1.74.17 requires setuptools>=60.9.0, but you'll have setuptools 57.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed aiodns-3.0.0 aiohttp-3.8.1 aiosignal-1.2.0 arrow-1.2.2 async-timeout-4.0.2 asynctest-0.13.0 atari-py-0.2.6 ccxt-1.74.17 colorama-0.4.4 cryptography-36.0.1 empyrical-0.5.5 finrl-0.0.3 frozenlist-1.3.0 lxml-4.8.0 multidict-6.0.2 prompt-toolkit-3.0.28 pycares-4.1.2 pyfolio-0.9.2 python-rapidjson-1.6 questionary-1.10.0 requests-2.27.1 stable-baselines3-1.4.0 stockstats-0.4.1 tf-estimator-nightly-2.8.0.dev2021122109 yarl-1.7.2 yfinance-0.1.70\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/quantopian/pyfolio.git\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-req-build-9tek8wy0\n",
            "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-req-build-9tek8wy0\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (5.5.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.0.2)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (0.11.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (0.5.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (2.6.1)\n",
            "Collecting prompt-toolkit<2.0.0,>=1.0.4\n",
            "  Downloading prompt_toolkit-1.0.18-py3-none-any.whl (245 kB)\n",
            "\u001b[K     |████████████████████████████████| 245 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (5.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16.1->pyfolio==0.9.2+75.g4b901f6) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16.1->pyfolio==0.9.2+75.g4b901f6) (1.1.0)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (0.9.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.7.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.2.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (4.8.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2021.10.8)\n",
            "Building wheels for collected packages: pyfolio\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75774 sha256=fc928fc52a6c5e3e7c8a0cac6874e0a51bedb2127287fa57d50175620b1fbd7f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nrlip3ur/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
            "Successfully built pyfolio\n",
            "Installing collected packages: pyfolio, prompt-toolkit\n",
            "  Attempting uninstall: pyfolio\n",
            "    Found existing installation: pyfolio 0.9.2\n",
            "    Uninstalling pyfolio-0.9.2:\n",
            "      Successfully uninstalled pyfolio-0.9.2\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 3.0.28\n",
            "    Uninstalling prompt-toolkit-3.0.28:\n",
            "      Successfully uninstalled prompt-toolkit-3.0.28\n",
            "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
            "questionary 1.10.0 requires prompt_toolkit<4.0,>=2.0, but you'll have prompt-toolkit 1.0.18 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you'll have requests 2.27.1 which is incompatible.\u001b[0m\n",
            "Successfully installed prompt-toolkit-1.0.18 pyfolio-0.9.2+75.g4b901f6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.70)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.8.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# DESCARGA DE LIBRERIAS\n",
        "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git@2070f85cdd4d2cde4c00da98ff01ff448b1e593b --use-deprecated=legacy-resolver\n",
        "!pip install git+https://github.com/quantopian/pyfolio.git --use-deprecated=legacy-resolver\n",
        "!pip install yfinance --use-deprecated=legacy-resolver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxqB2TSe-rZd"
      },
      "source": [
        "#Descarga de librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9xZAmbuDXSZ",
        "outputId": "836fbc2a-bdd9-4fe5-f646-8df5115cf903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
            "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se ha creado el directorio: ./data \n"
          ]
        }
      ],
      "source": [
        "# DESCARGA DE LIBRERIAS 2\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import datetime\n",
        "import os\n",
        "import math\n",
        "\n",
        "from finrl.config import config\n",
        "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
        "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
        "from finrl.preprocessing.data import data_split\n",
        "from finrl.env.env_portfolio import StockPortfolioEnv\n",
        "\n",
        "from finrl.model.models import DRLAgent\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "import yfinance as yf\n",
        "from pandas_datareader import data as pdr\n",
        "\n",
        "import pyfolio\n",
        "from copy import deepcopy\n",
        "\n",
        "  # para usar el sr como reward funct\n",
        "  # Se define el nombre de la carpeta o directorio a crear\n",
        "directorio = \"./data\"\n",
        "try:\n",
        "  os.mkdir(directorio)\n",
        "except OSError:\n",
        "  print(\"La creación del directorio %s falló\" % directorio)\n",
        "else:\n",
        "  print(\"Se ha creado el directorio: %s \" % directorio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9WZVB3eyjXN"
      },
      "source": [
        "# AGENTE\n",
        "\n",
        "En esta sección se configuran los ajustes del agente:\n",
        " - PPO Policy\n",
        " - actor, es la red neuronal (Figura de actor, hasta Miu), es a partir del ELSE\n",
        "        1. cambiar funcion de activación con el mismo numero de capas\n",
        "        2. cambiar optimizador\n",
        "        3. cambiar número de capas (no tienen q ser 64)\n",
        " - critic: Tiene 1 neurona de salida, puede agregarse otra capa de salida\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA6FmNNCoj27",
        "outputId": "2a8b3279-71b0-445f-fe34-d66d7de5938e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "Device set to : Tesla T4\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "# AGENT DE APRENDIZAJE POR REFUERZO\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.distributions import Categorical\n",
        "import time\n",
        "\n",
        "################################## set device ##################################\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "# set device to cpu or cuda\n",
        "device = torch.device('cpu')\n",
        "\n",
        "if(torch.cuda.is_available()): \n",
        "    device = torch.device('cuda:0') \n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
        "else:\n",
        "    print(\"Device set to : cpu\")\n",
        "    \n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "################################## PPO Policy ##################################\n",
        "\n",
        "\n",
        "class RolloutBuffer:\n",
        "    def __init__(self):\n",
        "        self.actions = []\n",
        "        self.states = []\n",
        "        self.logprobs = []\n",
        "        self.rewards = []\n",
        "        self.is_terminals = []\n",
        "    \n",
        "\n",
        "    def clear(self):\n",
        "        del self.actions[:]\n",
        "        del self.states[:]\n",
        "        del self.logprobs[:]\n",
        "        del self.rewards[:]\n",
        "        del self.is_terminals[:]\n",
        "\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self,\n",
        "                 state_dim,\n",
        "                 action_dim,\n",
        "                 has_continuous_action_space,\n",
        "                 action_std_init,\n",
        "                 nn_arch,\n",
        "                 kernel_size):\n",
        "        super(ActorCritic, self).__init__()\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_dim = action_dim\n",
        "            #[0.6, 0.6, 0.6]\n",
        "            # Calcular la varianza los precios de cierre historicos de cada activo\n",
        "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
        "\n",
        "        self.nn_arch = nn_arch\n",
        "\n",
        "        # actor\n",
        "        # 1. cambiar funcion de activación con el mismo nuomero de capas\n",
        "        # 2. cambiar optimizador\n",
        "        # 3. cambiar número de capas\n",
        "        if has_continuous_action_space:\n",
        "            if self.nn_arch == 'CNN-MLP':\n",
        "              self.actor = nn.Sequential(\n",
        "                              nn.Linear(state_dim, state_dim),\n",
        "                              nn.AvgPool1d(kernel_size, stride=kernel_size),\n",
        "                              #nn.Conv1d(1, 1, kernel_size, stride=kernel_size),\n",
        "                              #2d, #imprimir diagrama, #downsampling, upsampling\n",
        "                              nn.Linear(int(state_dim / kernel_size), 64),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(64, 64),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(64, action_dim),\n",
        "                              nn.Tanh())\n",
        "    ######################### AQUI SE MODIFICA #############################\n",
        "            else:\n",
        "              self.actor = nn.Sequential(\n",
        "                              nn.Linear(state_dim, 100),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(100, 100),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(100, action_dim),\n",
        "                              nn.Tanh())\n",
        "                              \n",
        "        # critic\n",
        "        if self.nn_arch == 'CNN-MLP':\n",
        "            self.critic = nn.Sequential(\n",
        "                            nn.Linear(state_dim, state_dim),\n",
        "                            nn.AvgPool1d(kernel_size, stride=kernel_size),\n",
        "                            #nn.Conv1d(1, 1, kernel_size, stride=kernel_size),\n",
        "                            nn.Linear(int(state_dim / kernel_size), 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 1))\n",
        "    ######################### AQUI SE MODIFICA #############################\n",
        "        else:\n",
        "          self.critic = nn.Sequential(\n",
        "                          nn.Linear(state_dim, 100),\n",
        "                          nn.Tanh(),\n",
        "                          nn.Linear(100, 100),\n",
        "                          nn.Tanh(),\n",
        "                          nn.Linear(100, 1))\n",
        "                          #nn.Tanh())\n",
        "                \n",
        "        \n",
        "    def set_action_std(self, new_action_std):\n",
        "        #return\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "    \n",
        "\n",
        "    def act(self, state):\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state) #LA SALIDA ES MIU\n",
        "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0) #Calcula la matriz de covarianzas\n",
        "            dist = MultivariateNormal(action_mean, cov_mat) #Genera la matriz de distribución normal con (M,N) o sea la funcion\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "\n",
        "        action = dist.sample() # Genera numeros aleatorios y se los pasa a la funcion de distribucion que se deriva de las medias de las acciones y la matriz de covarianza (dist)\n",
        "        action_logprob = dist.log_prob(action) #La accion es la flechita que sale de N en el diagrama\n",
        "        \n",
        "        return action.detach(), action_logprob.detach()\n",
        "    \n",
        "\n",
        "    def evaluate(self, state, action): #Es similar a actuar, pero evalua que tan buenos son los valores de los estados que se han pronosticado\n",
        "        if self.nn_arch == 'CNN-MLP':\n",
        "          state = state.unsqueeze(0)\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state)\n",
        "            \n",
        "            action_var = self.action_var.expand_as(action_mean)\n",
        "            cov_mat = torch.diag_embed(action_var).to(device)\n",
        "            dist = MultivariateNormal(action_mean, cov_mat)\n",
        "            \n",
        "            # For Single Action Environments.\n",
        "            if self.action_dim == 1:\n",
        "                action = action.reshape(-1, self.action_dim)\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "        state_values = self.critic(state)\n",
        "        \n",
        "        return action_logprobs, state_values, dist_entropy\n",
        "\n",
        "\n",
        "class PPO:\n",
        "    def __init__(self,\n",
        "                 state_dim,\n",
        "                 action_dim,\n",
        "                 lr_actor,\n",
        "                 lr_critic,\n",
        "                 gamma,\n",
        "                 K_epochs,\n",
        "                 eps_clip,\n",
        "                 has_continuous_action_space,\n",
        "                 action_std_init=0.6,\n",
        "                 nn_arch='MLP',\n",
        "                 kernel_size=1):\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_std = action_std_init\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.eps_clip = eps_clip\n",
        "        self.K_epochs = K_epochs\n",
        "        \n",
        "        self.buffer = RolloutBuffer()\n",
        "\n",
        "        self.policy = ActorCritic(state_dim,\n",
        "                                  action_dim,\n",
        "                                  has_continuous_action_space,\n",
        "                                  action_std_init,\n",
        "                                  nn_arch,\n",
        "                                  kernel_size).to(device)\n",
        "        print(self.policy)\n",
        "        self.optimizer = torch.optim.RMSprop([\n",
        "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
        "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
        "                    ])\n",
        "\n",
        "        self.policy_old = ActorCritic(state_dim,\n",
        "                                      action_dim,\n",
        "                                      has_continuous_action_space,\n",
        "                                      action_std_init,\n",
        "                                      nn_arch,\n",
        "                                      kernel_size).to(device)\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "        \n",
        "        self.MseLoss = nn.MSELoss()\n",
        "\n",
        "\n",
        "    def set_action_std(self, new_action_std):\n",
        "        \n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = new_action_std\n",
        "            self.policy.set_action_std(new_action_std)\n",
        "            self.policy_old.set_action_std(new_action_std)\n",
        "        \n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = self.action_std - action_std_decay_rate\n",
        "            self.action_std = round(self.action_std, 4)\n",
        "            if (self.action_std <= min_action_std):\n",
        "                self.action_std = min_action_std\n",
        "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
        "            else:\n",
        "                print(\"setting actor output action_std to : \", self.action_std)\n",
        "            self.set_action_std(self.action_std)\n",
        "\n",
        "        else:\n",
        "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
        "\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def select_action(self, state):\n",
        "        with torch.no_grad():\n",
        "            state = torch.FloatTensor(state).to(device)\n",
        "            state_unsqueeze = state.unsqueeze(0)\n",
        "            action, action_logprob = self.policy_old.act(state_unsqueeze)\n",
        "  \n",
        "        if self.has_continuous_action_space:\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "\n",
        "            return action.detach().cpu().numpy().flatten()\n",
        "        else:\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "\n",
        "            return action.item()\n",
        "\n",
        "\n",
        "    def update(self):\n",
        "      # Monte Carlo estimate of returns\n",
        "      rewards = []\n",
        "      discounted_reward = 0\n",
        "      for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
        "          if is_terminal:\n",
        "              discounted_reward = 0\n",
        "          discounted_reward = reward + (self.gamma * discounted_reward)\n",
        "          rewards.insert(0, discounted_reward)\n",
        "          \n",
        "      # Normalizing the rewards\n",
        "      rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "      rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
        "\n",
        "      # convert list to tensor\n",
        "      old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
        "      old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
        "      old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
        "\n",
        "      \n",
        "      # Optimize policy for K epochs\n",
        "      for _ in range(self.K_epochs):\n",
        "\n",
        "        # Evaluating old actions and values\n",
        "        logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
        "\n",
        "        # match state_values tensor dimensions with rewards tensor\n",
        "        state_values = torch.squeeze(state_values)\n",
        "        \n",
        "        # Finding the ratio (pi_theta / pi_theta__old)\n",
        "        ratios = torch.exp(logprobs - old_logprobs.detach())\n",
        "\n",
        "        # Finding Surrogate Loss\n",
        "        advantages = rewards - state_values.detach()   \n",
        "        surr1 = ratios * advantages\n",
        "        surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
        "\n",
        "        # final loss of clipped objective PPO\n",
        "        loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
        "        \n",
        "        # take gradient step\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.mean().backward()\n",
        "        self.optimizer.step()\n",
        "      # Copy new weights into old policy\n",
        "      self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "      # clear buffer\n",
        "      self.buffer.clear()\n",
        "            \n",
        "    def save(self, checkpoint_path):\n",
        "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
        "   \n",
        "\n",
        "    def load(self, checkpoint_path):\n",
        "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
        "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDfuXELB-0Ob"
      },
      "source": [
        "#PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Td0JBxOpEMtE"
      },
      "outputs": [],
      "source": [
        "class PortfolioAllocation(gym.Env):\n",
        "  passmetadata = {'render.modes': ['human']}\n",
        "\n",
        "  def __init__(self,\n",
        "               df,\n",
        "               stock_dim,\n",
        "               initial_amount,\n",
        "               tech_indicator_list,\n",
        "               market_variables,\n",
        "               reward_function,\n",
        "               day=0,\n",
        "               data_stddev=None,\n",
        "               free_risk_return=None,\n",
        "               data_corr=None,\n",
        "               expected_values=None,\n",
        "               trading_fee=0,\n",
        "               nn_arch='MLP',\n",
        "               window_width=1):\n",
        "    self.df = df\n",
        "    self.stock_dim = stock_dim\n",
        "    self.initial_amount = initial_amount\n",
        "    self.tech_indicator_list = tech_indicator_list\n",
        "    self.day_start = day\n",
        "    self.day = self.day_start\n",
        "    self.market_variables = market_variables\n",
        "    self.reward_function = reward_function\n",
        "    self.window_width = window_width\n",
        "    self.nn_arch = nn_arch\n",
        "\n",
        "    self.setup()\n",
        "\n",
        "    # Reward based on Sharpe Ratio (correlation)\n",
        "    self.expected_values = expected_values\n",
        "    self.data_stddev = data_stddev\n",
        "    self.data_corr = data_corr\n",
        "    self.free_risk_return = free_risk_return\n",
        "\n",
        "    self.trading_fee = trading_fee\n",
        "\n",
        "  def setup(self):\n",
        "    # action_space normalization and shape is self.stock_dim\n",
        "    self.action_space = spaces.Box(low=0, high=1,\n",
        "                                   shape=(self.stock_dim,))\n",
        "    # observation space\n",
        "    shape = (self.stock_dim * (len(self.market_variables) + len(self.tech_indicator_list)) * self.window_width,)\n",
        "\n",
        "    self.observation_space = spaces.Box(low=-0, high=np.inf,\n",
        "                                        shape=shape)\n",
        "\n",
        "    self.reset()\n",
        "\n",
        "  def step(self, actions):\n",
        "    self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
        "\n",
        "    if self.terminal:\n",
        "      #df = pd.DataFrame(self.portfolio_return_memory)\n",
        "      #df.columns = ['daily_return']\n",
        "      return self.state, self.reward, self.terminal, {}\n",
        "    else:\n",
        "      # actions are the portfolio weight\n",
        "      # normalize to sum of 1\n",
        "      weights = self.softmax_normalization(actions) #-> [0.2, 0.7, 0.1] #Los pesos son el capital a destinar de cada uno de los activos, se calculan a paritr de aplicar una normalizacion de tipo softmax a lo que se considera actions\n",
        "      # Acciones son la salida de la N\n",
        "\n",
        "      last_day_memory = self.data\n",
        "\n",
        "      # load next state\n",
        "      self.day += 1\n",
        "      self.state = self._get_state()\n",
        "  \n",
        "      prev_portfolio_value = self.portfolio_value\n",
        "      # [0.2, 0.7, 0.1] * [80, 120] -> [0.2, 0.7, 0.1] * [80, 120, 1] \n",
        "      # 1 am = [1] / [120] = 0.0083 (1dll)\n",
        "      # 2 [0.0083]* [150] = 1.25  (+ 0.25dll)\n",
        "      # 3 am += ([1] * [1.25]) / [150] = \n",
        "      # A [0.5, 0.5] / [120, 80] = 0.0041, 0.0062\n",
        "      # B [0.0041, 0.0062] * [130, 100] = [ 0.54 , 0.62] = 1.16\n",
        "      # C [0.3, 0.7] * [1.16] = [0.384, 0.82] / [130, 100] = [0.00276259, 0.0082] = \n",
        "      self.portfolio_value = sum(self.actions_memory[-1] * self.data.close.values)\n",
        "      self.actions_memory.append(weights*self.portfolio_value / self.data.close.values)\n",
        "      portfolio_return = ((self.portfolio_value / prev_portfolio_value) - 1)\n",
        "\n",
        "      # save into memory\n",
        "      self.portfolio_return_memory.append(portfolio_return)\n",
        "      self.date_memory.append(self.data.date.unique()[0])           \n",
        "      self.asset_memory.append(self.portfolio_value)\n",
        "\n",
        "      # reward\n",
        "\n",
        "      if self.reward_function == 'pv':\n",
        "        self.reward = portfolio_return\n",
        "        #self.reward = portfolio_return\n",
        "      elif self.reward_function == 'sr':\n",
        "        portfolio_risk = self.portfolio_risk(weights, self.data_stddev, self.data_corr)\n",
        "        self.reward = self.sharpeVE_ratio(weights, self.expected_values, portfolio_risk, self.free_risk_return)\n",
        "\n",
        "      return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "  def _get_state(self):\n",
        "    self.data = self.df.loc[self.day,:].sort_values(by=['tic'])\n",
        "\n",
        "    tmp_data = [np.array(self.data[prop])\n",
        "                for prop in self.market_variables + self.tech_indicator_list]\n",
        "\n",
        "    for i in range(1, self.window_width):\n",
        "      data = self.df.loc[self.day - i,:].sort_values(by=['tic'])\n",
        "      tmp_data = tmp_data + [np.array(data[prop])\n",
        "                             for prop in self.market_variables + self.tech_indicator_list]\n",
        "    \n",
        "    state = np.concatenate(tmp_data, axis=0)\n",
        "    return state\n",
        "\n",
        "  def _reset(self):\n",
        "    self.state = self._get_state()\n",
        "    self.terminal = False\n",
        "    # Agregar + 1 en stock_dim 1/(self.stock_dim + 1)\n",
        "    initial_weights = np.array([1/self.stock_dim] * self.stock_dim)\n",
        "    # [.5, .5] * [120, 80] = [0.004, 0.006]* [120, 80] = [0.5, 0.5]\n",
        "    self.portfolio_value = sum((initial_weights / self.data.close.values) * self.data.close.values)\n",
        "\n",
        "    self.portfolio_return_memory = [0]\n",
        "    self.asset_memory = [self.initial_amount]\n",
        "    # agregar + 1\n",
        "    self.actions_memory = [initial_weights / self.data.close.values]\n",
        "    self.date_memory = [self.data.date.unique()[0]] \n",
        "\n",
        "  def reset(self):\n",
        "    self.day = self.day_start\n",
        "    self._reset()\n",
        "    return self.state\n",
        "\n",
        "  def save_asset_memory(self):\n",
        "    date_list = self.date_memory\n",
        "    portfolio_return = self.portfolio_return_memory\n",
        "    df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "    return df_account_value\n",
        "\n",
        "  def save_action_memory(self):\n",
        "    # date and close price length must match actions length\n",
        "    date_list = self.date_memory\n",
        "    df_date = pd.DataFrame(date_list)\n",
        "    df_date.columns = ['date']\n",
        "    \n",
        "    action_list = self.actions_memory\n",
        "    df_actions = pd.DataFrame(action_list)\n",
        "    df_actions.columns = self.data.tic.values\n",
        "    df_actions.index = df_date.date\n",
        "    return df_actions\n",
        "\n",
        "  def render(self, mode='human'):\n",
        "    return self.state\n",
        "\n",
        "  def softmax_normalization(self, actions):\n",
        "    numerator = np.exp(actions)\n",
        "    denominator = np.sum(np.exp(actions))\n",
        "    softmax_output = numerator/denominator\n",
        "    return softmax_output\n",
        "\n",
        "  def _seed(self, seed=None):\n",
        "    self.np_random, seed = seeding.np_random(seed)\n",
        "    return [seed]\n",
        "\n",
        "  def get_sb_env(self):\n",
        "    e = DummyVecEnv([lambda: self])\n",
        "    obs = e.reset()\n",
        "    return e, obs\n",
        "\n",
        "  def portfolio_risk(self, weights, data_stddev, data_corr):\n",
        "    aux_1 = 0\n",
        "    aux_2 = 0\n",
        "    for i in range(len(weights)):\n",
        "        aux_1 += math.pow(weights[i], 2) * math.pow(data_stddev[i], 2)\n",
        "\n",
        "    for i in range(len(weights)):\n",
        "        for j in range(len(weights)):\n",
        "            if i == j:\n",
        "                continue\n",
        "            aux_2 += weights[i] * weights[j] * data_stddev[i] * data_stddev[j] * data_corr.values[i][j]\n",
        "\n",
        "    return np.sqrt(aux_1 + (2 * aux_2))\n",
        "\n",
        "  def sharpeVE_ratio(self, weights, expected_values,\n",
        "                     risk, free_risk_return):\n",
        "    sr = (sum(weights * expected_values * 252) - free_risk_return) / risk\n",
        "    return sr\n",
        "\n",
        "def get_dataframe(tickers, start_date, end_date):\n",
        "    df = YahooDownloader(start_date=start_date,\n",
        "                         end_date=end_date,\n",
        "                         ticker_list=tickers).fetch_data()\n",
        "    return df\n",
        "\n",
        "def retrieve_data_from_yahoo(assets, start_date, end_date, attribute):\n",
        "  '''\n",
        "  -> Example output\n",
        "                  GFNORTEO.MX     BSMXB.MX    ....\n",
        "  Date                              \n",
        "  2019-01-02      93.142639       24.001934\n",
        "  ...\n",
        "  ...\n",
        "  2019-12-31      93.142639       24.001934\n",
        "  '''\n",
        "  df = pd.DataFrame()\n",
        "  for asset in assets:\n",
        "    try:\n",
        "      df_asset = pd.read_csv('./data/{}+[{}]_[{}].csv'.format(asset, start_date, end_date))\n",
        "      df_asset.set_index('Date', inplace=True)\n",
        "    except FileNotFoundError as e:\n",
        "      df_asset = pdr.get_data_yahoo(asset, start=start_date, end=end_date)[attribute]\n",
        "      df_asset = df_asset.to_frame(name=asset)\n",
        "      df_asset.to_csv('./data/{}+[{}]_[{}].csv'.format(asset, start_date, end_date))\n",
        "\n",
        "    df = pd.concat([df, df_asset], axis=1, sort=False)\n",
        "  return df\n",
        "\n",
        "def data_cleaning(dataframe):\n",
        "    df = dataframe.dropna(axis=1, how='all') \n",
        "    df = df.interpolate(limit_direction='both') \n",
        "    return df.sort_index(axis=1), sorted(df.columns)\n",
        "\n",
        "def data_preparation(dataframe, assets):\n",
        "  data_pct_changes = dataframe.pct_change().dropna()\n",
        "  data_covariances = np.cov(data_pct_changes.transpose())\n",
        "  data_stddev = np.array(np.std(data_pct_changes))\n",
        "  data_corr = data_pct_changes.corr()\n",
        "  expected_values = get_expected_values(dataframe, data_pct_changes, assets)\n",
        "\n",
        "  return data_stddev, data_corr, expected_values\n",
        "  #return data_pct_changes, data_covariances, data_stddev, data_corr, expected_values\n",
        "\n",
        "def get_expected_values(data, data_pct_changes, assets):\n",
        "  expected_values = []\n",
        "\n",
        "  for serie in assets:\n",
        "      x, rangos = np.histogram(data_pct_changes[serie], bins=10)\n",
        "      y=[]\n",
        "      for i in range(len(rangos) - 1):\n",
        "          y.append((rangos[i] + rangos[i + 1]) / 2)\n",
        "      p = x / len(data)\n",
        "      expected_value = sum(p * y) \n",
        "      expected_values.append(expected_value)\n",
        "\n",
        "  return np.array(expected_values)\n",
        "\n",
        "def feature_engineering(df, indicators):\n",
        "    fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                        tech_indicator_list=indicators,\n",
        "                        use_turbulence=False,\n",
        "                        user_defined_feature=False)\n",
        "\n",
        "    return fe.preprocess_data(df)\n",
        "\n",
        "def zscore(df, tickers, properties):\n",
        "  df = df.copy()\n",
        "  df = df.sort_values(by=['tic','date'])\n",
        "\n",
        "  for var in properties:\n",
        "      var_df = pd.DataFrame()\n",
        "      for ticker in tickers:\n",
        "          temp_normalized = stats.zscore(df[df.tic == ticker][var])\n",
        "          temp_normalized = pd.DataFrame(temp_normalized, columns=[var+'_zscore'])\n",
        "          temp_normalized['tic'] = ticker\n",
        "          temp_normalized['date'] = df[df.tic == ticker]['date'].to_list()\n",
        "          var_df = var_df.append(\n",
        "              temp_normalized, ignore_index=True\n",
        "          )\n",
        "      df = df.merge(var_df[['tic','date',var+'_zscore']],on=['tic','date'],how='left')\n",
        "  df = df.sort_values(by=['date','tic'])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKENnzGyiGJ3"
      },
      "source": [
        "# Hiperparametros del PPO\n",
        "\n",
        "se crea el agente y el entorno. \n",
        "\n",
        "Se pueden modificar las epocas del PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tv6P9YbTE8Hw"
      },
      "outputs": [],
      "source": [
        "def train_and_perform(index,\n",
        "                      policy,\n",
        "                      episodes,\n",
        "                      n_steps,\n",
        "                      market_variables,\n",
        "                      indicators,\n",
        "                      reward_function,\n",
        "                      normalization_function,\n",
        "                      tickers,\n",
        "                      training_start_date,\n",
        "                      training_end_date,\n",
        "                      trading_start_date,\n",
        "                      trading_end_date,\n",
        "                      trading_fee,\n",
        "                      file_,\n",
        "                      nn_arch='MLP',\n",
        "                      window_width=1):\n",
        "  df = get_dataframe(tickers, training_start_date, trading_end_date)\n",
        "  df['rate open/close'] = df['open']/df['close']\n",
        "  df = feature_engineering(df, indicators)\n",
        "\n",
        "  if not (normalization_function is None):\n",
        "    df = normalization_function(df, tickers, market_variables + indicators)\n",
        "\n",
        "  train_df = data_split(df, training_start_date, training_end_date)\n",
        "  print(train_df)\n",
        "  # calcular vector varianzas de train_df en base a los precios de cierre\n",
        "  trading_df = data_split(df, trading_start_date, trading_end_date)\n",
        "\n",
        "  if reward_function == 'pv':\n",
        "    env_kwargs = {\n",
        "    'initial_amount': 1, \n",
        "    'stock_dim': len(tickers),\n",
        "    'tech_indicator_list': indicators,\n",
        "    'market_variables': market_variables,\n",
        "    'reward_function': reward_function,\n",
        "    'trading_fee': trading_fee,\n",
        "    'nn_arch': nn_arch,\n",
        "    'window_width': window_width,\n",
        "    'day': window_width - 1\n",
        "    }\n",
        "  elif reward_function == 'sr':\n",
        "    yf.pdr_override()\n",
        "\n",
        "    df_adj_close = retrieve_data_from_yahoo(tickers,\n",
        "                                            training_start_date,\n",
        "                                            training_end_date,\n",
        "                                            'Adj Close')\n",
        "    df_adj_close, tickers_adj_close = data_cleaning(df_adj_close)\n",
        "\n",
        "    data_stddev, data_corr, expected_values = data_preparation(df_adj_close, tickers_adj_close)\n",
        "\n",
        "    free_risk_return = 0.015\n",
        "\n",
        "    env_kwargs = {\n",
        "      'initial_amount': 1, \n",
        "      'stock_dim': len(tickers), \n",
        "      'tech_indicator_list': indicators, \n",
        "      'market_variables': market_variables,\n",
        "      'expected_values': expected_values,\n",
        "      'reward_function': reward_function,\n",
        "      'free_risk_return': free_risk_return,\n",
        "      'data_stddev': data_stddev,\n",
        "      'data_corr': data_corr,\n",
        "      'trading_fee': trading_fee,\n",
        "      'nn_arch': nn_arch,\n",
        "      'window_width': window_width,\n",
        "      'day': window_width - 1\n",
        "    }\n",
        "\n",
        "  training_env_gym = PortfolioAllocation(df=train_df, **env_kwargs)\n",
        "  training_env, _ = training_env_gym.get_sb_env()\n",
        "\n",
        "  trading_env_gym = PortfolioAllocation(df=trading_df, **env_kwargs)\n",
        "  trading_env, _ = trading_env_gym.get_sb_env()\n",
        "\n",
        "  ####### initialize environment hyperparameters ######\n",
        "\n",
        "  has_continuous_action_space = True\n",
        "  max_ep_len = len(train_df.date.unique())\n",
        "  max_ep_trading_len = len(trading_df.date.unique())                   \n",
        "  max_training_timesteps = len(train_df.date.unique()) * episodes \n",
        "\n",
        "  print_freq = max_ep_len * 10        # print avg reward in the interval (in num timesteps)\n",
        "  log_freq = max_ep_len * 2           # log avg reward in the interval (in num timesteps)\n",
        "  save_model_freq = int(1e5)          # save model frequency (in num timesteps)\n",
        "\n",
        "  action_std = 0.6                    # starting std for action distribution (Multivariate Normal)\n",
        "  action_std_decay_rate = 0.01        # linearly decay action_std (action_std = action_std - action_std_decay_rate)\n",
        "  min_action_std = 0.1                # minimum action_std (stop decay after action_std <= min_action_std)\n",
        "  action_std_decay_freq = int(5.5e3)  # action_std decay frequency (in num timesteps)\n",
        "  \n",
        "  #####################################################\n",
        "\n",
        "  ################ PPO hyperparameters ################\n",
        "\n",
        "  update_timestep = max_ep_len * 4      # update policy every n timesteps\n",
        "  #update_timestep = int(max_ep_len / 4)\n",
        "  K_epochs = 80               # update policy for K epochs in one PPO update\n",
        "\n",
        "  eps_clip = 0.2          # clip parameter for PPO\n",
        "  gamma = 0.99           # discount factor\n",
        "\n",
        "  lr_actor = 0.0003       # learning rate for actor network\n",
        "  lr_critic = 0.001       # learning rate for critic network\n",
        "\n",
        "  random_seed = 0         # set random seed if required (0 = no random seed)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  # state space dimension\n",
        "  state_dim = training_env.observation_space.shape[0]\n",
        "\n",
        "  # action space dimension\n",
        "  action_dim = training_env.action_space.shape[0]\n",
        "\n",
        "  ppo_agent = PPO(state_dim,\n",
        "                  action_dim, #[0.2, 0.3, 0.5] aunque solamente tengas 2 activos\n",
        "                  lr_actor,\n",
        "                  lr_critic,\n",
        "                  gamma,\n",
        "                  K_epochs,\n",
        "                  eps_clip,\n",
        "                  has_continuous_action_space,\n",
        "                  action_std,\n",
        "                  nn_arch=nn_arch,\n",
        "                  kernel_size=(len(market_variables) + len(indicators)) * window_width)\n",
        "  \n",
        "  # printing and logging variables\n",
        "  print_running_reward = 0\n",
        "  print_running_episodes = 0\n",
        "\n",
        "  time_step = 0\n",
        "  i_episode = 0\n",
        "\n",
        "  ################ Training ################\n",
        "  training_time = time.time()\n",
        "  while time_step <= max_training_timesteps:\n",
        "    state = training_env.reset()\n",
        "    current_ep_reward = 0\n",
        "\n",
        "    for t in range(1, max_ep_len+1):\n",
        "      # select action with policy\n",
        "      action = ppo_agent.select_action(state)\n",
        "      state, reward, done, _ = training_env.step([action])\n",
        "\n",
        "      reward = reward[0]\n",
        "\n",
        "      # saving reward and is_terminals\n",
        "      ppo_agent.buffer.rewards.append(reward)\n",
        "      ppo_agent.buffer.is_terminals.append(done)\n",
        "\n",
        "      time_step +=1\n",
        "      current_ep_reward += reward\n",
        "\n",
        "      # update PPO agent\n",
        "      if time_step % update_timestep == 0:\n",
        "        ppo_agent.update()\n",
        "\n",
        "      # if continuous action space; then decay action std of ouput action distribution\n",
        "      if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
        "        ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
        "\n",
        "      # break; if the episode is over\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    print_running_reward += current_ep_reward\n",
        "    print_running_episodes += 1\n",
        "\n",
        "    i_episode += 1\n",
        "  training_time = time.time() - training_time\n",
        "  print('Training')\n",
        "  \n",
        "  #####################################################\n",
        "\n",
        "  ################ Testing ################\n",
        "\n",
        "  testing_time = 0\n",
        "  df_daily_return = None\n",
        "  total_test_episodes = 15\n",
        "  for ep in range(total_test_episodes):\n",
        "    testing_time_  = time.time()\n",
        "    ep_reward = 0\n",
        "    state = trading_env.reset()\n",
        "\n",
        "    for t in range(max_ep_trading_len):\n",
        "      action = ppo_agent.select_action(state)\n",
        "      state, reward, done, _ = trading_env.step([action])\n",
        "  \n",
        "      reward = reward[0]\n",
        "      ep_reward += reward\n",
        "\n",
        "      if t == max_ep_trading_len - (window_width + 2):\n",
        "        tmp_dr = trading_env.env_method(method_name=\"save_asset_memory\")[0]\n",
        "        actions_memory = trading_env.env_method(method_name=\"save_action_memory\")[0]\n",
        "        if df_daily_return is None:\n",
        "          df_daily_return = tmp_dr\n",
        "        else:\n",
        "          df_daily_return['daily_return'] = df_daily_return['daily_return'] + tmp_dr['daily_return']\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    # clear buffer\n",
        "    ppo_agent.buffer.clear()\n",
        "    testing_time += (time.time() - testing_time_)\n",
        "\n",
        "  print('Testing')\n",
        "  print(actions_memory)\n",
        "  #####################################################\n",
        "\n",
        "  df_daily_return.loc[:,'daily_return'] /= total_test_episodes\n",
        "  df_plot = deepcopy(df_daily_return)\n",
        "  df_plot['date'] = pd.to_datetime(df_plot['date'])\n",
        "  df_plot.set_index(\"date\", inplace=True, drop=True)\n",
        "  df_plot.index = df_plot.index.tz_localize(\"UTC\")\n",
        "\n",
        "  serie = pd.Series(df_plot[\"daily_return\"], index=df_plot.index)\n",
        "  print(serie)\n",
        "  file_.write('training_time {}\\n'.format(training_time))\n",
        "  file_.write('testing_time {}\\n'.format(testing_time))\n",
        "  file_.write(str(pyfolio.timeseries.perf_stats(returns=serie)))\n",
        "  serie.to_csv('2019-drl{}-{}-{}-{}.csv'.format(window_width, index, reward_function, normalization_function))\n",
        "  #print(pyfolio.timeseries.perf_stats(returns=serie))\n",
        "  pyfolio.create_full_tear_sheet(returns=serie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6ZTJ1HnlEvr"
      },
      "source": [
        "# Ejecución del algoritmo\n",
        "\n",
        "Episodios se pueden modificar\n",
        "\n",
        "Market variables también, pero hay que revisar el DF\n",
        "\n",
        "Indicadores tambien asi se queda\n",
        "\n",
        "Las variables y los indicadores dan como resultado todas las combinaciones\n",
        "\n",
        "Funcion de recompensa puede ser SR y PV\n",
        "\n",
        "Activos\n",
        "\n",
        "Lag\n",
        "\n",
        "A la salida el setting actor output action_std es que hace mas chica la campana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q8BDFx-zCCfI",
        "outputId": "6418a5c6-7066-4b39-f756-74b516ac8bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...       atr    boll_ub    boll_lb\n",
            "0    2015-01-02  16.139999  16.559999  ...  4.414464  12.346537  11.724671\n",
            "0    2015-01-02  23.430000  23.670000  ...  4.108538  12.346537  11.724671\n",
            "0    2015-01-02  14.517553  15.148191  ...  4.246774  12.605561  11.695618\n",
            "0    2015-01-02  16.482443  16.833435  ...  4.272575  12.800760  11.702591\n",
            "0    2015-01-02  31.850000  31.900000  ...  4.238547  13.524111  11.403150\n",
            "..          ...        ...        ...  ...       ...        ...        ...\n",
            "494  2016-12-29  28.059999  28.850000  ...  2.531657  13.462506  12.358211\n",
            "494  2016-12-29  33.619999  34.650002  ...  2.511735  13.489896  12.216190\n",
            "494  2016-12-29   4.080000   4.120000  ...  2.491620  13.502216  12.097731\n",
            "494  2016-12-29  26.680000  26.850000  ...  2.485799  13.603888  11.869541\n",
            "494  2016-12-29   5.784615   5.961538  ...  2.504681  13.566197  11.807037\n",
            "\n",
            "[22275 rows x 19 columns]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=2340, out_features=100, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=100, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=2340, out_features=100, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=100, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2017-01-05  0.001563  0.000999  0.001587  ...  0.005394  0.001139  0.004048\n",
            "2017-01-06  0.000958  0.001667  0.000670  ...  0.011695  0.000364  0.003363\n",
            "2017-01-09  0.001985  0.002737  0.000877  ...  0.009556  0.000296  0.002952\n",
            "2017-01-10  0.000682  0.001207  0.000834  ...  0.004541  0.001093  0.002834\n",
            "2017-01-11  0.000810  0.001659  0.000785  ...  0.006172  0.000629  0.003728\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2017-12-22  0.000516  0.000818  0.001732  ...  0.001711  0.001312  0.002061\n",
            "2017-12-25  0.001243  0.001237  0.001395  ...  0.003141  0.000362  0.001689\n",
            "2017-12-26  0.000694  0.000704  0.001244  ...  0.003274  0.001602  0.003319\n",
            "2017-12-27  0.004460  0.001702  0.000645  ...  0.002042  0.000439  0.002160\n",
            "2017-12-28  0.001477  0.000748  0.001480  ...  0.001925  0.000427  0.002021\n",
            "\n",
            "[250 rows x 45 columns]\n",
            "date\n",
            "2017-01-05 00:00:00+00:00    0.000000e+00\n",
            "2017-01-06 00:00:00+00:00   -8.699258e-03\n",
            "2017-01-09 00:00:00+00:00    1.867763e-03\n",
            "2017-01-10 00:00:00+00:00    2.049753e-03\n",
            "2017-01-11 00:00:00+00:00    6.766096e-03\n",
            "                                 ...     \n",
            "2017-12-22 00:00:00+00:00    1.572112e-03\n",
            "2017-12-25 00:00:00+00:00   -4.683168e-08\n",
            "2017-12-26 00:00:00+00:00    8.542932e-03\n",
            "2017-12-27 00:00:00+00:00    7.669323e-03\n",
            "2017-12-28 00:00:00+00:00    4.950861e-03\n",
            "Name: daily_return, Length: 250, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2017-01-05</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2017-12-28</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>23.798%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>23.589%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>19.316%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>1.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>1.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-12.479%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>1.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>-1.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>10.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.341%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.48</td>\n",
              "      <td>2017-02-21</td>\n",
              "      <td>2017-05-18</td>\n",
              "      <td>2017-08-07</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.58</td>\n",
              "      <td>2017-09-18</td>\n",
              "      <td>2017-11-15</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.10</td>\n",
              "      <td>2017-01-26</td>\n",
              "      <td>2017-01-30</td>\n",
              "      <td>2017-02-10</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.80</td>\n",
              "      <td>2017-08-07</td>\n",
              "      <td>2017-08-10</td>\n",
              "      <td>2017-08-22</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.97</td>\n",
              "      <td>2017-01-17</td>\n",
              "      <td>2017-01-19</td>\n",
              "      <td>2017-01-20</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.09%</td>\n",
              "      <td>-8.77%</td>\n",
              "      <td>4.01%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...    boll_ub    boll_lb     rsi_14\n",
            "0    2015-01-02  16.139999  16.559999  ...  12.346535  11.724672   0.000000\n",
            "0    2015-01-02  23.430000  23.670000  ...  12.346535  11.724672   0.000000\n",
            "0    2015-01-02  14.517553  15.148191  ...  12.605561  11.695617  69.022210\n",
            "0    2015-01-02  16.482443  16.833435  ...  12.800762  11.702590  75.891667\n",
            "0    2015-01-02  31.850000  31.900000  ...  13.524114  11.403148  88.159392\n",
            "..          ...        ...        ...  ...        ...        ...        ...\n",
            "494  2016-12-29  28.059999  28.850000  ...  13.462505  12.358212  35.019184\n",
            "494  2016-12-29  33.619999  34.650002  ...  13.489895  12.216191  33.302190\n",
            "494  2016-12-29   4.080000   4.120000  ...  13.502215  12.097732  33.302190\n",
            "494  2016-12-29  26.680000  26.850000  ...  13.603888  11.869541  27.730657\n",
            "494  2016-12-29   5.784615   5.961538  ...  13.566197  11.807036  39.974006\n",
            "\n",
            "[22275 rows x 13 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=1260, out_features=100, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=100, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=1260, out_features=100, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=100, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2017-01-05  0.001563  0.000999  0.001587  ...  0.005394  0.001139  0.004048\n",
            "2017-01-06  0.001018  0.000956  0.001490  ...  0.005121  0.001029  0.003220\n",
            "2017-01-09  0.001869  0.000307  0.000753  ...  0.004415  0.001140  0.002432\n",
            "2017-01-10  0.001533  0.000433  0.003011  ...  0.001674  0.000855  0.002257\n",
            "2017-01-11  0.002278  0.000242  0.002587  ...  0.002425  0.000556  0.006778\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2017-12-22  0.000901  0.001032  0.001111  ...  0.004766  0.001749  0.003035\n",
            "2017-12-25  0.001611  0.000657  0.001713  ...  0.004185  0.001294  0.002873\n",
            "2017-12-26  0.001011  0.000311  0.000615  ...  0.003771  0.000707  0.009917\n",
            "2017-12-27  0.002389  0.000446  0.000822  ...  0.001802  0.000957  0.003300\n",
            "2017-12-28  0.000526  0.000582  0.000920  ...  0.003265  0.000454  0.002731\n",
            "\n",
            "[250 rows x 45 columns]\n",
            "date\n",
            "2017-01-05 00:00:00+00:00    0.000000e+00\n",
            "2017-01-06 00:00:00+00:00   -8.699258e-03\n",
            "2017-01-09 00:00:00+00:00    2.586387e-03\n",
            "2017-01-10 00:00:00+00:00    2.872033e-03\n",
            "2017-01-11 00:00:00+00:00    3.174348e-03\n",
            "                                 ...     \n",
            "2017-12-22 00:00:00+00:00    1.499547e-03\n",
            "2017-12-25 00:00:00+00:00    1.088091e-08\n",
            "2017-12-26 00:00:00+00:00    8.180756e-03\n",
            "2017-12-27 00:00:00+00:00    6.345712e-03\n",
            "2017-12-28 00:00:00+00:00    5.716624e-03\n",
            "Name: daily_return, Length: 250, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2017-01-05</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2017-12-28</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>24.63%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>24.413%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>18.858%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>1.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>2.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-10.832%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>1.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>-1.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>11.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.281%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.83</td>\n",
              "      <td>2017-02-21</td>\n",
              "      <td>2017-05-18</td>\n",
              "      <td>2017-08-07</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.73</td>\n",
              "      <td>2017-09-18</td>\n",
              "      <td>2017-11-14</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.81</td>\n",
              "      <td>2017-01-26</td>\n",
              "      <td>2017-01-30</td>\n",
              "      <td>2017-02-10</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.92</td>\n",
              "      <td>2017-08-07</td>\n",
              "      <td>2017-08-10</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.17</td>\n",
              "      <td>2017-01-17</td>\n",
              "      <td>2017-01-19</td>\n",
              "      <td>2017-01-23</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.09%</td>\n",
              "      <td>-8.79%</td>\n",
              "      <td>2.97%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...       atr    boll_ub    boll_lb\n",
            "0    2015-01-02  16.139999  16.559999  ...  4.414468  12.346532  11.724671\n",
            "0    2015-01-02  23.430000  23.670000  ...  4.108542  12.346532  11.724671\n",
            "0    2015-01-02  14.517553  15.148191  ...  4.246777  12.605562  11.695613\n",
            "0    2015-01-02  16.482443  16.833435  ...  4.272577  12.800763  11.702586\n",
            "0    2015-01-02  31.850000  31.900000  ...  4.238549  13.524114  11.403146\n",
            "..          ...        ...        ...  ...       ...        ...        ...\n",
            "494  2016-12-29  28.059999  28.850000  ...  2.531657  13.462506  12.358211\n",
            "494  2016-12-29  33.619999  34.650002  ...  2.511735  13.489897  12.216189\n",
            "494  2016-12-29   4.080000   4.120000  ...  2.491620  13.502217  12.097730\n",
            "494  2016-12-29  26.680000  26.850000  ...  2.485799  13.603889  11.869540\n",
            "494  2016-12-29   5.784615   5.961538  ...  2.504681  13.566199  11.807035\n",
            "\n",
            "[22275 rows x 19 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=1980, out_features=100, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=100, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=1980, out_features=100, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=100, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2017-01-05  0.001563  0.000999  0.001587  ...  0.005394  0.001139  0.004048\n",
            "2017-01-06  0.002816  0.000842  0.001112  ...  0.012564  0.000568  0.001548\n",
            "2017-01-09  0.003087  0.002535  0.001702  ...  0.011909  0.002198  0.002841\n",
            "2017-01-10  0.001288  0.000816  0.002754  ...  0.003452  0.000604  0.003648\n",
            "2017-01-11  0.001795  0.001085  0.001124  ...  0.004914  0.000522  0.003516\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2017-12-22  0.000985  0.002068  0.000532  ...  0.002857  0.000290  0.006002\n",
            "2017-12-25  0.000853  0.003784  0.003024  ...  0.001614  0.000518  0.005851\n",
            "2017-12-26  0.002631  0.000683  0.000882  ...  0.006041  0.000528  0.002237\n",
            "2017-12-27  0.000467  0.002264  0.002384  ...  0.003177  0.000420  0.004509\n",
            "2017-12-28  0.000792  0.000956  0.000557  ...  0.002259  0.000336  0.008194\n",
            "\n",
            "[250 rows x 45 columns]\n",
            "date\n",
            "2017-01-05 00:00:00+00:00    0.000000e+00\n",
            "2017-01-06 00:00:00+00:00   -8.699248e-03\n",
            "2017-01-09 00:00:00+00:00    7.396003e-04\n",
            "2017-01-10 00:00:00+00:00    1.206147e-03\n",
            "2017-01-11 00:00:00+00:00    4.153006e-03\n",
            "                                 ...     \n",
            "2017-12-22 00:00:00+00:00    1.397617e-03\n",
            "2017-12-25 00:00:00+00:00    8.827555e-09\n",
            "2017-12-26 00:00:00+00:00    8.675554e-03\n",
            "2017-12-27 00:00:00+00:00    6.034290e-03\n",
            "2017-12-28 00:00:00+00:00    5.089511e-03\n",
            "Name: daily_return, Length: 250, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2017-01-05</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2017-12-28</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>25.709%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>25.481%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>19.135%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>1.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>2.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-11.38%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>1.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>-1.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>11.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.313%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.38</td>\n",
              "      <td>2017-02-21</td>\n",
              "      <td>2017-05-18</td>\n",
              "      <td>2017-08-02</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.72</td>\n",
              "      <td>2017-09-18</td>\n",
              "      <td>2017-11-15</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.78</td>\n",
              "      <td>2017-01-26</td>\n",
              "      <td>2017-01-30</td>\n",
              "      <td>2017-02-10</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.83</td>\n",
              "      <td>2017-08-07</td>\n",
              "      <td>2017-08-10</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.09</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>2017-08-17</td>\n",
              "      <td>2017-08-22</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.10%</td>\n",
              "      <td>-8.97%</td>\n",
              "      <td>3.26%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...    boll_ub    boll_lb     rsi_14\n",
            "0    2015-01-02  16.139999  16.559999  ...  12.346536  11.724670   0.000000\n",
            "0    2015-01-02  23.430000  23.670000  ...  12.346536  11.724670   0.000000\n",
            "0    2015-01-02  14.517553  15.148191  ...  12.605564  11.695615  69.022252\n",
            "0    2015-01-02  16.482443  16.833435  ...  12.800760  11.702590  75.891523\n",
            "0    2015-01-02  31.850000  31.900000  ...  13.524114  11.403148  88.159354\n",
            "..          ...        ...        ...  ...        ...        ...        ...\n",
            "494  2016-12-29  28.059999  28.850000  ...  13.462506  12.358211  35.019192\n",
            "494  2016-12-29  33.619999  34.650002  ...  13.489896  12.216190  33.302215\n",
            "494  2016-12-29   4.080000   4.120000  ...  13.502216  12.097730  33.302215\n",
            "494  2016-12-29  26.680000  26.850000  ...  13.603888  11.869540  27.730699\n",
            "494  2016-12-29   5.784615   5.961538  ...  13.566198  11.807035  39.974042\n",
            "\n",
            "[22275 rows x 13 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=900, out_features=100, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=100, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=900, out_features=100, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=100, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2017-01-05  0.001563  0.000999  0.001587  ...  0.005394  0.001139  0.004048\n",
            "2017-01-06  0.001811  0.000319  0.001673  ...  0.003676  0.000411  0.008101\n",
            "2017-01-09  0.000999  0.000176  0.001705  ...  0.001366  0.000395  0.002221\n",
            "2017-01-10  0.000912  0.000386  0.000641  ...  0.006515  0.000693  0.002369\n",
            "2017-01-11  0.001470  0.001271  0.001355  ...  0.003967  0.000472  0.001619\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2017-12-22  0.000608  0.000443  0.000880  ...  0.007247  0.000382  0.002646\n",
            "2017-12-25  0.001555  0.000618  0.001659  ...  0.001679  0.000488  0.002413\n",
            "2017-12-26  0.001197  0.000444  0.000987  ...  0.003930  0.000681  0.000943\n",
            "2017-12-27  0.000779  0.000952  0.001017  ...  0.001248  0.000302  0.002352\n",
            "2017-12-28  0.003067  0.000760  0.000820  ...  0.000654  0.000296  0.002808\n",
            "\n",
            "[250 rows x 45 columns]\n",
            "date\n",
            "2017-01-05 00:00:00+00:00    0.000000e+00\n",
            "2017-01-06 00:00:00+00:00   -8.699215e-03\n",
            "2017-01-09 00:00:00+00:00    2.481557e-03\n",
            "2017-01-10 00:00:00+00:00    1.446974e-03\n",
            "2017-01-11 00:00:00+00:00    3.905378e-03\n",
            "                                 ...     \n",
            "2017-12-22 00:00:00+00:00    1.437108e-03\n",
            "2017-12-25 00:00:00+00:00   -1.161256e-08\n",
            "2017-12-26 00:00:00+00:00    8.254041e-03\n",
            "2017-12-27 00:00:00+00:00    6.226258e-03\n",
            "2017-12-28 00:00:00+00:00    6.511827e-03\n",
            "Name: daily_return, Length: 250, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2017-01-05</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2017-12-28</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>22.797%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>22.597%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>19.026%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>1.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-12.23%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>1.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>-1.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>11.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.308%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.23</td>\n",
              "      <td>2017-02-21</td>\n",
              "      <td>2017-05-18</td>\n",
              "      <td>2017-08-07</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.66</td>\n",
              "      <td>2017-10-13</td>\n",
              "      <td>2017-11-15</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.47</td>\n",
              "      <td>2017-09-18</td>\n",
              "      <td>2017-09-28</td>\n",
              "      <td>2017-10-13</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.89</td>\n",
              "      <td>2017-01-26</td>\n",
              "      <td>2017-01-30</td>\n",
              "      <td>2017-02-10</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.03</td>\n",
              "      <td>2017-08-07</td>\n",
              "      <td>2017-08-10</td>\n",
              "      <td>2017-08-22</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.09%</td>\n",
              "      <td>-8.83%</td>\n",
              "      <td>3.46%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "policies = ['MlpPolicy'] #SE QUEDA ASI\n",
        "episodes = [100] #MODIFICABLE, SE QUEDA ASI POR CONEGUNDES\n",
        "\n",
        "market_variables = [['open', 'close', 'volume'], ['volume']] #SE PUEDE PONER EL CIERRE AJUSTADO\n",
        "indicators = [['close_5_sma', 'close_10_sma', 'close_5_ema', 'close_10_ema', 'macd', 'rsi_14', 'cci', 'atr', 'boll_ub', 'boll_lb'],\n",
        "              ['close_20_sma', 'boll_ub', 'boll_lb', 'rsi_14']]\n",
        "\n",
        "\n",
        "reward_function = ['pv'] #SE MODIFICA DE ACUERDO A LA CORRIDA, SE PUEDE CORRER CON ['pv', 'sr']\n",
        "n_steps = [None]\n",
        "normalization_function = [None]\n",
        "\n",
        "#tickers=['PLTR', 'DELL', 'GLW', 'LSPD', 'ST', 'VNT', 'SAIC', 'YALA']\n",
        "#tickers=['ELAT', 'OSH', 'AMWL', 'INSP', 'CTLT', 'BIO', 'TARO', 'BSX', 'AMN', 'TEVA']\n",
        "#tickers=['PDS', 'WLL', 'PBA', 'ALIN-PE', 'EURN', 'XOM', 'TPL', 'DLNG-PA', 'OVV', 'EPD']\n",
        "# 2017\n",
        "#tickers=['ITUB4.SA', 'BBDC4.SA', 'ABEV3.SA', 'PETR4.SA', 'VALE3.SA', 'BRFS3.SA', 'BBAS3.SA', 'ITSA4.SA', 'B3SA3.SA', 'UGPA3.SA']\n",
        "# 2018\n",
        "#tickers=['ITUB4.SA', 'VALE3.SA', 'BBDC4.SA', 'ABEV3.SA', 'PETR4.SA', 'B3SA3.SA', 'ITSA4.SA', 'BBAS3.SA', 'UGPA3.SA', 'BRFS3.SA']\n",
        "# 2019\n",
        "#tickers=['ITUB4.SA', 'VALE3.SA', 'BBDC4.SA', 'PETR4.SA', 'ABEV3.SA', 'BBAS3.SA', 'B3SA3.SA', 'ITSA4.SA', 'LREN3.SA', 'UGPA3.SA']\n",
        "# SP500 - 2020\n",
        "#tickers=['MSFT', 'AAPL']\n",
        "# BOVESPA ETF\n",
        "tickers=['ITUB4.SA','BBDC4.SA','ABEV3.SA', 'PETR4.SA', 'VALE3.SA','PETR3.SA', 'BBAS3.SA', 'ITSA4.SA', 'BRFS3.SA','UGPA3.SA','CIEL3.SA', 'JBSS3.SA','BBSE3.SA','BBDC3.SA','LREN3.SA','CCRO3.SA','RADL3.SA','EMBR3.SA','SANB11.SA','EQTL3.SA','HYPE3.SA','SBSP3.SA','GGBR4.SA','WEGE3.SA','BRKM5.SA','BRML3.SA','CPFE3.SA','CMIG4.SA','EGIE3.SA','KLBN11.SA','CSNA3.SA','CSAN3.SA','RENT3.SA','ELET3.SA','MULT3.SA','BRAP4.SA','QUAL3.SA','MRVE3.SA','ENBR3.SA','CPLE6.SA','GOAU4.SA','CYRE3.SA','USIM5.SA','MRFG3.SA','ECOR3.SA']\n",
        "\n",
        "training_start_date='2015-01-01'\n",
        "training_end_date='2016-12-31'\n",
        "trading_start_date='2017-01-01'\n",
        "trading_end_date='2017-12-31'\n",
        "\n",
        "f= open(\"./out.txt\",\"w+\")\n",
        "f.write(str(tickers) + '\\n')\n",
        "f.write(training_start_date+ '\\n')\n",
        "f.write(training_end_date+ '\\n')\n",
        "f.write(trading_start_date+ '\\n')\n",
        "f.write(trading_end_date+ '\\n\\n')\n",
        "\n",
        "for i, cb in enumerate(itertools.product(policies,\n",
        "                                episodes,\n",
        "                                n_steps,\n",
        "                                market_variables,\n",
        "                                indicators,\n",
        "                                reward_function,\n",
        "                                normalization_function)):\n",
        "  \n",
        "  f.write('CB' + str(i) + '\\n')\n",
        "  f.write('{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n'.format(cb[0],cb[1], cb[2], cb[3], cb[4], cb[5], cb[6]))\n",
        "  train_and_perform(index='CB' + str(i),\n",
        "                    policy=cb[0],\n",
        "                    episodes=cb[1],\n",
        "                    n_steps=None,\n",
        "                    market_variables=cb[3],\n",
        "                    indicators=cb[4],\n",
        "                    reward_function=cb[5],\n",
        "                    normalization_function=cb[6],\n",
        "                    tickers=tickers,\n",
        "                    training_start_date=training_start_date,\n",
        "                    training_end_date=training_end_date,\n",
        "                    trading_start_date=trading_start_date,\n",
        "                    trading_end_date=trading_end_date,\n",
        "                    trading_fee=0,\n",
        "                    file_=f,\n",
        "                    nn_arch='MLP',\n",
        "                    window_width=4) #LAG\n",
        "  f.write('\\n\\n\\n')\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KNP526zy69NK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jvQeBc6SyedA",
        "IxqB2TSe-rZd",
        "J9WZVB3eyjXN",
        "JDfuXELB-0Ob",
        "hKENnzGyiGJ3"
      ],
      "name": "V4_ppo_trading_2_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}