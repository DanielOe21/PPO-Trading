{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvQeBc6SyedA"
      },
      "source": [
        "#INSTALA LIBRERIAS\n",
        "\n",
        "Se descargan librerias de GitHub necesarias para ejecutar el algoritmo, se puede comentariar si se ejecutan varios experimentos, solo correr 1 vez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5oNllgBLECXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28d4334d-4ca0-4ef5-96ba-377152a2aeff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git@2070f85cdd4d2cde4c00da98ff01ff448b1e593b\n",
            "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git (to revision 2070f85cdd4d2cde4c00da98ff01ff448b1e593b) to /tmp/pip-req-build-5dwkec8b\n",
            "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-5dwkec8b\n",
            "  Running command git rev-parse -q --verify 'sha^2070f85cdd4d2cde4c00da98ff01ff448b1e593b'\n",
            "  Running command git fetch -q https://github.com/AI4Finance-LLC/FinRL-Library.git 2070f85cdd4d2cde4c00da98ff01ff448b1e593b\n",
            "  Running command git checkout -q 2070f85cdd4d2cde4c00da98ff01ff448b1e593b\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (1.21.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (1.3.5)\n",
            "Collecting stockstats\n",
            "  Downloading stockstats-0.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Collecting pyfolio\n",
            "  Downloading pyfolio-0.9.2.tar.gz (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (1.0.2)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (0.17.3)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-1.4.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (3.6.4)\n",
            "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (0.37.1)\n",
            "Collecting arrow\n",
            "  Downloading arrow-1.2.2-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting python-rapidjson\n",
            "  Downloading python_rapidjson-1.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 45.0 MB/s \n",
            "\u001b[?25hCollecting questionary\n",
            "  Downloading questionary-1.10.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (1.4.31)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (0.8.9)\n",
            "Collecting ccxt\n",
            "  Downloading ccxt-1.73.96-py2.py3-none-any.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 38.9 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (2.8.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from finrl==0.0.3) (1.5.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->finrl==0.0.3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->finrl==0.0.3) (2.8.2)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.0.3) (0.0.10)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 29.1 MB/s \n",
            "\u001b[?25hCollecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio->finrl==0.0.3) (5.5.0)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio->finrl==0.0.3) (1.4.1)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio->finrl==0.0.3) (0.11.2)\n",
            "Collecting empyrical>=0.5.0\n",
            "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.0.3) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.0.3) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.0.3) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.0.3) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.0.3) (1.1.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.0.3) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.0.3) (1.5.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (1.10.0+cu111)\n",
            "Requirement already satisfied: psutil; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (5.4.8)\n",
            "Requirement already satisfied: opencv-python; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (4.1.2.30)\n",
            "Requirement already satisfied: tensorboard>=2.2.0; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (2.8.0)\n",
            "Requirement already satisfied: pillow; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (7.1.2)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'atari-py' candidate (version 0.2.6 at https://files.pythonhosted.org/packages/8f/ba/1d22e9d2f332f07aaa57041f5dd569c2cb40a92bd6374a0b743ec3dfae97/atari_py-0.2.6-cp37-cp37m-manylinux1_x86_64.whl#sha256=d9e2c25d39783867c2f29d1dd9d3a659fc56036456d07dc9efe8bd7bb31a07d7 (from https://pypi.org/simple/atari-py/))\n",
            "Reason for being yanked: re-release with new wheels\u001b[0m\n",
            "Collecting atari-py==0.2.6; extra == \"extra\"\n",
            "  Downloading atari_py-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (1.15.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (1.11.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (8.12.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.0.3) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from arrow->finrl==0.0.3) (3.10.0.2)\n",
            "Collecting prompt_toolkit<4.0,>=2.0\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[K     |████████████████████████████████| 380 kB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->finrl==0.0.3) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->finrl==0.0.3) (4.11.1)\n",
            "Collecting aiohttp>=3.8; python_version >= \"3.5.2\"\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.0 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.6.1\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 48.9 MB/s \n",
            "\u001b[?25hCollecting aiodns>=1.1.1; python_version >= \"3.5.2\"\n",
            "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
            "Collecting yarl==1.7.2; python_version >= \"3.5.2\"\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 61.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.7/dist-packages (from ccxt->finrl==0.0.3) (2021.10.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.0.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (0.5.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (0.24.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.43.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (13.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->finrl==0.0.3) (0.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance->finrl==0.0.3) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance->finrl==0.0.3) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance->finrl==0.0.3) (2.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (5.1.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio->finrl==0.0.3) (4.8.0)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio->finrl==0.0.3) (0.9.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.0.3) (0.16.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (3.3.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->finrl==0.0.3) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy->finrl==0.0.3) (3.7.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 45.6 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0; python_version < \"3.8\"\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.0.3) (1.15.0)\n",
            "Collecting pycares>=4.0.0\n",
            "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
            "\u001b[K     |████████████████████████████████| 291 kB 64.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->finrl==0.0.3) (1.5.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=3.2.3->pyfolio->finrl==0.0.3) (0.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.0.3) (2.21)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (3.2.0)\n",
            "Building wheels for collected packages: finrl, pyfolio, empyrical\n",
            "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.0.3-py3-none-any.whl size=117219 sha256=ef027ee0970bc46c49f2661f91f101a88b7a172b34ff8f99520c333403dcf5f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b3/33/ac4f66c4d2bf78bb4e478f9ed5e647b08f249b35ee59243a74\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2-py3-none-any.whl size=88682 sha256=5eb46920a6650ce1ca99d7e95ef1f958e76e0bfb5465b7b08531a8fd0e0acafd\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/96/9b/0dfff5453e702fd780a099b7c850521099c5ec0dfafae189f9\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39780 sha256=272aa438a25daf656ab73a33e64941cd66a2924e27d4e7efe515367272cd6da1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
            "Successfully built finrl pyfolio empyrical\n",
            "Installing collected packages: stockstats, lxml, requests, yfinance, empyrical, pyfolio, atari-py, stable-baselines3, arrow, python-rapidjson, prompt-toolkit, questionary, frozenlist, multidict, asynctest, async-timeout, aiosignal, yarl, aiohttp, cryptography, pycares, aiodns, ccxt, colorama, finrl, tf-estimator-nightly\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: atari-py\n",
            "    Found existing installation: atari-py 0.2.9\n",
            "    Uninstalling atari-py-0.2.9:\n",
            "      Successfully uninstalled atari-py-0.2.9\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.28 which is incompatible.\n",
            "ipython 5.5.0 requires prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 3.0.28 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you'll have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\n",
            "ccxt 1.73.96 requires setuptools>=60.9.0, but you'll have setuptools 57.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed aiodns-3.0.0 aiohttp-3.8.1 aiosignal-1.2.0 arrow-1.2.2 async-timeout-4.0.2 asynctest-0.13.0 atari-py-0.2.6 ccxt-1.73.96 colorama-0.4.4 cryptography-36.0.1 empyrical-0.5.5 finrl-0.0.3 frozenlist-1.3.0 lxml-4.8.0 multidict-6.0.2 prompt-toolkit-3.0.28 pycares-4.1.2 pyfolio-0.9.2 python-rapidjson-1.6 questionary-1.10.0 requests-2.27.1 stable-baselines3-1.4.0 stockstats-0.4.1 tf-estimator-nightly-2.8.0.dev2021122109 yarl-1.7.2 yfinance-0.1.70\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/quantopian/pyfolio.git\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-req-build-_vlfg8vo\n",
            "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-req-build-_vlfg8vo\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (5.5.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.0.2)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (0.11.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (0.5.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.8.1)\n",
            "Collecting prompt-toolkit<2.0.0,>=1.0.4\n",
            "  Downloading prompt_toolkit-1.0.18-py3-none-any.whl (245 kB)\n",
            "\u001b[K     |████████████████████████████████| 245 kB 20.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (3.0.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16.1->pyfolio==0.9.2+75.g4b901f6) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16.1->pyfolio==0.9.2+75.g4b901f6) (1.1.0)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (0.9.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2.27.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (4.8.0)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2.0.12)\n",
            "Building wheels for collected packages: pyfolio\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75774 sha256=ef860da05b3f6a2ba449c08b91f9f22d67fd0436f5e11ebffded747ebdfcbe59\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-70eve64p/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
            "Successfully built pyfolio\n",
            "Installing collected packages: pyfolio, prompt-toolkit\n",
            "  Attempting uninstall: pyfolio\n",
            "    Found existing installation: pyfolio 0.9.2\n",
            "    Uninstalling pyfolio-0.9.2:\n",
            "      Successfully uninstalled pyfolio-0.9.2\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 3.0.28\n",
            "    Uninstalling prompt-toolkit-3.0.28:\n",
            "      Successfully uninstalled prompt-toolkit-3.0.28\n",
            "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
            "questionary 1.10.0 requires prompt_toolkit<4.0,>=2.0, but you'll have prompt-toolkit 1.0.18 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you'll have requests 2.27.1 which is incompatible.\u001b[0m\n",
            "Successfully installed prompt-toolkit-1.0.18 pyfolio-0.9.2+75.g4b901f6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.70)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.8.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# DESCARGA DE LIBRERIAS\n",
        "#!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git@2070f85cdd4d2cde4c00da98ff01ff448b1e593b --use-deprecated=legacy-resolver\n",
        "#!pip install git+https://github.com/quantopian/pyfolio.git --use-deprecated=legacy-resolver\n",
        "#!pip install yfinance --use-deprecated=legacy-resolver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxqB2TSe-rZd"
      },
      "source": [
        "#Descarga de librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9xZAmbuDXSZ",
        "outputId": "f5720718-d38c-48ff-ed97-cb851077257e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
            "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se ha creado el directorio: ./data \n"
          ]
        }
      ],
      "source": [
        "# DESCARGA DE LIBRERIAS 2\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import datetime\n",
        "import os\n",
        "import math\n",
        "\n",
        "from finrl.config import config\n",
        "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
        "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
        "from finrl.preprocessing.data import data_split\n",
        "from finrl.env.env_portfolio import StockPortfolioEnv\n",
        "\n",
        "from finrl.model.models import DRLAgent\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "import yfinance as yf\n",
        "from pandas_datareader import data as pdr\n",
        "\n",
        "import pyfolio\n",
        "from copy import deepcopy\n",
        "\n",
        "  # para usar el sr como reward funct\n",
        "  # Se define el nombre de la carpeta o directorio a crear\n",
        "directorio = \"./data\"\n",
        "try:\n",
        "  os.mkdir(directorio)\n",
        "except OSError:\n",
        "  print(\"La creación del directorio %s falló\" % directorio)\n",
        "else:\n",
        "  print(\"Se ha creado el directorio: %s \" % directorio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9WZVB3eyjXN"
      },
      "source": [
        "# AGENTE\n",
        "\n",
        "En esta sección se configuran los ajustes del agente:\n",
        " - PPO Policy\n",
        " - actor, es la red neuronal (Figura de actor, hasta Miu), es a partir del ELSE\n",
        "        1. cambiar funcion de activación con el mismo numero de capas\n",
        "        2. cambiar optimizador\n",
        "        3. cambiar número de capas (no tienen q ser 64)\n",
        " - critic: Tiene 1 neurona de salida, puede agregarse otra capa de salida\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA6FmNNCoj27",
        "outputId": "59e4eca7-f095-40f0-a9cf-64260dc7c381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "Device set to : cpu\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "# AGENT DE APRENDIZAJE POR REFUERZO\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.distributions import Categorical\n",
        "import time\n",
        "\n",
        "################################## set device ##################################\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "# set device to cpu or cuda\n",
        "device = torch.device('cpu')\n",
        "\n",
        "if(torch.cuda.is_available()): \n",
        "    device = torch.device('cuda:0') \n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
        "else:\n",
        "    print(\"Device set to : cpu\")\n",
        "    \n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "################################## PPO Policy ##################################\n",
        "\n",
        "\n",
        "class RolloutBuffer:\n",
        "    def __init__(self):\n",
        "        self.actions = []\n",
        "        self.states = []\n",
        "        self.logprobs = []\n",
        "        self.rewards = []\n",
        "        self.is_terminals = []\n",
        "    \n",
        "\n",
        "    def clear(self):\n",
        "        del self.actions[:]\n",
        "        del self.states[:]\n",
        "        del self.logprobs[:]\n",
        "        del self.rewards[:]\n",
        "        del self.is_terminals[:]\n",
        "\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self,\n",
        "                 state_dim,\n",
        "                 action_dim,\n",
        "                 has_continuous_action_space,\n",
        "                 action_std_init,\n",
        "                 nn_arch,\n",
        "                 kernel_size):\n",
        "        super(ActorCritic, self).__init__()\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_dim = action_dim\n",
        "            #[0.6, 0.6, 0.6]\n",
        "            # Calcular la varianza los precios de cierre historicos de cada activo\n",
        "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
        "\n",
        "        self.nn_arch = nn_arch\n",
        "\n",
        "        # actor\n",
        "        # 1. cambiar funcion de activación con el mismo nuomero de capas\n",
        "        # 2. cambiar optimizador\n",
        "        # 3. cambiar número de capas\n",
        "        if has_continuous_action_space:\n",
        "            if self.nn_arch == 'CNN-MLP':\n",
        "              self.actor = nn.Sequential(\n",
        "                              nn.Linear(state_dim, state_dim),\n",
        "                              nn.AvgPool1d(kernel_size, stride=kernel_size),\n",
        "                              #nn.Conv1d(1, 1, kernel_size, stride=kernel_size),\n",
        "                              #2d, #imprimir diagrama, #downsampling, upsampling\n",
        "                              nn.Linear(int(state_dim / kernel_size), 64),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(64, 64),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(64, action_dim),\n",
        "                              nn.Tanh())\n",
        "    ######################### AQUI SE MODIFICA #############################\n",
        "            else:\n",
        "              self.actor = nn.Sequential(\n",
        "                              nn.Linear(state_dim, 64),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(64, 64),\n",
        "                              nn.Tanh(),\n",
        "                              nn.Linear(64, action_dim),\n",
        "                              nn.Tanh())\n",
        "                              \n",
        "        # critic\n",
        "        if self.nn_arch == 'CNN-MLP':\n",
        "            self.critic = nn.Sequential(\n",
        "                            nn.Linear(state_dim, state_dim),\n",
        "                            nn.AvgPool1d(kernel_size, stride=kernel_size),\n",
        "                            #nn.Conv1d(1, 1, kernel_size, stride=kernel_size),\n",
        "                            nn.Linear(int(state_dim / kernel_size), 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 1))\n",
        "    ######################### AQUI SE MODIFICA #############################\n",
        "        else:\n",
        "          self.critic = nn.Sequential(\n",
        "                          nn.Linear(state_dim, 64),\n",
        "                          nn.Tanh(),\n",
        "                          nn.Linear(64, 64),\n",
        "                          nn.Tanh(),\n",
        "                          nn.Linear(64, 1))\n",
        "                          #nn.Tanh())\n",
        "                \n",
        "        \n",
        "    def set_action_std(self, new_action_std):\n",
        "        #return\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "    \n",
        "\n",
        "    def act(self, state):\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state) #LA SALIDA ES MIU\n",
        "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0) #Calcula la matriz de covarianzas\n",
        "            dist = MultivariateNormal(action_mean, cov_mat) #Genera la matriz de distribución normal con (M,N) o sea la funcion\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "\n",
        "        action = dist.sample() # Genera numeros aleatorios y se los pasa a la funcion de distribucion que se deriva de las medias de las acciones y la matriz de covarianza (dist)\n",
        "        action_logprob = dist.log_prob(action) #La accion es la flechita que sale de N en el diagrama\n",
        "        \n",
        "        return action.detach(), action_logprob.detach()\n",
        "    \n",
        "\n",
        "    def evaluate(self, state, action): #Es similar a actuar, pero evalua que tan buenos son los valores de los estados que se han pronosticado\n",
        "        if self.nn_arch == 'CNN-MLP':\n",
        "          state = state.unsqueeze(0)\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state)\n",
        "            \n",
        "            action_var = self.action_var.expand_as(action_mean)\n",
        "            cov_mat = torch.diag_embed(action_var).to(device)\n",
        "            dist = MultivariateNormal(action_mean, cov_mat)\n",
        "            \n",
        "            # For Single Action Environments.\n",
        "            if self.action_dim == 1:\n",
        "                action = action.reshape(-1, self.action_dim)\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "        state_values = self.critic(state)\n",
        "        \n",
        "        return action_logprobs, state_values, dist_entropy\n",
        "\n",
        "\n",
        "class PPO:\n",
        "    def __init__(self,\n",
        "                 state_dim,\n",
        "                 action_dim,\n",
        "                 lr_actor,\n",
        "                 lr_critic,\n",
        "                 gamma,\n",
        "                 K_epochs,\n",
        "                 eps_clip,\n",
        "                 has_continuous_action_space,\n",
        "                 action_std_init=0.6,\n",
        "                 nn_arch='MLP',\n",
        "                 kernel_size=1):\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_std = action_std_init\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.eps_clip = eps_clip\n",
        "        self.K_epochs = K_epochs\n",
        "        \n",
        "        self.buffer = RolloutBuffer()\n",
        "\n",
        "        self.policy = ActorCritic(state_dim,\n",
        "                                  action_dim,\n",
        "                                  has_continuous_action_space,\n",
        "                                  action_std_init,\n",
        "                                  nn_arch,\n",
        "                                  kernel_size).to(device)\n",
        "        print(self.policy)\n",
        "        self.optimizer = torch.optim.RMSprop([\n",
        "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
        "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
        "                    ])\n",
        "\n",
        "        self.policy_old = ActorCritic(state_dim,\n",
        "                                      action_dim,\n",
        "                                      has_continuous_action_space,\n",
        "                                      action_std_init,\n",
        "                                      nn_arch,\n",
        "                                      kernel_size).to(device)\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "        \n",
        "        self.MseLoss = nn.MSELoss()\n",
        "\n",
        "\n",
        "    def set_action_std(self, new_action_std):\n",
        "        \n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = new_action_std\n",
        "            self.policy.set_action_std(new_action_std)\n",
        "            self.policy_old.set_action_std(new_action_std)\n",
        "        \n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = self.action_std - action_std_decay_rate\n",
        "            self.action_std = round(self.action_std, 4)\n",
        "            if (self.action_std <= min_action_std):\n",
        "                self.action_std = min_action_std\n",
        "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
        "            else:\n",
        "                print(\"setting actor output action_std to : \", self.action_std)\n",
        "            self.set_action_std(self.action_std)\n",
        "\n",
        "        else:\n",
        "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
        "\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def select_action(self, state):\n",
        "        with torch.no_grad():\n",
        "            state = torch.FloatTensor(state).to(device)\n",
        "            state_unsqueeze = state.unsqueeze(0)\n",
        "            action, action_logprob = self.policy_old.act(state_unsqueeze)\n",
        "  \n",
        "        if self.has_continuous_action_space:\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "\n",
        "            return action.detach().cpu().numpy().flatten()\n",
        "        else:\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "\n",
        "            return action.item()\n",
        "\n",
        "\n",
        "    def update(self):\n",
        "      # Monte Carlo estimate of returns\n",
        "      rewards = []\n",
        "      discounted_reward = 0\n",
        "      for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
        "          if is_terminal:\n",
        "              discounted_reward = 0\n",
        "          discounted_reward = reward + (self.gamma * discounted_reward)\n",
        "          rewards.insert(0, discounted_reward)\n",
        "          \n",
        "      # Normalizing the rewards\n",
        "      rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "      rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
        "\n",
        "      # convert list to tensor\n",
        "      old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
        "      old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
        "      old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
        "\n",
        "      \n",
        "      # Optimize policy for K epochs\n",
        "      for _ in range(self.K_epochs):\n",
        "\n",
        "        # Evaluating old actions and values\n",
        "        logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
        "\n",
        "        # match state_values tensor dimensions with rewards tensor\n",
        "        state_values = torch.squeeze(state_values)\n",
        "        \n",
        "        # Finding the ratio (pi_theta / pi_theta__old)\n",
        "        ratios = torch.exp(logprobs - old_logprobs.detach())\n",
        "\n",
        "        # Finding Surrogate Loss\n",
        "        advantages = rewards - state_values.detach()   \n",
        "        surr1 = ratios * advantages\n",
        "        surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
        "\n",
        "        # final loss of clipped objective PPO\n",
        "        loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
        "        \n",
        "        # take gradient step\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.mean().backward()\n",
        "        self.optimizer.step()\n",
        "      # Copy new weights into old policy\n",
        "      self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "      # clear buffer\n",
        "      self.buffer.clear()\n",
        "            \n",
        "    def save(self, checkpoint_path):\n",
        "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
        "   \n",
        "\n",
        "    def load(self, checkpoint_path):\n",
        "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
        "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDfuXELB-0Ob"
      },
      "source": [
        "#PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Td0JBxOpEMtE"
      },
      "outputs": [],
      "source": [
        "class PortfolioAllocation(gym.Env):\n",
        "  passmetadata = {'render.modes': ['human']}\n",
        "\n",
        "  def __init__(self,\n",
        "               df,\n",
        "               stock_dim,\n",
        "               initial_amount,\n",
        "               tech_indicator_list,\n",
        "               market_variables,\n",
        "               reward_function,\n",
        "               day=0,\n",
        "               data_stddev=None,\n",
        "               free_risk_return=None,\n",
        "               data_corr=None,\n",
        "               expected_values=None,\n",
        "               trading_fee=0,\n",
        "               nn_arch='MLP',\n",
        "               window_width=1):\n",
        "    self.df = df\n",
        "    self.stock_dim = stock_dim\n",
        "    self.initial_amount = initial_amount\n",
        "    self.tech_indicator_list = tech_indicator_list\n",
        "    self.day_start = day\n",
        "    self.day = self.day_start\n",
        "    self.market_variables = market_variables\n",
        "    self.reward_function = reward_function\n",
        "    self.window_width = window_width\n",
        "    self.nn_arch = nn_arch\n",
        "\n",
        "    self.setup()\n",
        "\n",
        "    # Reward based on Sharpe Ratio (correlation)\n",
        "    self.expected_values = expected_values\n",
        "    self.data_stddev = data_stddev\n",
        "    self.data_corr = data_corr\n",
        "    self.free_risk_return = free_risk_return\n",
        "\n",
        "    self.trading_fee = trading_fee\n",
        "\n",
        "  def setup(self):\n",
        "    # action_space normalization and shape is self.stock_dim\n",
        "    self.action_space = spaces.Box(low=0, high=1,\n",
        "                                   shape=(self.stock_dim,))\n",
        "    # observation space\n",
        "    shape = (self.stock_dim * (len(self.market_variables) + len(self.tech_indicator_list)) * self.window_width,)\n",
        "\n",
        "    self.observation_space = spaces.Box(low=-0, high=np.inf,\n",
        "                                        shape=shape)\n",
        "\n",
        "    self.reset()\n",
        "\n",
        "  def step(self, actions):\n",
        "    self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
        "\n",
        "    if self.terminal:\n",
        "      #df = pd.DataFrame(self.portfolio_return_memory)\n",
        "      #df.columns = ['daily_return']\n",
        "      return self.state, self.reward, self.terminal, {}\n",
        "    else:\n",
        "      # actions are the portfolio weight\n",
        "      # normalize to sum of 1\n",
        "      weights = self.softmax_normalization(actions) #-> [0.2, 0.7, 0.1] #Los pesos son el capital a destinar de cada uno de los activos, se calculan a paritr de aplicar una normalizacion de tipo softmax a lo que se considera actions\n",
        "      # Acciones son la salida de la N\n",
        "\n",
        "      last_day_memory = self.data\n",
        "\n",
        "      # load next state\n",
        "      self.day += 1\n",
        "      self.state = self._get_state()\n",
        "  \n",
        "      prev_portfolio_value = self.portfolio_value\n",
        "      # [0.2, 0.7, 0.1] * [80, 120] -> [0.2, 0.7, 0.1] * [80, 120, 1] \n",
        "      # 1 am = [1] / [120] = 0.0083 (1dll)\n",
        "      # 2 [0.0083]* [150] = 1.25  (+ 0.25dll)\n",
        "      # 3 am += ([1] * [1.25]) / [150] = \n",
        "      # A [0.5, 0.5] / [120, 80] = 0.0041, 0.0062\n",
        "      # B [0.0041, 0.0062] * [130, 100] = [ 0.54 , 0.62] = 1.16\n",
        "      # C [0.3, 0.7] * [1.16] = [0.384, 0.82] / [130, 100] = [0.00276259, 0.0082] = \n",
        "      self.portfolio_value = sum(self.actions_memory[-1] * self.data.close.values)\n",
        "      self.actions_memory.append(weights*self.portfolio_value / self.data.close.values)\n",
        "      portfolio_return = ((self.portfolio_value / prev_portfolio_value) - 1)\n",
        "\n",
        "      # save into memory\n",
        "      self.portfolio_return_memory.append(portfolio_return)\n",
        "      self.date_memory.append(self.data.date.unique()[0])           \n",
        "      self.asset_memory.append(self.portfolio_value)\n",
        "\n",
        "      # reward\n",
        "\n",
        "      if self.reward_function == 'pv':\n",
        "        self.reward = portfolio_return\n",
        "        #self.reward = portfolio_return\n",
        "      elif self.reward_function == 'sr':\n",
        "        portfolio_risk = self.portfolio_risk(weights, self.data_stddev, self.data_corr)\n",
        "        self.reward = self.sharpeVE_ratio(weights, self.expected_values, portfolio_risk, self.free_risk_return)\n",
        "\n",
        "      return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "  def _get_state(self):\n",
        "    self.data = self.df.loc[self.day,:].sort_values(by=['tic'])\n",
        "\n",
        "    tmp_data = [np.array(self.data[prop])\n",
        "                for prop in self.market_variables + self.tech_indicator_list]\n",
        "\n",
        "    for i in range(1, self.window_width):\n",
        "      data = self.df.loc[self.day - i,:].sort_values(by=['tic'])\n",
        "      tmp_data = tmp_data + [np.array(data[prop])\n",
        "                             for prop in self.market_variables + self.tech_indicator_list]\n",
        "    \n",
        "    state = np.concatenate(tmp_data, axis=0)\n",
        "    return state\n",
        "\n",
        "  def _reset(self):\n",
        "    self.state = self._get_state()\n",
        "    self.terminal = False\n",
        "    # Agregar + 1 en stock_dim 1/(self.stock_dim + 1)\n",
        "    initial_weights = np.array([1/self.stock_dim] * self.stock_dim)\n",
        "    # [.5, .5] * [120, 80] = [0.004, 0.006]* [120, 80] = [0.5, 0.5]\n",
        "    self.portfolio_value = sum((initial_weights / self.data.close.values) * self.data.close.values)\n",
        "\n",
        "    self.portfolio_return_memory = [0]\n",
        "    self.asset_memory = [self.initial_amount]\n",
        "    # agregar + 1\n",
        "    self.actions_memory = [initial_weights / self.data.close.values]\n",
        "    self.date_memory = [self.data.date.unique()[0]] \n",
        "\n",
        "  def reset(self):\n",
        "    self.day = self.day_start\n",
        "    self._reset()\n",
        "    return self.state\n",
        "\n",
        "  def save_asset_memory(self):\n",
        "    date_list = self.date_memory\n",
        "    portfolio_return = self.portfolio_return_memory\n",
        "    df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "    return df_account_value\n",
        "\n",
        "  def save_action_memory(self):\n",
        "    # date and close price length must match actions length\n",
        "    date_list = self.date_memory\n",
        "    df_date = pd.DataFrame(date_list)\n",
        "    df_date.columns = ['date']\n",
        "    \n",
        "    action_list = self.actions_memory\n",
        "    df_actions = pd.DataFrame(action_list)\n",
        "    df_actions.columns = self.data.tic.values\n",
        "    df_actions.index = df_date.date\n",
        "    return df_actions\n",
        "\n",
        "  def render(self, mode='human'):\n",
        "    return self.state\n",
        "\n",
        "  def softmax_normalization(self, actions):\n",
        "    numerator = np.exp(actions)\n",
        "    denominator = np.sum(np.exp(actions))\n",
        "    softmax_output = numerator/denominator\n",
        "    return softmax_output\n",
        "\n",
        "  def _seed(self, seed=None):\n",
        "    self.np_random, seed = seeding.np_random(seed)\n",
        "    return [seed]\n",
        "\n",
        "  def get_sb_env(self):\n",
        "    e = DummyVecEnv([lambda: self])\n",
        "    obs = e.reset()\n",
        "    return e, obs\n",
        "\n",
        "  def portfolio_risk(self, weights, data_stddev, data_corr):\n",
        "    aux_1 = 0\n",
        "    aux_2 = 0\n",
        "    for i in range(len(weights)):\n",
        "        aux_1 += math.pow(weights[i], 2) * math.pow(data_stddev[i], 2)\n",
        "\n",
        "    for i in range(len(weights)):\n",
        "        for j in range(len(weights)):\n",
        "            if i == j:\n",
        "                continue\n",
        "            aux_2 += weights[i] * weights[j] * data_stddev[i] * data_stddev[j] * data_corr.values[i][j]\n",
        "\n",
        "    return np.sqrt(aux_1 + (2 * aux_2))\n",
        "\n",
        "  def sharpeVE_ratio(self, weights, expected_values,\n",
        "                     risk, free_risk_return):\n",
        "    sr = (sum(weights * expected_values * 252) - free_risk_return) / risk\n",
        "    return sr\n",
        "\n",
        "def get_dataframe(tickers, start_date, end_date):\n",
        "    df = YahooDownloader(start_date=start_date,\n",
        "                         end_date=end_date,\n",
        "                         ticker_list=tickers).fetch_data()\n",
        "    return df\n",
        "\n",
        "def retrieve_data_from_yahoo(assets, start_date, end_date, attribute):\n",
        "  '''\n",
        "  -> Example output\n",
        "                  GFNORTEO.MX     BSMXB.MX    ....\n",
        "  Date                              \n",
        "  2019-01-02      93.142639       24.001934\n",
        "  ...\n",
        "  ...\n",
        "  2019-12-31      93.142639       24.001934\n",
        "  '''\n",
        "  df = pd.DataFrame()\n",
        "  for asset in assets:\n",
        "    try:\n",
        "      df_asset = pd.read_csv('./data/{}+[{}]_[{}].csv'.format(asset, start_date, end_date))\n",
        "      df_asset.set_index('Date', inplace=True)\n",
        "    except FileNotFoundError as e:\n",
        "      df_asset = pdr.get_data_yahoo(asset, start=start_date, end=end_date)[attribute]\n",
        "      df_asset = df_asset.to_frame(name=asset)\n",
        "      df_asset.to_csv('./data/{}+[{}]_[{}].csv'.format(asset, start_date, end_date))\n",
        "\n",
        "    df = pd.concat([df, df_asset], axis=1, sort=False)\n",
        "  return df\n",
        "\n",
        "def data_cleaning(dataframe):\n",
        "    df = dataframe.dropna(axis=1, how='all') \n",
        "    df = df.interpolate(limit_direction='both') \n",
        "    return df.sort_index(axis=1), sorted(df.columns)\n",
        "\n",
        "def data_preparation(dataframe, assets):\n",
        "  data_pct_changes = dataframe.pct_change().dropna()\n",
        "  data_covariances = np.cov(data_pct_changes.transpose())\n",
        "  data_stddev = np.array(np.std(data_pct_changes))\n",
        "  data_corr = data_pct_changes.corr()\n",
        "  expected_values = get_expected_values(dataframe, data_pct_changes, assets)\n",
        "\n",
        "  return data_stddev, data_corr, expected_values\n",
        "  #return data_pct_changes, data_covariances, data_stddev, data_corr, expected_values\n",
        "\n",
        "def get_expected_values(data, data_pct_changes, assets):\n",
        "  expected_values = []\n",
        "\n",
        "  for serie in assets:\n",
        "      x, rangos = np.histogram(data_pct_changes[serie], bins=10)\n",
        "      y=[]\n",
        "      for i in range(len(rangos) - 1):\n",
        "          y.append((rangos[i] + rangos[i + 1]) / 2)\n",
        "      p = x / len(data)\n",
        "      expected_value = sum(p * y) \n",
        "      expected_values.append(expected_value)\n",
        "\n",
        "  return np.array(expected_values)\n",
        "\n",
        "def feature_engineering(df, indicators):\n",
        "    fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                        tech_indicator_list=indicators,\n",
        "                        use_turbulence=False,\n",
        "                        user_defined_feature=False)\n",
        "\n",
        "    return fe.preprocess_data(df)\n",
        "\n",
        "def zscore(df, tickers, properties):\n",
        "  df = df.copy()\n",
        "  df = df.sort_values(by=['tic','date'])\n",
        "\n",
        "  for var in properties:\n",
        "      var_df = pd.DataFrame()\n",
        "      for ticker in tickers:\n",
        "          temp_normalized = stats.zscore(df[df.tic == ticker][var])\n",
        "          temp_normalized = pd.DataFrame(temp_normalized, columns=[var+'_zscore'])\n",
        "          temp_normalized['tic'] = ticker\n",
        "          temp_normalized['date'] = df[df.tic == ticker]['date'].to_list()\n",
        "          var_df = var_df.append(\n",
        "              temp_normalized, ignore_index=True\n",
        "          )\n",
        "      df = df.merge(var_df[['tic','date',var+'_zscore']],on=['tic','date'],how='left')\n",
        "  df = df.sort_values(by=['date','tic'])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKENnzGyiGJ3"
      },
      "source": [
        "# Hiperparametros del PPO\n",
        "\n",
        "se crea el agente y el entorno. \n",
        "\n",
        "Se pueden modificar las epocas del PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tv6P9YbTE8Hw"
      },
      "outputs": [],
      "source": [
        "def train_and_perform(index,\n",
        "                      policy,\n",
        "                      episodes,\n",
        "                      n_steps,\n",
        "                      market_variables,\n",
        "                      indicators,\n",
        "                      reward_function,\n",
        "                      normalization_function,\n",
        "                      tickers,\n",
        "                      training_start_date,\n",
        "                      training_end_date,\n",
        "                      trading_start_date,\n",
        "                      trading_end_date,\n",
        "                      trading_fee,\n",
        "                      file_,\n",
        "                      nn_arch='MLP',\n",
        "                      window_width=1):\n",
        "  df = get_dataframe(tickers, training_start_date, trading_end_date)\n",
        "  df['rate open/close'] = df['open']/df['close']\n",
        "  df = feature_engineering(df, indicators)\n",
        "\n",
        "  if not (normalization_function is None):\n",
        "    df = normalization_function(df, tickers, market_variables + indicators)\n",
        "\n",
        "  train_df = data_split(df, training_start_date, training_end_date)\n",
        "  print(train_df)\n",
        "  # calcular vector varianzas de train_df en base a los precios de cierre\n",
        "  trading_df = data_split(df, trading_start_date, trading_end_date)\n",
        "\n",
        "  if reward_function == 'pv':\n",
        "    env_kwargs = {\n",
        "    'initial_amount': 1, \n",
        "    'stock_dim': len(tickers),\n",
        "    'tech_indicator_list': indicators,\n",
        "    'market_variables': market_variables,\n",
        "    'reward_function': reward_function,\n",
        "    'trading_fee': trading_fee,\n",
        "    'nn_arch': nn_arch,\n",
        "    'window_width': window_width,\n",
        "    'day': window_width - 1\n",
        "    }\n",
        "  elif reward_function == 'sr':\n",
        "    yf.pdr_override()\n",
        "\n",
        "    df_adj_close = retrieve_data_from_yahoo(tickers,\n",
        "                                            training_start_date,\n",
        "                                            training_end_date,\n",
        "                                            'Adj Close')\n",
        "    df_adj_close, tickers_adj_close = data_cleaning(df_adj_close)\n",
        "\n",
        "    data_stddev, data_corr, expected_values = data_preparation(df_adj_close, tickers_adj_close)\n",
        "\n",
        "    free_risk_return = 0.015\n",
        "\n",
        "    env_kwargs = {\n",
        "      'initial_amount': 1, \n",
        "      'stock_dim': len(tickers), \n",
        "      'tech_indicator_list': indicators, \n",
        "      'market_variables': market_variables,\n",
        "      'expected_values': expected_values,\n",
        "      'reward_function': reward_function,\n",
        "      'free_risk_return': free_risk_return,\n",
        "      'data_stddev': data_stddev,\n",
        "      'data_corr': data_corr,\n",
        "      'trading_fee': trading_fee,\n",
        "      'nn_arch': nn_arch,\n",
        "      'window_width': window_width,\n",
        "      'day': window_width - 1\n",
        "    }\n",
        "\n",
        "  training_env_gym = PortfolioAllocation(df=train_df, **env_kwargs)\n",
        "  training_env, _ = training_env_gym.get_sb_env()\n",
        "\n",
        "  trading_env_gym = PortfolioAllocation(df=trading_df, **env_kwargs)\n",
        "  trading_env, _ = trading_env_gym.get_sb_env()\n",
        "\n",
        "  ####### initialize environment hyperparameters ######\n",
        "\n",
        "  has_continuous_action_space = True\n",
        "  max_ep_len = len(train_df.date.unique())\n",
        "  max_ep_trading_len = len(trading_df.date.unique())                   \n",
        "  max_training_timesteps = len(train_df.date.unique()) * episodes \n",
        "\n",
        "  print_freq = max_ep_len * 10        # print avg reward in the interval (in num timesteps)\n",
        "  log_freq = max_ep_len * 2           # log avg reward in the interval (in num timesteps)\n",
        "  save_model_freq = int(1e5)          # save model frequency (in num timesteps)\n",
        "\n",
        "  action_std = 0.6                    # starting std for action distribution (Multivariate Normal)\n",
        "  action_std_decay_rate = 0.01        # linearly decay action_std (action_std = action_std - action_std_decay_rate)\n",
        "  min_action_std = 0.1                # minimum action_std (stop decay after action_std <= min_action_std)\n",
        "  action_std_decay_freq = int(5.5e3)  # action_std decay frequency (in num timesteps)\n",
        "  \n",
        "  #####################################################\n",
        "\n",
        "  ################ PPO hyperparameters ################\n",
        "\n",
        "  update_timestep = max_ep_len * 4      # update policy every n timesteps\n",
        "  #update_timestep = int(max_ep_len / 4)\n",
        "  K_epochs = 80               # update policy for K epochs in one PPO update\n",
        "\n",
        "  eps_clip = 0.2          # clip parameter for PPO\n",
        "  gamma = 0.99           # discount factor\n",
        "\n",
        "  lr_actor = 0.0003       # learning rate for actor network\n",
        "  lr_critic = 0.001       # learning rate for critic network\n",
        "\n",
        "  random_seed = 0         # set random seed if required (0 = no random seed)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  # state space dimension\n",
        "  state_dim = training_env.observation_space.shape[0]\n",
        "\n",
        "  # action space dimension\n",
        "  action_dim = training_env.action_space.shape[0]\n",
        "\n",
        "  ppo_agent = PPO(state_dim,\n",
        "                  action_dim, #[0.2, 0.3, 0.5] aunque solamente tengas 2 activos\n",
        "                  lr_actor,\n",
        "                  lr_critic,\n",
        "                  gamma,\n",
        "                  K_epochs,\n",
        "                  eps_clip,\n",
        "                  has_continuous_action_space,\n",
        "                  action_std,\n",
        "                  nn_arch=nn_arch,\n",
        "                  kernel_size=(len(market_variables) + len(indicators)) * window_width)\n",
        "  \n",
        "  # printing and logging variables\n",
        "  print_running_reward = 0\n",
        "  print_running_episodes = 0\n",
        "\n",
        "  time_step = 0\n",
        "  i_episode = 0\n",
        "\n",
        "  ################ Training ################\n",
        "  training_time = time.time()\n",
        "  while time_step <= max_training_timesteps:\n",
        "    state = training_env.reset()\n",
        "    current_ep_reward = 0\n",
        "\n",
        "    for t in range(1, max_ep_len+1):\n",
        "      # select action with policy\n",
        "      action = ppo_agent.select_action(state)\n",
        "      state, reward, done, _ = training_env.step([action])\n",
        "\n",
        "      reward = reward[0]\n",
        "\n",
        "      # saving reward and is_terminals\n",
        "      ppo_agent.buffer.rewards.append(reward)\n",
        "      ppo_agent.buffer.is_terminals.append(done)\n",
        "\n",
        "      time_step +=1\n",
        "      current_ep_reward += reward\n",
        "\n",
        "      # update PPO agent\n",
        "      if time_step % update_timestep == 0:\n",
        "        ppo_agent.update()\n",
        "\n",
        "      # if continuous action space; then decay action std of ouput action distribution\n",
        "      if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
        "        ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
        "\n",
        "      # break; if the episode is over\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    print_running_reward += current_ep_reward\n",
        "    print_running_episodes += 1\n",
        "\n",
        "    i_episode += 1\n",
        "  training_time = time.time() - training_time\n",
        "  print('Training')\n",
        "  \n",
        "  #####################################################\n",
        "\n",
        "  ################ Testing ################\n",
        "\n",
        "  testing_time = 0\n",
        "  df_daily_return = None\n",
        "  total_test_episodes = 15\n",
        "  for ep in range(total_test_episodes):\n",
        "    testing_time_  = time.time()\n",
        "    ep_reward = 0\n",
        "    state = trading_env.reset()\n",
        "\n",
        "    for t in range(max_ep_trading_len):\n",
        "      action = ppo_agent.select_action(state)\n",
        "      state, reward, done, _ = trading_env.step([action])\n",
        "  \n",
        "      reward = reward[0]\n",
        "      ep_reward += reward\n",
        "\n",
        "      if t == max_ep_trading_len - (window_width + 2):\n",
        "        tmp_dr = trading_env.env_method(method_name=\"save_asset_memory\")[0]\n",
        "        actions_memory = trading_env.env_method(method_name=\"save_action_memory\")[0]\n",
        "        if df_daily_return is None:\n",
        "          df_daily_return = tmp_dr\n",
        "        else:\n",
        "          df_daily_return['daily_return'] = df_daily_return['daily_return'] + tmp_dr['daily_return']\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    # clear buffer\n",
        "    ppo_agent.buffer.clear()\n",
        "    testing_time += (time.time() - testing_time_)\n",
        "\n",
        "  print('Testing')\n",
        "  print(actions_memory)\n",
        "  #####################################################\n",
        "\n",
        "  df_daily_return.loc[:,'daily_return'] /= total_test_episodes\n",
        "  df_plot = deepcopy(df_daily_return)\n",
        "  df_plot['date'] = pd.to_datetime(df_plot['date'])\n",
        "  df_plot.set_index(\"date\", inplace=True, drop=True)\n",
        "  df_plot.index = df_plot.index.tz_localize(\"UTC\")\n",
        "\n",
        "  serie = pd.Series(df_plot[\"daily_return\"], index=df_plot.index)\n",
        "  print(serie)\n",
        "  file_.write('training_time {}\\n'.format(training_time))\n",
        "  file_.write('testing_time {}\\n'.format(testing_time))\n",
        "  file_.write(str(pyfolio.timeseries.perf_stats(returns=serie)))\n",
        "  serie.to_csv('2019-drl{}-{}-{}-{}.csv'.format(window_width, index, reward_function, normalization_function))\n",
        "  #print(pyfolio.timeseries.perf_stats(returns=serie))\n",
        "  pyfolio.create_full_tear_sheet(returns=serie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6ZTJ1HnlEvr"
      },
      "source": [
        "# Ejecución del algoritmo\n",
        "\n",
        "Episodios se pueden modificar\n",
        "\n",
        "Market variables también, pero hay que revisar el DF\n",
        "\n",
        "Indicadores tambien asi se queda\n",
        "\n",
        "Las variables y los indicadores dan como resultado todas las combinaciones\n",
        "\n",
        "Funcion de recompensa puede ser SR y PV\n",
        "\n",
        "Activos\n",
        "\n",
        "Lag\n",
        "\n",
        "A la salida el setting actor output action_std es que hace mas chica la campana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q8BDFx-zCCfI",
        "outputId": "2a05182e-0135-401f-e7cd-be2c2dc5b709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...       atr    boll_ub    boll_lb\n",
            "0    2016-01-04  17.730000  17.730000  ...  3.509300  14.647763  14.016737\n",
            "0    2016-01-04  14.440000  14.570000  ...  3.400412  14.647763  14.016737\n",
            "0    2016-01-04  10.452175  10.597057  ...  3.269908  14.548197  14.097023\n",
            "0    2016-01-04  10.825763  10.973749  ...  3.199397  14.662571  13.782960\n",
            "0    2016-01-04  23.850000  24.150000  ...  3.217245  14.594391  13.804041\n",
            "..          ...        ...        ...  ...       ...        ...        ...\n",
            "502  2017-12-29  34.330002  34.330002  ...  1.934575  21.228147  19.053770\n",
            "502  2017-12-29  37.500000  37.500000  ...  1.943872  21.318277  18.827589\n",
            "502  2017-12-29   9.100000   9.100000  ...  1.981404  21.291976  18.751094\n",
            "502  2017-12-29  40.259998  40.259998  ...  1.963694  21.247254  18.647671\n",
            "502  2017-12-29   9.273076   9.273076  ...  1.974344  21.140938  18.619447\n",
            "\n",
            "[22635 rows x 19 columns]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=2925, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=2925, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2018-01-08  0.001165  0.000820  0.001269  ...  0.002447  0.000673  0.002483\n",
            "2018-01-09  0.001593  0.001361  0.002221  ...  0.002993  0.001224  0.002638\n",
            "2018-01-10  0.001785  0.000705  0.000609  ...  0.001929  0.000432  0.002653\n",
            "2018-01-11  0.001573  0.001786  0.000648  ...  0.003650  0.000879  0.001825\n",
            "2018-01-12  0.001198  0.000887  0.000954  ...  0.002216  0.001155  0.001389\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2018-12-19  0.001719  0.000579  0.000440  ...  0.003217  0.000378  0.002507\n",
            "2018-12-20  0.000928  0.000416  0.003916  ...  0.001567  0.001768  0.001234\n",
            "2018-12-21  0.000724  0.000902  0.001077  ...  0.003904  0.000685  0.000980\n",
            "2018-12-26  0.002262  0.001940  0.000767  ...  0.003847  0.001204  0.003367\n",
            "2018-12-27  0.003174  0.001120  0.001754  ...  0.002940  0.000693  0.003027\n",
            "\n",
            "[241 rows x 45 columns]\n",
            "date\n",
            "2018-01-08 00:00:00+00:00    0.000000\n",
            "2018-01-09 00:00:00+00:00   -0.006211\n",
            "2018-01-10 00:00:00+00:00   -0.008047\n",
            "2018-01-11 00:00:00+00:00    0.018222\n",
            "2018-01-12 00:00:00+00:00   -0.000124\n",
            "                               ...   \n",
            "2018-12-19 00:00:00+00:00   -0.006512\n",
            "2018-12-20 00:00:00+00:00   -0.006599\n",
            "2018-12-21 00:00:00+00:00    0.002907\n",
            "2018-12-26 00:00:00+00:00   -0.002859\n",
            "2018-12-27 00:00:00+00:00    0.004080\n",
            "Name: daily_return, Length: 241, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2018-01-08</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2018-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>6.973%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>6.659%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>22.437%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>0.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-21.213%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>0.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.79%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21.21</td>\n",
              "      <td>2018-02-23</td>\n",
              "      <td>2018-06-18</td>\n",
              "      <td>2018-11-01</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.40</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>2018-11-13</td>\n",
              "      <td>2018-12-03</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.36</td>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>2018-02-09</td>\n",
              "      <td>2018-02-21</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.52</td>\n",
              "      <td>2018-12-03</td>\n",
              "      <td>2018-12-20</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.52</td>\n",
              "      <td>2018-01-17</td>\n",
              "      <td>2018-01-23</td>\n",
              "      <td>2018-01-24</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.04%</td>\n",
              "      <td>-4.78%</td>\n",
              "      <td>5.04%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...    boll_ub    boll_lb      rsi_14\n",
            "0    2016-01-04  17.730000  17.730000  ...  14.647769  14.016734  100.000000\n",
            "0    2016-01-04  14.440000  14.570000  ...  14.647769  14.016734  100.000000\n",
            "0    2016-01-04  10.452175  10.597057  ...  14.548201  14.097022   59.592663\n",
            "0    2016-01-04  10.825763  10.973749  ...  14.662575  13.782959   27.367809\n",
            "0    2016-01-04  23.850000  24.150000  ...  14.594394  13.804039   43.190096\n",
            "..          ...        ...        ...  ...        ...        ...         ...\n",
            "502  2017-12-29  34.330002  34.330002  ...  21.228148  19.053771   32.104787\n",
            "502  2017-12-29  37.500000  37.500000  ...  21.318278  18.827589   36.519794\n",
            "502  2017-12-29   9.100000   9.100000  ...  21.291977  18.751095   46.509123\n",
            "502  2017-12-29  40.259998  40.259998  ...  21.247255  18.647672   43.298862\n",
            "502  2017-12-29   9.273076   9.273076  ...  21.140939  18.619447   47.636111\n",
            "\n",
            "[22635 rows x 13 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=1575, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=1575, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2018-01-08  0.001165  0.000820  0.001269  ...  0.002447  0.000673  0.002483\n",
            "2018-01-09  0.000666  0.001079  0.001731  ...  0.000711  0.000604  0.001935\n",
            "2018-01-10  0.002154  0.000272  0.002656  ...  0.002910  0.000422  0.002119\n",
            "2018-01-11  0.002301  0.001042  0.000749  ...  0.000812  0.000410  0.001510\n",
            "2018-01-12  0.001950  0.000716  0.000511  ...  0.001540  0.000238  0.001282\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2018-12-19  0.002196  0.000459  0.000929  ...  0.001107  0.000719  0.001406\n",
            "2018-12-20  0.004892  0.000376  0.000417  ...  0.001600  0.000206  0.002909\n",
            "2018-12-21  0.005103  0.000490  0.000924  ...  0.001234  0.000653  0.001274\n",
            "2018-12-26  0.001560  0.000243  0.000335  ...  0.000891  0.000947  0.000546\n",
            "2018-12-27  0.000979  0.000397  0.000297  ...  0.004200  0.000586  0.003844\n",
            "\n",
            "[241 rows x 45 columns]\n",
            "date\n",
            "2018-01-08 00:00:00+00:00    0.000000\n",
            "2018-01-09 00:00:00+00:00   -0.006211\n",
            "2018-01-10 00:00:00+00:00   -0.008142\n",
            "2018-01-11 00:00:00+00:00    0.015859\n",
            "2018-01-12 00:00:00+00:00   -0.001150\n",
            "                               ...   \n",
            "2018-12-19 00:00:00+00:00   -0.007716\n",
            "2018-12-20 00:00:00+00:00   -0.006159\n",
            "2018-12-21 00:00:00+00:00    0.000112\n",
            "2018-12-26 00:00:00+00:00   -0.003055\n",
            "2018-12-27 00:00:00+00:00    0.004002\n",
            "Name: daily_return, Length: 241, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2018-01-08</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2018-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>3.351%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>3.202%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>21.675%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-20.633%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.708%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.63</td>\n",
              "      <td>2018-02-23</td>\n",
              "      <td>2018-06-18</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.12</td>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>2018-02-09</td>\n",
              "      <td>2018-02-21</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.54</td>\n",
              "      <td>2018-01-22</td>\n",
              "      <td>2018-01-23</td>\n",
              "      <td>2018-01-24</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.43</td>\n",
              "      <td>2018-01-08</td>\n",
              "      <td>2018-01-10</td>\n",
              "      <td>2018-01-11</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.95</td>\n",
              "      <td>2018-01-26</td>\n",
              "      <td>2018-01-30</td>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.02%</td>\n",
              "      <td>-4.41%</td>\n",
              "      <td>5.12%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...       atr    boll_ub    boll_lb\n",
            "0    2016-01-04  17.730000  17.730000  ...  3.509299  14.647766  14.016737\n",
            "0    2016-01-04  14.440000  14.570000  ...  3.400411  14.647766  14.016737\n",
            "0    2016-01-04  10.452175  10.597057  ...  3.269906  14.548200  14.097024\n",
            "0    2016-01-04  10.825763  10.973749  ...  3.199395  14.662576  13.782956\n",
            "0    2016-01-04  23.850000  24.150000  ...  3.217245  14.594396  13.804038\n",
            "..          ...        ...        ...  ...       ...        ...        ...\n",
            "502  2017-12-29  34.330002  34.330002  ...  1.934575  21.228145  19.053773\n",
            "502  2017-12-29  37.500000  37.500000  ...  1.943872  21.318275  18.827591\n",
            "502  2017-12-29   9.100000   9.100000  ...  1.981404  21.291975  18.751096\n",
            "502  2017-12-29  40.259998  40.259998  ...  1.963693  21.247252  18.647673\n",
            "502  2017-12-29   9.273076   9.273076  ...  1.974343  21.140937  18.619449\n",
            "\n",
            "[22635 rows x 19 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=2475, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=2475, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2018-01-08  0.001165  0.000820  0.001269  ...  0.002447  0.000673  0.002483\n",
            "2018-01-09  0.001370  0.000297  0.000568  ...  0.001906  0.001518  0.001618\n",
            "2018-01-10  0.001663  0.000545  0.001109  ...  0.002372  0.000389  0.000772\n",
            "2018-01-11  0.000566  0.000335  0.000589  ...  0.001263  0.000815  0.001577\n",
            "2018-01-12  0.000740  0.000485  0.000743  ...  0.001162  0.002009  0.000971\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2018-12-19  0.000639  0.000424  0.000804  ...  0.002221  0.000671  0.005042\n",
            "2018-12-20  0.000487  0.001332  0.000579  ...  0.001516  0.000431  0.003887\n",
            "2018-12-21  0.003214  0.000352  0.001864  ...  0.001972  0.001130  0.004973\n",
            "2018-12-26  0.002287  0.000243  0.000497  ...  0.002181  0.001078  0.001430\n",
            "2018-12-27  0.001057  0.000103  0.000948  ...  0.003156  0.000593  0.002157\n",
            "\n",
            "[241 rows x 45 columns]\n",
            "date\n",
            "2018-01-08 00:00:00+00:00    0.000000\n",
            "2018-01-09 00:00:00+00:00   -0.006211\n",
            "2018-01-10 00:00:00+00:00   -0.008508\n",
            "2018-01-11 00:00:00+00:00    0.018799\n",
            "2018-01-12 00:00:00+00:00    0.000466\n",
            "                               ...   \n",
            "2018-12-19 00:00:00+00:00   -0.005715\n",
            "2018-12-20 00:00:00+00:00   -0.006699\n",
            "2018-12-21 00:00:00+00:00    0.001591\n",
            "2018-12-26 00:00:00+00:00   -0.004717\n",
            "2018-12-27 00:00:00+00:00    0.002217\n",
            "Name: daily_return, Length: 241, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2018-01-08</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2018-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>5.13%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>4.901%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>21.831%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>0.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-20.234%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.721%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.23</td>\n",
              "      <td>2018-02-26</td>\n",
              "      <td>2018-06-18</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.62</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>2018-11-13</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.18</td>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>2018-02-09</td>\n",
              "      <td>2018-02-21</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.91</td>\n",
              "      <td>2018-01-17</td>\n",
              "      <td>2018-01-23</td>\n",
              "      <td>2018-01-24</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.47</td>\n",
              "      <td>2018-01-08</td>\n",
              "      <td>2018-01-10</td>\n",
              "      <td>2018-01-11</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.03%</td>\n",
              "      <td>-4.67%</td>\n",
              "      <td>4.72%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/finrl/marketdata/yahoodownloader.py:69: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data_df = data_df.drop(\"adjcp\", 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (33705, 8)\n",
            "Successfully added technical indicators\n",
            "           date       open       high  ...    boll_ub    boll_lb      rsi_14\n",
            "0    2016-01-04  17.730000  17.730000  ...  14.647762  14.016736  100.000000\n",
            "0    2016-01-04  14.440000  14.570000  ...  14.647762  14.016736  100.000000\n",
            "0    2016-01-04  10.452175  10.597057  ...  14.548196  14.097022   59.592518\n",
            "0    2016-01-04  10.825763  10.973749  ...  14.662570  13.782960   27.367700\n",
            "0    2016-01-04  23.850000  24.150000  ...  14.594390  13.804041   43.190120\n",
            "..          ...        ...        ...  ...        ...        ...         ...\n",
            "502  2017-12-29  34.330002  34.330002  ...  21.228144  19.053772   32.104776\n",
            "502  2017-12-29  37.500000  37.500000  ...  21.318274  18.827590   36.519787\n",
            "502  2017-12-29   9.100000   9.100000  ...  21.291975  18.751096   46.509124\n",
            "502  2017-12-29  40.259998  40.259998  ...  21.247252  18.647674   43.298904\n",
            "502  2017-12-29   9.273076   9.273076  ...  21.140936  18.619450   47.636105\n",
            "\n",
            "[22635 rows x 13 columns]\n",
            "ActorCritic(\n",
            "  (actor): Sequential(\n",
            "    (0): Linear(in_features=1125, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=45, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            "  (critic): Sequential(\n",
            "    (0): Linear(in_features=1125, out_features=64, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.59\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.58\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.57\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.56\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.55\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.54\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.53\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.52\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "setting actor output action_std to :  0.51\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training\n",
            "Testing\n",
            "            ABEV3.SA  BBAS3.SA  BBDC3.SA  ...  USIM5.SA  VALE3.SA  WEGE3.SA\n",
            "date                                      ...                              \n",
            "2018-01-08  0.001165  0.000820  0.001269  ...  0.002447  0.000673  0.002483\n",
            "2018-01-09  0.001807  0.000345  0.002731  ...  0.002474  0.000516  0.002976\n",
            "2018-01-10  0.001230  0.001165  0.000648  ...  0.004012  0.000353  0.006324\n",
            "2018-01-11  0.000330  0.000417  0.000416  ...  0.002367  0.000659  0.003852\n",
            "2018-01-12  0.000726  0.000317  0.000634  ...  0.002531  0.000566  0.001875\n",
            "...              ...       ...       ...  ...       ...       ...       ...\n",
            "2018-12-19  0.001803  0.000696  0.001713  ...  0.002691  0.000523  0.002601\n",
            "2018-12-20  0.003013  0.000234  0.001525  ...  0.003012  0.000400  0.005152\n",
            "2018-12-21  0.001384  0.000448  0.001844  ...  0.002678  0.000362  0.003476\n",
            "2018-12-26  0.001121  0.000869  0.001202  ...  0.003708  0.000609  0.002050\n",
            "2018-12-27  0.001417  0.000493  0.001861  ...  0.003798  0.000868  0.003073\n",
            "\n",
            "[241 rows x 45 columns]\n",
            "date\n",
            "2018-01-08 00:00:00+00:00    0.000000\n",
            "2018-01-09 00:00:00+00:00   -0.006211\n",
            "2018-01-10 00:00:00+00:00   -0.007967\n",
            "2018-01-11 00:00:00+00:00    0.018342\n",
            "2018-01-12 00:00:00+00:00    0.000023\n",
            "                               ...   \n",
            "2018-12-19 00:00:00+00:00   -0.005937\n",
            "2018-12-20 00:00:00+00:00   -0.005088\n",
            "2018-12-21 00:00:00+00:00    0.000521\n",
            "2018-12-26 00:00:00+00:00   -0.003659\n",
            "2018-12-27 00:00:00+00:00    0.002550\n",
            "Name: daily_return, Length: 241, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2018-01-08</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2018-12-27</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>5.727%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>5.47%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>21.846%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>0.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-19.626%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.721%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.63</td>\n",
              "      <td>2018-02-23</td>\n",
              "      <td>2018-06-18</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.73</td>\n",
              "      <td>2018-01-26</td>\n",
              "      <td>2018-02-09</td>\n",
              "      <td>2018-02-23</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.56</td>\n",
              "      <td>2018-11-05</td>\n",
              "      <td>2018-11-13</td>\n",
              "      <td>2018-11-29</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.71</td>\n",
              "      <td>2018-12-03</td>\n",
              "      <td>2018-12-26</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.49</td>\n",
              "      <td>2018-01-17</td>\n",
              "      <td>2018-01-23</td>\n",
              "      <td>2018-01-24</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py:1230: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
            "  period = returns_dupe.loc[start:end]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.03%</td>\n",
              "      <td>-4.58%</td>\n",
              "      <td>5.25%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "policies = ['MlpPolicy'] #SE QUEDA ASI\n",
        "episodes = [100] #MODIFICABLE, SE QUEDA ASI POR CONEGUNDES\n",
        "\n",
        "market_variables = [['open', 'close', 'volume'], ['volume']] #SE PUEDE PONER EL CIERRE AJUSTADO\n",
        "indicators = [['close_5_sma', 'close_10_sma', 'close_5_ema', 'close_10_ema', 'macd', 'rsi_14', 'cci', 'atr', 'boll_ub', 'boll_lb'],\n",
        "              ['close_20_sma', 'boll_ub', 'boll_lb', 'rsi_14']]\n",
        "\n",
        "\n",
        "reward_function = ['pv'] #SE MODIFICA DE ACUERDO A LA CORRIDA, SE PUEDE CORRER CON ['pv', 'sr']\n",
        "n_steps = [None]\n",
        "normalization_function = [None]\n",
        "\n",
        "#tickers=['PLTR', 'DELL', 'GLW', 'LSPD', 'ST', 'VNT', 'SAIC', 'YALA']\n",
        "#tickers=['ELAT', 'OSH', 'AMWL', 'INSP', 'CTLT', 'BIO', 'TARO', 'BSX', 'AMN', 'TEVA']\n",
        "#tickers=['PDS', 'WLL', 'PBA', 'ALIN-PE', 'EURN', 'XOM', 'TPL', 'DLNG-PA', 'OVV', 'EPD']\n",
        "# 2017\n",
        "#tickers=['ITUB4.SA', 'BBDC4.SA', 'ABEV3.SA', 'PETR4.SA', 'VALE3.SA', 'BRFS3.SA', 'BBAS3.SA', 'ITSA4.SA', 'B3SA3.SA', 'UGPA3.SA']\n",
        "# 2018\n",
        "#tickers=['ITUB4.SA', 'VALE3.SA', 'BBDC4.SA', 'ABEV3.SA', 'PETR4.SA', 'B3SA3.SA', 'ITSA4.SA', 'BBAS3.SA', 'UGPA3.SA', 'BRFS3.SA']\n",
        "# 2019\n",
        "#tickers=['ITUB4.SA', 'VALE3.SA', 'BBDC4.SA', 'PETR4.SA', 'ABEV3.SA', 'BBAS3.SA', 'B3SA3.SA', 'ITSA4.SA', 'LREN3.SA', 'UGPA3.SA']\n",
        "# SP500 - 2020\n",
        "#tickers=['MSFT', 'AAPL']\n",
        "# BOVESPA ETF\n",
        "tickers=['ITUB4.SA','BBDC4.SA','ABEV3.SA', 'PETR4.SA', 'VALE3.SA','PETR3.SA', 'BBAS3.SA', 'ITSA4.SA', 'BRFS3.SA','UGPA3.SA','CIEL3.SA', 'JBSS3.SA','BBSE3.SA','BBDC3.SA','LREN3.SA','CCRO3.SA','RADL3.SA','EMBR3.SA','SANB11.SA','EQTL3.SA','HYPE3.SA','SBSP3.SA','GGBR4.SA','WEGE3.SA','BRKM5.SA','BRML3.SA','CPFE3.SA','CMIG4.SA','EGIE3.SA','KLBN11.SA','CSNA3.SA','CSAN3.SA','RENT3.SA','ELET3.SA','MULT3.SA','BRAP4.SA','QUAL3.SA','MRVE3.SA','ENBR3.SA','CPLE6.SA','GOAU4.SA','CYRE3.SA','USIM5.SA','MRFG3.SA','ECOR3.SA']\n",
        "\n",
        "training_start_date='2016-01-01'\n",
        "training_end_date='2017-12-31'\n",
        "trading_start_date='2018-01-01'\n",
        "trading_end_date='2018-12-31'\n",
        "\n",
        "f= open(\"./out.txt\",\"w+\")\n",
        "f.write(str(tickers) + '\\n')\n",
        "f.write(training_start_date+ '\\n')\n",
        "f.write(training_end_date+ '\\n')\n",
        "f.write(trading_start_date+ '\\n')\n",
        "f.write(trading_end_date+ '\\n\\n')\n",
        "\n",
        "for i, cb in enumerate(itertools.product(policies,\n",
        "                                episodes,\n",
        "                                n_steps,\n",
        "                                market_variables,\n",
        "                                indicators,\n",
        "                                reward_function,\n",
        "                                normalization_function)):\n",
        "  \n",
        "  f.write('CB' + str(i) + '\\n')\n",
        "  f.write('{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n{}\\n'.format(cb[0],cb[1], cb[2], cb[3], cb[4], cb[5], cb[6]))\n",
        "  train_and_perform(index='CB' + str(i),\n",
        "                    policy=cb[0],\n",
        "                    episodes=cb[1],\n",
        "                    n_steps=None,\n",
        "                    market_variables=cb[3],\n",
        "                    indicators=cb[4],\n",
        "                    reward_function=cb[5],\n",
        "                    normalization_function=cb[6],\n",
        "                    tickers=tickers,\n",
        "                    training_start_date=training_start_date,\n",
        "                    training_end_date=training_end_date,\n",
        "                    trading_start_date=trading_start_date,\n",
        "                    trading_end_date=trading_end_date,\n",
        "                    trading_fee=0,\n",
        "                    file_=f,\n",
        "                    nn_arch='MLP',\n",
        "                    window_width=5) #LAG\n",
        "  f.write('\\n\\n\\n')\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KNP526zy69NK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jvQeBc6SyedA",
        "IxqB2TSe-rZd",
        "J9WZVB3eyjXN",
        "JDfuXELB-0Ob",
        "hKENnzGyiGJ3"
      ],
      "name": "V4_ppo_trading_2_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}